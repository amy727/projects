{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Neural Collaborative Filtering\n",
        "\n",
        "The paper \"Neural Collaborative Filtering\" (https://arxiv.org/pdf/1708.05031.pdf) aims to improve traditional collaborative filtering by replacing the inner product with a neural architecture that can learn an arbitrary function from the data. To supercharge NCF modelling with non-linearities, the authors propose to leverage a multi-layer perceptron (MLP) to learn the user-item interaction function.\n",
        "\n",
        "This notebook implements and explores the NCF-GMF and NCF-MLP frameworks."
      ],
      "metadata": {
        "id": "ona6ZzEAnl_C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "ngk-cxGHoIBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from matplotlib import pyplot as plt"
      ],
      "metadata": {
        "id": "sfmt3VUToNBt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "aXAtjfIFpfMJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data\n",
        "The MovieLens dataset (ml-latest-small) describes 5-star rating and free-text tagging activity from MovieLens, a movie recommendation service. It contains 100004 ratings and 1296 tag applications across 9125 movies."
      ],
      "metadata": {
        "id": "4DzMCkUYodFQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fpULkr9gnBrN"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(\"ratings.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encode Data"
      ],
      "metadata": {
        "id": "lw5QohbppLsF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# split train and validation before encoding\n",
        "np.random.seed(3)\n",
        "msk = np.random.rand(len(data)) < 0.8\n",
        "train = data[msk].copy()\n",
        "val = data[~msk].copy()"
      ],
      "metadata": {
        "id": "JN7_KSRnpHuy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# here is a handy function modified from fast.ai\n",
        "def proc_col(col, train_col=None):\n",
        "    \"\"\"Encodes a pandas column with continuous ids.\n",
        "    \"\"\"\n",
        "    if train_col is not None:\n",
        "        uniq = train_col.unique()\n",
        "    else:\n",
        "        uniq = col.unique()\n",
        "    name2idx = {o:i for i,o in enumerate(uniq)}\n",
        "    return name2idx, np.array([name2idx.get(x, -1) for x in col]), len(uniq)"
      ],
      "metadata": {
        "id": "b8eckHjYpHiu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_data(df, train=None):\n",
        "    \"\"\" Encodes rating data with continous user and movie ids.\n",
        "    If train is provided, encodes df with the same encoding as train.\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "    for col_name in [\"userId\", \"movieId\"]:\n",
        "        train_col = None\n",
        "        if train is not None:\n",
        "            train_col = train[col_name]\n",
        "        _,col,_ = proc_col(df[col_name], train_col)\n",
        "        df[col_name] = col\n",
        "        df = df[df[col_name] >= 0]\n",
        "    return df"
      ],
      "metadata": {
        "id": "am86fxhppOpp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# encoding the train and validation data\n",
        "df_train = encode_data(train)\n",
        "df_val = encode_data(val, train)"
      ],
      "metadata": {
        "id": "zELEhSXQpSb7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "V1s4QCzkXLvc",
        "outputId": "ae630e3f-3ef6-40cc-d66d-9f727606d775"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    userId  movieId  rating  timestamp\n",
              "0        0        0     4.0  964982703\n",
              "1        0        1     4.0  964981247\n",
              "2        0        2     4.0  964982224\n",
              "3        0        3     5.0  964983815\n",
              "6        0        4     5.0  964980868\n",
              "7        0        5     4.0  964982176\n",
              "8        0        6     5.0  964984041\n",
              "9        0        7     5.0  964984100\n",
              "10       0        8     5.0  964983650\n",
              "11       0        9     5.0  964981208"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ab7e9a33-39b4-4df0-8c77-8fe3aa7c9d66\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964982703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964981247</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964982224</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>5.0</td>\n",
              "      <td>964983815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>5.0</td>\n",
              "      <td>964980868</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964982176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>5.0</td>\n",
              "      <td>964984041</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>5.0</td>\n",
              "      <td>964984100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>5.0</td>\n",
              "      <td>964983650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>5.0</td>\n",
              "      <td>964981208</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ab7e9a33-39b4-4df0-8c77-8fe3aa7c9d66')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ab7e9a33-39b4-4df0-8c77-8fe3aa7c9d66 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ab7e9a33-39b4-4df0-8c77-8fe3aa7c9d66');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e1c1464c-5fae-47ed-9cfd-8dff3657e756\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e1c1464c-5fae-47ed-9cfd-8dff3657e756')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e1c1464c-5fae-47ed-9cfd-8dff3657e756 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate model parameters for NCF-GMF"
      ],
      "metadata": {
        "id": "lPXMy7VkFaPs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# NCF-GMF implementation\n",
        "class MF(nn.Module):\n",
        "    def __init__(self, num_users, num_items, emb_size=100):\n",
        "        super(MF, self).__init__()\n",
        "        self.user_emb = nn.Embedding(num_users, emb_size)\n",
        "        self.item_emb = nn.Embedding(num_items, emb_size)\n",
        "        self.user_emb.weight.data.uniform_(0, 0.05)\n",
        "        self.item_emb.weight.data.uniform_(0, 0.05)\n",
        "\n",
        "    def forward(self, u, v):\n",
        "        u = self.user_emb(u)\n",
        "        v = self.item_emb(v)\n",
        "        return (u*v).sum(1)"
      ],
      "metadata": {
        "id": "T0JOqTqCFhWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_users = len(df_train.userId.unique())\n",
        "num_items = len(df_train.movieId.unique())\n",
        "print(num_users, num_items)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eq_djyakZt9V",
        "outputId": "4e7bfc53-bd59-42f6-c242-3ef43a9f47a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "610 8998\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Loop\n",
        "def train_epocs(model, epochs=10, lr=0.01, wd=0.0):\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
        "    model.train()\n",
        "    for i in range(epochs):\n",
        "        # Train\n",
        "        users = torch.LongTensor(df_train.userId.values) # .cuda()\n",
        "        items = torch.LongTensor(df_train.movieId.values) #.cuda()\n",
        "        ratings = torch.FloatTensor(df_train.rating.values) #.cuda()\n",
        "\n",
        "        y_hat = model(users, items)\n",
        "        loss = F.mse_loss(y_hat, ratings)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Val\n",
        "        users_val = torch.LongTensor(df_val.userId.values) # .cuda()\n",
        "        items_val = torch.LongTensor(df_val.movieId.values) #.cuda()\n",
        "        ratings_val = torch.FloatTensor(df_val.rating.values) #.cuda()\n",
        "\n",
        "        y_hat_val = model(users_val, items_val)\n",
        "        loss_val = F.mse_loss(y_hat_val, ratings_val)\n",
        "\n",
        "        # Display loss\n",
        "        print(f\"Epoch {i}: Training loss: {loss.item():.4f}  Validation loss: {loss_val.item():.4f}\")\n",
        "\n",
        "    final_val_loss_value = test_loss(model)\n",
        "    return final_val_loss_value\n",
        "\n",
        "def test_loss(model):\n",
        "    model.eval()\n",
        "    users = torch.LongTensor(df_val.userId.values) #.cuda()\n",
        "    items = torch.LongTensor(df_val.movieId.values) #.cuda()\n",
        "    ratings = torch.FloatTensor(df_val.rating.values) #.cuda()\n",
        "    y_hat = model(users, items)\n",
        "    loss = F.mse_loss(y_hat, ratings)\n",
        "    print(\"test loss %.3f \" % loss.item())\n",
        "    return loss.item()"
      ],
      "metadata": {
        "id": "uYMXkVIYZxTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Experiments to determine impact of regularization and embedding size on the model performance"
      ],
      "metadata": {
        "id": "e70gyXdkAvpH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Changing embedding size\n",
        "emb_sizes = [50, 100, 150, 200]\n",
        "val_loss_results = []\n",
        "for emb_size in emb_sizes:\n",
        "    model = MF(num_users, num_items, emb_size=emb_size)\n",
        "    print(f\"===== Train with Embedding Size of {emb_size} ======\")\n",
        "    val_loss_result = train_epocs(model, epochs=10, lr=0.1, wd=0.0)\n",
        "    val_loss_results.append(val_loss_result)\n",
        "plt.figure()\n",
        "plt.scatter(emb_sizes, val_loss_results, marker='o')  # Line plot with circle markers\n",
        "plt.title(\"Impact of Embedding Size on Val Loss for NCF-GMF\")\n",
        "plt.xlabel(\"Embedding Size\")\n",
        "plt.ylabel(\"MSE Loss\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pvZ3WXeJkjdt",
        "outputId": "44fedde1-bfd3-4653-c18c-4bf71f7dccf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== Train with Embedding Size of 50 ======\n",
            "Epoch 0: Training loss: 13.1301  Validation loss: 8.5638\n",
            "Epoch 1: Training loss: 8.4985  Validation loss: 2.6089\n",
            "Epoch 2: Training loss: 2.5938  Validation loss: 2.2174\n",
            "Epoch 3: Training loss: 2.2051  Validation loss: 4.3116\n",
            "Epoch 4: Training loss: 4.1543  Validation loss: 2.0916\n",
            "Epoch 5: Training loss: 1.8977  Validation loss: 1.0120\n",
            "Epoch 6: Training loss: 0.8076  Validation loss: 1.7446\n",
            "Epoch 7: Training loss: 1.5385  Validation loss: 2.6096\n",
            "Epoch 8: Training loss: 2.4093  Validation loss: 2.7405\n",
            "Epoch 9: Training loss: 2.5466  Validation loss: 2.1502\n",
            "test loss 2.150 \n",
            "===== Train with Embedding Size of 100 ======\n",
            "Epoch 0: Training loss: 12.9096  Validation loss: 4.8817\n",
            "Epoch 1: Training loss: 4.8461  Validation loss: 2.5640\n",
            "Epoch 2: Training loss: 2.6094  Validation loss: 3.2424\n",
            "Epoch 3: Training loss: 3.0917  Validation loss: 1.0336\n",
            "Epoch 4: Training loss: 0.8481  Validation loss: 2.0336\n",
            "Epoch 5: Training loss: 1.8238  Validation loss: 2.8758\n",
            "Epoch 6: Training loss: 2.6588  Validation loss: 2.3631\n",
            "Epoch 7: Training loss: 2.1381  Validation loss: 1.3299\n",
            "Epoch 8: Training loss: 1.0935  Validation loss: 1.2154\n",
            "Epoch 9: Training loss: 0.9770  Validation loss: 1.8490\n",
            "test loss 1.849 \n",
            "===== Train with Embedding Size of 150 ======\n",
            "Epoch 0: Training loss: 12.6929  Validation loss: 2.4355\n",
            "Epoch 1: Training loss: 2.4260  Validation loss: 15.2170\n",
            "Epoch 2: Training loss: 15.1320  Validation loss: 1.9832\n",
            "Epoch 3: Training loss: 1.8192  Validation loss: 2.2250\n",
            "Epoch 4: Training loss: 2.0569  Validation loss: 5.6162\n",
            "Epoch 5: Training loss: 5.4380  Validation loss: 7.3370\n",
            "Epoch 6: Training loss: 7.1365  Validation loss: 7.4653\n",
            "Epoch 7: Training loss: 7.2304  Validation loss: 6.4683\n",
            "Epoch 8: Training loss: 6.2007  Validation loss: 4.8362\n",
            "Epoch 9: Training loss: 4.5645  Validation loss: 3.3881\n",
            "test loss 3.388 \n",
            "===== Train with Embedding Size of 200 ======\n",
            "Epoch 0: Training loss: 12.4884  Validation loss: 1.2120\n",
            "Epoch 1: Training loss: 1.2291  Validation loss: 27.1617\n",
            "Epoch 2: Training loss: 26.7202  Validation loss: 2.8775\n",
            "Epoch 3: Training loss: 2.6107  Validation loss: 3.6759\n",
            "Epoch 4: Training loss: 3.4891  Validation loss: 8.4368\n",
            "Epoch 5: Training loss: 8.2774  Validation loss: 11.1252\n",
            "Epoch 6: Training loss: 10.9663  Validation loss: 12.3227\n",
            "Epoch 7: Training loss: 12.1478  Validation loss: 12.8551\n",
            "Epoch 8: Training loss: 12.6482  Validation loss: 13.1156\n",
            "Epoch 9: Training loss: 12.8379  Validation loss: 13.2292\n",
            "test loss 13.229 \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the experiments, it can be seen that initially, increasing the embedding size led to lower MSE loss until an embedding size of 100 and afterwards embedding size increases actually led to worse model performance. This could be because with a larger embedding size, the model may be overfitting on the training data and not generalizing well to the validation/test data.\n"
      ],
      "metadata": {
        "id": "8944Jyu8-CJw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Changing Regularization\n",
        "wds = [0.0, 0.01, 0.05, 0.1]\n",
        "val_loss_results = []\n",
        "for wd in wds:\n",
        "    model = MF(num_users, num_items, emb_size=100)\n",
        "    print(f\"===== Train with Regularization of {wd} ======\")\n",
        "    val_loss_result = train_epocs(model, epochs=10, lr=0.1, wd=wd)\n",
        "    val_loss_results.append(val_loss_result)\n",
        "plt.figure()\n",
        "plt.scatter(wds, val_loss_results, marker='o')  # Line plot with circle markers\n",
        "plt.title(\"Impact of Regularization on Val Loss for NCF-GMF\")\n",
        "plt.xlabel(\"Regularization\")\n",
        "plt.ylabel(\"MSE Loss\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jP0cyzYHfOqI",
        "outputId": "8a7e0c20-1961-42d2-f156-9e6d59e9b12f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== Train with Regularization of 0.0 ======\n",
            "Epoch 0: Training loss: 12.9136  Validation loss: 4.8943\n",
            "Epoch 1: Training loss: 4.8563  Validation loss: 2.5391\n",
            "Epoch 2: Training loss: 2.5844  Validation loss: 3.2550\n",
            "Epoch 3: Training loss: 3.1042  Validation loss: 1.0365\n",
            "Epoch 4: Training loss: 0.8508  Validation loss: 2.0297\n",
            "Epoch 5: Training loss: 1.8206  Validation loss: 2.8716\n",
            "Epoch 6: Training loss: 2.6561  Validation loss: 2.3579\n",
            "Epoch 7: Training loss: 2.1348  Validation loss: 1.3228\n",
            "Epoch 8: Training loss: 1.0880  Validation loss: 1.2104\n",
            "Epoch 9: Training loss: 0.9732  Validation loss: 1.8520\n",
            "test loss 1.852 \n",
            "===== Train with Regularization of 0.01 ======\n",
            "Epoch 0: Training loss: 12.9143  Validation loss: 15.8462\n",
            "Epoch 1: Training loss: 15.8719  Validation loss: 13.5858\n",
            "Epoch 2: Training loss: 13.5024  Validation loss: 13.2487\n",
            "Epoch 3: Training loss: 13.1636  Validation loss: 13.6575\n",
            "Epoch 4: Training loss: 13.5989  Validation loss: 13.5001\n",
            "Epoch 5: Training loss: 13.4266  Validation loss: 13.2724\n",
            "Epoch 6: Training loss: 13.1766  Validation loss: 13.4643\n",
            "Epoch 7: Training loss: 13.3705  Validation loss: 13.8995\n",
            "Epoch 8: Training loss: 13.8256  Validation loss: 14.0522\n",
            "Epoch 9: Training loss: 13.9872  Validation loss: 13.7938\n",
            "test loss 13.794 \n",
            "===== Train with Regularization of 0.05 ======\n",
            "Epoch 0: Training loss: 12.9135  Validation loss: 13.2961\n",
            "Epoch 1: Training loss: 13.3229  Validation loss: 13.1752\n",
            "Epoch 2: Training loss: 13.0920  Validation loss: 13.5448\n",
            "Epoch 3: Training loss: 13.4676  Validation loss: 13.3782\n",
            "Epoch 4: Training loss: 13.3401  Validation loss: 13.2588\n",
            "Epoch 5: Training loss: 13.2038  Validation loss: 13.3829\n",
            "Epoch 6: Training loss: 13.2964  Validation loss: 13.4432\n",
            "Epoch 7: Training loss: 13.3529  Validation loss: 13.3254\n",
            "Epoch 8: Training loss: 13.2491  Validation loss: 13.2466\n",
            "Epoch 9: Training loss: 13.1727  Validation loss: 13.3149\n",
            "test loss 13.315 \n",
            "===== Train with Regularization of 0.1 ======\n",
            "Epoch 0: Training loss: 12.9093  Validation loss: 11.6514\n",
            "Epoch 1: Training loss: 11.6348  Validation loss: 12.9586\n",
            "Epoch 2: Training loss: 12.8698  Validation loss: 13.3611\n",
            "Epoch 3: Training loss: 13.2824  Validation loss: 12.6240\n",
            "Epoch 4: Training loss: 12.5740  Validation loss: 12.6555\n",
            "Epoch 5: Training loss: 12.5895  Validation loss: 13.2424\n",
            "Epoch 6: Training loss: 13.1521  Validation loss: 13.4341\n",
            "Epoch 7: Training loss: 13.3435  Validation loss: 13.1173\n",
            "Epoch 8: Training loss: 13.0414  Validation loss: 12.9263\n",
            "Epoch 9: Training loss: 12.8538  Validation loss: 13.1206\n",
            "test loss 13.121 \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the experiments, it can be seen that introducing regularization initially increases the MSE Loss for the NCF-GMF model. This is likely because when regularization is added, it restricts from fitting the data as closely as it could without regularization, which would lead to an increase in MSE loss. However, as we increase the regularization, the loss decreases slightly, showing that it has started to generalize better."
      ],
      "metadata": {
        "id": "CXQAdlE8BHV_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hyperparameter tuning experiments"
      ],
      "metadata": {
        "id": "lPdIluD0DePW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameter tuning to find the best model\n",
        "wds = [0.0, 0.01, 0.05, 0.1]\n",
        "emb_sizes = [50, 100, 150, 200]\n",
        "results = []\n",
        "i = 0\n",
        "for wd in wds:\n",
        "    for emb_size in emb_sizes:\n",
        "        model = MF(num_users, num_items, emb_size=emb_size)\n",
        "        print(f\"===== Experiment {i} ======\")\n",
        "        print(f\"wd: {wd}, emb_size: {emb_size}\")\n",
        "        val_loss_result = train_epocs(model, epochs=10, lr=0.1, wd=wd)\n",
        "        results.append((wd, emb_size, val_loss_result))\n",
        "        i += 1\n",
        "print(\"====== Best Performing Model ======\")\n",
        "best_res_idx = results.index(min(results, key=lambda x: x[2]))\n",
        "print(f\"Best result: {results[best_res_idx][2]}\")\n",
        "print(f\"Best hyperparameters: wd={results[best_res_idx][0]}, emb_size={results[best_res_idx][1]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZrUe0UG-A_W",
        "outputId": "b6c3a9c4-e781-450a-8120-dca2fb350785"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== Experiment 0 ======\n",
            "wd: 0.0, emb_size: 50\n",
            "Epoch 0: Training loss: 13.1294  Validation loss: 8.5617\n",
            "Epoch 1: Training loss: 8.4959  Validation loss: 2.6067\n",
            "Epoch 2: Training loss: 2.5911  Validation loss: 2.2196\n",
            "Epoch 3: Training loss: 2.2080  Validation loss: 4.3094\n",
            "Epoch 4: Training loss: 4.1525  Validation loss: 2.0901\n",
            "Epoch 5: Training loss: 1.8957  Validation loss: 1.0125\n",
            "Epoch 6: Training loss: 0.8078  Validation loss: 1.7454\n",
            "Epoch 7: Training loss: 1.5392  Validation loss: 2.6095\n",
            "Epoch 8: Training loss: 2.4094  Validation loss: 2.7397\n",
            "Epoch 9: Training loss: 2.5459  Validation loss: 2.1493\n",
            "test loss 2.149 \n",
            "===== Experiment 1 ======\n",
            "wd: 0.0, emb_size: 100\n",
            "Epoch 0: Training loss: 12.9114  Validation loss: 4.8898\n",
            "Epoch 1: Training loss: 4.8508  Validation loss: 2.5544\n",
            "Epoch 2: Training loss: 2.6014  Validation loss: 3.2485\n",
            "Epoch 3: Training loss: 3.0987  Validation loss: 1.0354\n",
            "Epoch 4: Training loss: 0.8501  Validation loss: 2.0311\n",
            "Epoch 5: Training loss: 1.8229  Validation loss: 2.8734\n",
            "Epoch 6: Training loss: 2.6588  Validation loss: 2.3617\n",
            "Epoch 7: Training loss: 2.1389  Validation loss: 1.3290\n",
            "Epoch 8: Training loss: 1.0939  Validation loss: 1.2152\n",
            "Epoch 9: Training loss: 0.9768  Validation loss: 1.8510\n",
            "test loss 1.851 \n",
            "===== Experiment 2 ======\n",
            "wd: 0.0, emb_size: 150\n",
            "Epoch 0: Training loss: 12.6988  Validation loss: 2.4424\n",
            "Epoch 1: Training loss: 2.4337  Validation loss: 15.1688\n",
            "Epoch 2: Training loss: 15.0824  Validation loss: 1.9774\n",
            "Epoch 3: Training loss: 1.8144  Validation loss: 2.2233\n",
            "Epoch 4: Training loss: 2.0565  Validation loss: 5.6072\n",
            "Epoch 5: Training loss: 5.4292  Validation loss: 7.3192\n",
            "Epoch 6: Training loss: 7.1180  Validation loss: 7.4377\n",
            "Epoch 7: Training loss: 7.2012  Validation loss: 6.4304\n",
            "Epoch 8: Training loss: 6.1604  Validation loss: 4.7952\n",
            "Epoch 9: Training loss: 4.5198  Validation loss: 3.3627\n",
            "test loss 3.363 \n",
            "===== Experiment 3 ======\n",
            "wd: 0.0, emb_size: 200\n",
            "Epoch 0: Training loss: 12.4861  Validation loss: 1.2164\n",
            "Epoch 1: Training loss: 1.2340  Validation loss: 27.0343\n",
            "Epoch 2: Training loss: 26.6082  Validation loss: 2.8751\n",
            "Epoch 3: Training loss: 2.6126  Validation loss: 3.6848\n",
            "Epoch 4: Training loss: 3.4969  Validation loss: 8.4265\n",
            "Epoch 5: Training loss: 8.2645  Validation loss: 11.1031\n",
            "Epoch 6: Training loss: 10.9411  Validation loss: 12.2974\n",
            "Epoch 7: Training loss: 12.1221  Validation loss: 12.8310\n",
            "Epoch 8: Training loss: 12.6248  Validation loss: 13.0903\n",
            "Epoch 9: Training loss: 12.8106  Validation loss: 13.1963\n",
            "test loss 13.196 \n",
            "===== Experiment 4 ======\n",
            "wd: 0.01, emb_size: 50\n",
            "Epoch 0: Training loss: 13.1271  Validation loss: 14.5663\n",
            "Epoch 1: Training loss: 14.5234  Validation loss: 13.5060\n",
            "Epoch 2: Training loss: 13.4169  Validation loss: 13.3178\n",
            "Epoch 3: Training loss: 13.2284  Validation loss: 13.4924\n",
            "Epoch 4: Training loss: 13.4146  Validation loss: 13.4016\n",
            "Epoch 5: Training loss: 13.3158  Validation loss: 13.3023\n",
            "Epoch 6: Training loss: 13.2061  Validation loss: 13.4305\n",
            "Epoch 7: Training loss: 13.3359  Validation loss: 13.6710\n",
            "Epoch 8: Training loss: 13.5863  Validation loss: 13.7436\n",
            "Epoch 9: Training loss: 13.6632  Validation loss: 13.5925\n",
            "test loss 13.592 \n",
            "===== Experiment 5 ======\n",
            "wd: 0.01, emb_size: 100\n",
            "Epoch 0: Training loss: 12.9161  Validation loss: 15.8443\n",
            "Epoch 1: Training loss: 15.8621  Validation loss: 13.5855\n",
            "Epoch 2: Training loss: 13.5014  Validation loss: 13.2521\n",
            "Epoch 3: Training loss: 13.1673  Validation loss: 13.6618\n",
            "Epoch 4: Training loss: 13.6027  Validation loss: 13.5024\n",
            "Epoch 5: Training loss: 13.4291  Validation loss: 13.2736\n",
            "Epoch 6: Training loss: 13.1786  Validation loss: 13.4651\n",
            "Epoch 7: Training loss: 13.3713  Validation loss: 13.8992\n",
            "Epoch 8: Training loss: 13.8241  Validation loss: 14.0500\n",
            "Epoch 9: Training loss: 13.9835  Validation loss: 13.7911\n",
            "test loss 13.791 \n",
            "===== Experiment 6 ======\n",
            "wd: 0.01, emb_size: 150\n",
            "Epoch 0: Training loss: 12.6973  Validation loss: 17.2944\n",
            "Epoch 1: Training loss: 17.3845  Validation loss: 13.6693\n",
            "Epoch 2: Training loss: 13.5896  Validation loss: 13.2093\n",
            "Epoch 3: Training loss: 13.1291  Validation loss: 13.8954\n",
            "Epoch 4: Training loss: 13.8569  Validation loss: 13.6838\n",
            "Epoch 5: Training loss: 13.6250  Validation loss: 13.3014\n",
            "Epoch 6: Training loss: 13.2086  Validation loss: 13.5053\n",
            "Epoch 7: Training loss: 13.4118  Validation loss: 14.0855\n",
            "Epoch 8: Training loss: 14.0173  Validation loss: 14.3072\n",
            "Epoch 9: Training loss: 14.2509  Validation loss: 13.9646\n",
            "test loss 13.965 \n",
            "===== Experiment 7 ======\n",
            "wd: 0.01, emb_size: 200\n",
            "Epoch 0: Training loss: 12.4889  Validation loss: 18.9439\n",
            "Epoch 1: Training loss: 19.0874  Validation loss: 13.7586\n",
            "Epoch 2: Training loss: 13.6820  Validation loss: 13.2061\n",
            "Epoch 3: Training loss: 13.1282  Validation loss: 14.2119\n",
            "Epoch 4: Training loss: 14.1886  Validation loss: 13.9415\n",
            "Epoch 5: Training loss: 13.8973  Validation loss: 13.3660\n",
            "Epoch 6: Training loss: 13.2792  Validation loss: 13.5368\n",
            "Epoch 7: Training loss: 13.4444  Validation loss: 14.2231\n",
            "Epoch 8: Training loss: 14.1553  Validation loss: 14.5048\n",
            "Epoch 9: Training loss: 14.4483  Validation loss: 14.0914\n",
            "test loss 14.091 \n",
            "===== Experiment 8 ======\n",
            "wd: 0.05, emb_size: 50\n",
            "Epoch 0: Training loss: 13.1265  Validation loss: 13.3290\n",
            "Epoch 1: Training loss: 13.2942  Validation loss: 13.3101\n",
            "Epoch 2: Training loss: 13.2223  Validation loss: 13.4843\n",
            "Epoch 3: Training loss: 13.3981  Validation loss: 13.3887\n",
            "Epoch 4: Training loss: 13.3217  Validation loss: 13.3386\n",
            "Epoch 5: Training loss: 13.2640  Validation loss: 13.4103\n",
            "Epoch 6: Training loss: 13.3203  Validation loss: 13.4399\n",
            "Epoch 7: Training loss: 13.3475  Validation loss: 13.3759\n",
            "Epoch 8: Training loss: 13.2900  Validation loss: 13.3352\n",
            "Epoch 9: Training loss: 13.2510  Validation loss: 13.3737\n",
            "test loss 13.374 \n",
            "===== Experiment 9 ======\n",
            "wd: 0.05, emb_size: 100\n",
            "Epoch 0: Training loss: 12.9089  Validation loss: 13.2839\n",
            "Epoch 1: Training loss: 13.3096  Validation loss: 13.1790\n",
            "Epoch 2: Training loss: 13.0954  Validation loss: 13.5383\n",
            "Epoch 3: Training loss: 13.4606  Validation loss: 13.3628\n",
            "Epoch 4: Training loss: 13.3246  Validation loss: 13.2524\n",
            "Epoch 5: Training loss: 13.1971  Validation loss: 13.3844\n",
            "Epoch 6: Training loss: 13.2974  Validation loss: 13.4392\n",
            "Epoch 7: Training loss: 13.3486  Validation loss: 13.3098\n",
            "Epoch 8: Training loss: 13.2337  Validation loss: 13.2280\n",
            "Epoch 9: Training loss: 13.1548  Validation loss: 13.3050\n",
            "test loss 13.305 \n",
            "===== Experiment 10 ======\n",
            "wd: 0.05, emb_size: 150\n",
            "Epoch 0: Training loss: 12.6984  Validation loss: 13.3034\n",
            "Epoch 1: Training loss: 13.3971  Validation loss: 13.0398\n",
            "Epoch 2: Training loss: 12.9642  Validation loss: 13.6015\n",
            "Epoch 3: Training loss: 13.5320  Validation loss: 13.3709\n",
            "Epoch 4: Training loss: 13.3615  Validation loss: 13.1841\n",
            "Epoch 5: Training loss: 13.1512  Validation loss: 13.3590\n",
            "Epoch 6: Training loss: 13.2776  Validation loss: 13.4409\n",
            "Epoch 7: Training loss: 13.3512  Validation loss: 13.2577\n",
            "Epoch 8: Training loss: 13.1870  Validation loss: 13.1383\n",
            "Epoch 9: Training loss: 13.0715  Validation loss: 13.2446\n",
            "test loss 13.245 \n",
            "===== Experiment 11 ======\n",
            "wd: 0.05, emb_size: 200\n",
            "Epoch 0: Training loss: 12.4859  Validation loss: 13.3907\n",
            "Epoch 1: Training loss: 13.5503  Validation loss: 12.9166\n",
            "Epoch 2: Training loss: 12.8457  Validation loss: 13.6584\n",
            "Epoch 3: Training loss: 13.5968  Validation loss: 13.3969\n",
            "Epoch 4: Training loss: 13.4166  Validation loss: 13.1468\n",
            "Epoch 5: Training loss: 13.1355  Validation loss: 13.3491\n",
            "Epoch 6: Training loss: 13.2725  Validation loss: 13.4292\n",
            "Epoch 7: Training loss: 13.3408  Validation loss: 13.1777\n",
            "Epoch 8: Training loss: 13.1141  Validation loss: 13.0327\n",
            "Epoch 9: Training loss: 12.9738  Validation loss: 13.1835\n",
            "test loss 13.183 \n",
            "===== Experiment 12 ======\n",
            "wd: 0.1, emb_size: 50\n",
            "Epoch 0: Training loss: 13.1270  Validation loss: 12.5336\n",
            "Epoch 1: Training loss: 12.4787  Validation loss: 13.2010\n",
            "Epoch 2: Training loss: 13.1098  Validation loss: 13.3982\n",
            "Epoch 3: Training loss: 13.3118  Validation loss: 13.0272\n",
            "Epoch 4: Training loss: 12.9551  Validation loss: 13.0501\n",
            "Epoch 5: Training loss: 12.9700  Validation loss: 13.3440\n",
            "Epoch 6: Training loss: 13.2519  Validation loss: 13.4346\n",
            "Epoch 7: Training loss: 13.3425  Validation loss: 13.2732\n",
            "Epoch 8: Training loss: 13.1887  Validation loss: 13.1799\n",
            "Epoch 9: Training loss: 13.0971  Validation loss: 13.2812\n",
            "test loss 13.281 \n",
            "===== Experiment 13 ======\n",
            "wd: 0.1, emb_size: 100\n",
            "Epoch 0: Training loss: 12.9123  Validation loss: 11.7205\n",
            "Epoch 1: Training loss: 11.7034  Validation loss: 12.9728\n",
            "Epoch 2: Training loss: 12.8838  Validation loss: 13.3609\n",
            "Epoch 3: Training loss: 13.2828  Validation loss: 12.6443\n",
            "Epoch 4: Training loss: 12.5948  Validation loss: 12.6804\n",
            "Epoch 5: Training loss: 12.6139  Validation loss: 13.2520\n",
            "Epoch 6: Training loss: 13.1610  Validation loss: 13.4303\n",
            "Epoch 7: Training loss: 13.3399  Validation loss: 13.1134\n",
            "Epoch 8: Training loss: 13.0388  Validation loss: 12.9291\n",
            "Epoch 9: Training loss: 12.8579  Validation loss: 13.1254\n",
            "test loss 13.125 \n",
            "===== Experiment 14 ======\n",
            "wd: 0.1, emb_size: 150\n",
            "Epoch 0: Training loss: 12.6984  Validation loss: 10.9578\n",
            "Epoch 1: Training loss: 10.9786  Validation loss: 12.7505\n",
            "Epoch 2: Training loss: 12.6639  Validation loss: 13.3181\n",
            "Epoch 3: Training loss: 13.2479  Validation loss: 12.2801\n",
            "Epoch 4: Training loss: 12.2538  Validation loss: 12.3323\n",
            "Epoch 5: Training loss: 12.2802  Validation loss: 13.1669\n",
            "Epoch 6: Training loss: 13.0777  Validation loss: 13.4221\n",
            "Epoch 7: Training loss: 13.3336  Validation loss: 12.9539\n",
            "Epoch 8: Training loss: 12.8891  Validation loss: 12.6904\n",
            "Epoch 9: Training loss: 12.6304  Validation loss: 12.9816\n",
            "test loss 12.982 \n",
            "===== Experiment 15 ======\n",
            "wd: 0.1, emb_size: 200\n",
            "Epoch 0: Training loss: 12.4857  Validation loss: 10.0968\n",
            "Epoch 1: Training loss: 10.1434  Validation loss: 12.4985\n",
            "Epoch 2: Training loss: 12.4111  Validation loss: 13.2765\n",
            "Epoch 3: Training loss: 13.2161  Validation loss: 11.8731\n",
            "Epoch 4: Training loss: 11.8682  Validation loss: 11.9233\n",
            "Epoch 5: Training loss: 11.8820  Validation loss: 13.0558\n",
            "Epoch 6: Training loss: 12.9670  Validation loss: 13.4260\n",
            "Epoch 7: Training loss: 13.3401  Validation loss: 12.8133\n",
            "Epoch 8: Training loss: 12.7597  Validation loss: 12.4522\n",
            "Epoch 9: Training loss: 12.4048  Validation loss: 12.8238\n",
            "test loss 12.824 \n",
            "====== Best Performing Model ======\n",
            "Best result: 1.8510286808013916\n",
            "Best hyperparameters: wd=0.0, emb_size=100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the experiments, the best performing model based on the lowest validation loss had the following hyperparameters:\n",
        "\n",
        "\n",
        "*   Embedding size of 100\n",
        "*   Regularization of 0.0\n",
        "\n"
      ],
      "metadata": {
        "id": "CO74DdK_C_DT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NCF-MLP Model\n",
        "\n",
        "<img src=https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aP-Mx266ExwoWZPSdHtYpA.png width=\"600\">\n"
      ],
      "metadata": {
        "id": "1J9HMXYnoer8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# NCF-MLP Implementation\n",
        "class my_NCF_MLP(nn.Module):\n",
        "    def __init__(self, num_users, num_items, emb_size=100, hidden_size=10):\n",
        "        super(my_NCF_MLP, self).__init__()\n",
        "\n",
        "        self.user_emb = nn.Embedding(num_users, emb_size)\n",
        "        self.item_emb = nn.Embedding(num_items, emb_size)\n",
        "        self.user_emb.weight.data.uniform_(0, 0.05)\n",
        "        self.item_emb.weight.data.uniform_(0, 0.05)\n",
        "\n",
        "        self.fc_layers = nn.Sequential(\n",
        "            nn.Linear(2*emb_size, hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_size, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, u, v):\n",
        "\n",
        "        u = self.user_emb(u)\n",
        "        v = self.item_emb(v)\n",
        "\n",
        "        x = torch.cat([u, v], dim=1)\n",
        "        x = self.fc_layers(x).squeeze()\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "6BP9a7xIof7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train model"
      ],
      "metadata": {
        "id": "CS_fx_0E2Rfa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epocs(model, epochs=10, lr=0.01, wd=0.0):\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        # Train\n",
        "        users = torch.LongTensor(df_train.userId.values) # .cuda()\n",
        "        items = torch.LongTensor(df_train.movieId.values) #.cuda()\n",
        "        ratings = torch.FloatTensor(df_train.rating.values) #.cuda()\n",
        "\n",
        "        y_hat = model(users, items)\n",
        "        loss = F.mse_loss(y_hat, ratings)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Val\n",
        "        users_val = torch.LongTensor(df_val.userId.values) # .cuda()\n",
        "        items_val = torch.LongTensor(df_val.movieId.values) #.cuda()\n",
        "        ratings_val = torch.FloatTensor(df_val.rating.values) #.cuda()\n",
        "\n",
        "        y_hat_val = model(users_val, items_val)\n",
        "        loss_val = F.mse_loss(y_hat_val, ratings_val)\n",
        "\n",
        "        print(f'Epoch {epoch}: Training loss: {loss.item():.4f}  Validation Loss: {loss_val.item():.4f}')\n",
        "\n",
        "    # Val result\n",
        "    final_val_loss_result = test_loss(model)\n",
        "    return final_val_loss_result\n",
        "\n",
        "def test_loss(model):\n",
        "    model.eval()\n",
        "    users = torch.LongTensor(df_val.userId.values) #.cuda()\n",
        "    items = torch.LongTensor(df_val.movieId.values) #.cuda()\n",
        "    ratings = torch.FloatTensor(df_val.rating.values) #.cuda()\n",
        "    y_hat = model(users, items)\n",
        "    loss = F.mse_loss(y_hat, ratings)\n",
        "    print(\"test loss %.3f \" % loss.item())\n",
        "    return loss.item()"
      ],
      "metadata": {
        "id": "TJAtpqCC2T50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = my_NCF_MLP(num_users, num_items, emb_size=100, hidden_size=10)\n",
        "val_loss_result = train_epocs(model, epochs=10, lr=0.1, wd=0.0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ra2IiXCbqW7D",
        "outputId": "e55ee5f3-60c0-43bc-b355-eeb161c7931d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: Training loss: 11.9020  Validation Loss: 6.0066\n",
            "Epoch 1: Training loss: 5.9671  Validation Loss: 11.0078\n",
            "Epoch 2: Training loss: 11.0880  Validation Loss: 0.9612\n",
            "Epoch 3: Training loss: 0.9501  Validation Loss: 3.1275\n",
            "Epoch 4: Training loss: 3.0730  Validation Loss: 4.6609\n",
            "Epoch 5: Training loss: 4.5776  Validation Loss: 4.2349\n",
            "Epoch 6: Training loss: 4.1560  Validation Loss: 2.5906\n",
            "Epoch 7: Training loss: 2.5166  Validation Loss: 0.9083\n",
            "Epoch 8: Training loss: 0.8102  Validation Loss: 1.8010\n",
            "Epoch 9: Training loss: 1.6405  Validation Loss: 2.6065\n",
            "test loss 2.607 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate model parameters for NCF-MLP"
      ],
      "metadata": {
        "id": "d66B7bBu2rmP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Experiment to compare the impact of changing the embedding size, hidden layers size, regularization"
      ],
      "metadata": {
        "id": "zkgtSHSNJsUV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Changing embedding size\n",
        "emb_sizes = [50, 100, 150, 200]\n",
        "val_loss_results = []\n",
        "for emb_size in emb_sizes:\n",
        "    model = my_NCF_MLP(num_users, num_items, emb_size=emb_size, hidden_size=10)\n",
        "    print(f\"===== Embedding Size of {emb_size} =====\")\n",
        "    val_loss_result = train_epocs(model, epochs=10, lr=0.1, wd=0.0)\n",
        "    val_loss_results.append((val_loss_result))\n",
        "plt.figure()\n",
        "plt.scatter(emb_sizes, val_loss_results, marker='o')  # Line plot with circle markers\n",
        "plt.title(\"Impact of Embedding Size on Val Loss for NCF-MLP\")\n",
        "plt.xlabel(\"Embedding Size\")\n",
        "plt.ylabel(\"MSE Loss\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d77f2e7e-a0a7-4f65-cd0a-c7bd68e61b67",
        "id": "C4O97lyFJ9pZ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== Embedding Size of 50 =====\n",
            "Epoch 0: Training loss: 13.9155  Validation Loss: 7.7934\n",
            "Epoch 1: Training loss: 7.7276  Validation Loss: 3.6274\n",
            "Epoch 2: Training loss: 3.7202  Validation Loss: 1.3821\n",
            "Epoch 3: Training loss: 1.3536  Validation Loss: 1.3240\n",
            "Epoch 4: Training loss: 1.2414  Validation Loss: 2.1576\n",
            "Epoch 5: Training loss: 2.0480  Validation Loss: 1.5103\n",
            "Epoch 6: Training loss: 1.3756  Validation Loss: 0.9663\n",
            "Epoch 7: Training loss: 0.7951  Validation Loss: 1.7110\n",
            "Epoch 8: Training loss: 1.4981  Validation Loss: 1.5536\n",
            "Epoch 9: Training loss: 1.3342  Validation Loss: 0.8943\n",
            "test loss 0.894 \n",
            "===== Embedding Size of 100 =====\n",
            "Epoch 0: Training loss: 11.6072  Validation Loss: 6.0053\n",
            "Epoch 1: Training loss: 5.9612  Validation Loss: 11.7334\n",
            "Epoch 2: Training loss: 11.8498  Validation Loss: 0.9654\n",
            "Epoch 3: Training loss: 0.9552  Validation Loss: 2.7607\n",
            "Epoch 4: Training loss: 2.6981  Validation Loss: 3.9678\n",
            "Epoch 5: Training loss: 3.8894  Validation Loss: 3.0306\n",
            "Epoch 6: Training loss: 2.9464  Validation Loss: 1.1191\n",
            "Epoch 7: Training loss: 1.0473  Validation Loss: 2.3564\n",
            "Epoch 8: Training loss: 2.3041  Validation Loss: 1.5410\n",
            "Epoch 9: Training loss: 1.4423  Validation Loss: 0.7918\n",
            "test loss 0.792 \n",
            "===== Embedding Size of 150 =====\n",
            "Epoch 0: Training loss: 11.4957  Validation Loss: 2.8271\n",
            "Epoch 1: Training loss: 2.8121  Validation Loss: 82.3864\n",
            "Epoch 2: Training loss: 82.3825  Validation Loss: 1.5856\n",
            "Epoch 3: Training loss: 1.4804  Validation Loss: 8.4217\n",
            "Epoch 4: Training loss: 8.3360  Validation Loss: 8.5206\n",
            "Epoch 5: Training loss: 8.5289  Validation Loss: 4.7268\n",
            "Epoch 6: Training loss: 4.9185  Validation Loss: 3.2815\n",
            "Epoch 7: Training loss: 3.8086  Validation Loss: 3.2653\n",
            "Epoch 8: Training loss: 3.7034  Validation Loss: 1.5034\n",
            "Epoch 9: Training loss: 1.5774  Validation Loss: 1.5198\n",
            "test loss 1.520 \n",
            "===== Embedding Size of 200 =====\n",
            "Epoch 0: Training loss: 11.8849  Validation Loss: 2.2208\n",
            "Epoch 1: Training loss: 2.2231  Validation Loss: 143.2272\n",
            "Epoch 2: Training loss: 142.6769  Validation Loss: 2.1869\n",
            "Epoch 3: Training loss: 2.0179  Validation Loss: 9.6174\n",
            "Epoch 4: Training loss: 9.7371  Validation Loss: 8.4137\n",
            "Epoch 5: Training loss: 9.1942  Validation Loss: 3.0530\n",
            "Epoch 6: Training loss: 3.3100  Validation Loss: 3.5749\n",
            "Epoch 7: Training loss: 3.5701  Validation Loss: 7.0736\n",
            "Epoch 8: Training loss: 7.0194  Validation Loss: 3.1714\n",
            "Epoch 9: Training loss: 3.1366  Validation Loss: 0.9823\n",
            "test loss 0.982 \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABNN0lEQVR4nO3deVhUZf8G8HvYZljHkF3ZxBJxQdwILXdFU9LUV3MDt9xTsyzJlTazcssUl0oUU7NUUjOXQkXNMkQq00wUlVdRNHUGUECY5/eHP87rOCAzCowc7s91zVXznOec+T5HmLk55zlnFEIIASIiIiKZsDB3AURERETlieGGiIiIZIXhhoiIiGSF4YaIiIhkheGGiIiIZIXhhoiIiGSF4YaIiIhkheGGiIiIZIXhhoiIiGSF4YaqpPj4eAQGBsLa2ho1atQwdzkAAIVCgQkTJlT46+zfvx8KhQL79+8vs2+7du3Qrl076fn58+ehUCgQFxdXYfWVhwfrptLJbV/l5ORg5MiR8PDwgEKhwOTJk81dElVBDDdPmLi4OCgUCiQnJ5u7lMe2c+dOzJkzp9y3+/fff2Po0KEICAjAqlWrsHLlylL7zpkzBwqFotTHlStXyr0+Kt358+cxbNgwBAQEQKVSwcPDA23atMHs2bPNXVqF27JlCxQKBT7//PNS++zduxcKhQKffvppub++n58fevToUe7bLW8ffPAB4uLiMHbsWMTHx2PIkCEV+np+fn5QKBR49dVXDZYV/yHx7bffGiw7e/YsRo8ejTp16kClUsHJyQmtW7fG4sWLcefOHYPtl/TIy8t7aG3F718WFhbIyMgwWK7VamFra2vwh1XxHzGffPKJUWMvfri5ueH555/H1q1bH7peVWBl7gJIvnbu3ImlS5eWe8DZv38/dDodFi9ejLp16xq1TmxsLBwcHAzan5SjPpXF19cXd+7cgbW1daW/dlpaGlq0aAFbW1sMHz4cfn5+yMzMREpKCubNm4eYmBip7549eyq9vorWvXt3qNVqrF+/HiNHjiyxz/r162FpaYmXX365kqt7ciQmJuLZZ5+t9MC7atUqREdHw8vLq8y+33//Pf7zn/9AqVQiMjISDRs2REFBAQ4dOoSpU6fir7/+0vujq0mTJnj99dcNtmNjY2NUbUqlEhs2bMCbb76p175lyxaj1n+Y+2u7fPkyVqxYgd69eyM2NhZjxox57O2bC8MNVTlZWVkATAsmffv2hYuLSwVVVHUoFAqoVCqzvPbChQuRk5OD1NRU+Pr66i0r/jctZuybflWiVCrRt29frF69GpcvXzb4EM3Ly8PWrVvRuXNnuLm5malK88vKykJQUFC5ba+wsBA6ne6hP1MNGjTA6dOn8eGHH5Z51Cw9PR0vv/wyfH19kZiYCE9PT2nZ+PHjkZaWhu+//15vnVq1amHw4MGPPIYXXnihxHCzfv16dO/eHZs3b37kbT9YW2RkJOrWrYuFCxdW6XDD01JVwNChQ+Hg4ICLFy+iR48ecHBwQK1atbB06VIAwJ9//okOHTrA3t4evr6+WL9+vd76xae6kpKSMHr0aNSsWRNOTk6IjIzEzZs39fp+99136N69O7y8vKBUKhEQEIB3330XRUVFBnX9+uuveOGFF/DUU0/B3t4ejRs3xuLFi6Wai+u7/7BnWZYtW4YGDRpAqVTCy8sL48ePx61bt6Tlfn5+0l90rq6uUCgU5XJkqPjw86ZNmxATE4NatWrB0dERffv2hUajQX5+PiZPngw3Nzc4ODhg2LBhyM/PL3FbX331FerVqweVSoVmzZohKSnJoM+lS5cwfPhwuLu7Q6lUokGDBvjyyy8N+v33v/9Fr169YG9vDzc3N7z22mulvu7KlSsREBAAW1tbtGzZEgcPHjToU9Kcm+Kfr0uXLqFXr15wcHCAq6sr3njjDYN/93///RdDhgyBk5MTatSogaioKPz+++9GzeM5e/YsateubRBsABh8mD84j+Rhh/bvn3tk7H4tSWFhId59910EBARAqVTCz88Pb7/9tsH+Lj69c+jQIbRs2RIqlQp16tTB2rVry3yNwYMHQ6fTYePGjQbLvv/+e2g0GgwaNAgAsHr1anTo0AFubm5QKpUICgpCbGysUWN5VMbug+TkZISHh8PFxQW2trbw9/fH8OHD9fps3LgRzZo1g6OjI5ycnNCoUSPp/aEkxb+D6enp+P7776V/3/PnzwO4F3pGjBgBd3d3qFQqBAcHY82aNXrbuP90zKJFi6RxnDx58qHj9vPzQ2RkJFatWoXLly8/tO9HH32EnJwcfPHFF3rBpljdunUxadKkh27DVAMHDkRqair+/vtvqe3KlStITEzEwIEDy/W1PDw8UL9+faSnp5frdisbj9xUEUVFRejWrRvatGmDjz76CF999RUmTJgAe3t7TJ8+HYMGDULv3r2xfPlyREZGIiwsDP7+/nrbmDBhAmrUqIE5c+bg9OnTiI2NxYULF6Q3FeBeEHJwcMCUKVPg4OCAxMREzJo1C1qtFh9//LG0rb1796JHjx7w9PTEpEmT4OHhgVOnTmHHjh2YNGkSRo8ejcuXL2Pv3r2Ij483aoxz5sxBTEwMOnXqhLFjx0o1/vbbbzh8+DCsra2xaNEirF27Flu3bpVONTVu3LjMbd+4ccOgzcrKyuDoz9y5c2Fra4tp06YhLS0NS5YsgbW1NSwsLHDz5k3MmTMHv/zyC+Li4uDv749Zs2bprX/gwAF8/fXXmDhxIpRKJZYtW4auXbvi6NGjaNiwIQDg6tWrePbZZ6Xz5K6urvjhhx8wYsQIaLVaaQLlnTt30LFjR1y8eBETJ06El5cX4uPjkZiYaDCWL774AqNHj0arVq0wefJknDt3Di+++CKcnZ3h7e1d5v4pKipCeHg4QkND8cknn+DHH3/E/PnzERAQgLFjxwIAdDodIiIicPToUYwdOxaBgYH47rvvEBUVVeb2gXunxH788UckJiaiQ4cORq1TbNGiRcjJydFrW7hwIVJTU1GzZk0Axu/X0owcORJr1qxB37598frrr+PXX3/F3LlzcerUKYM5CGlpaejbty9GjBiBqKgofPnllxg6dCiaNWuGBg0alPoabdq0Qe3atbF+/XpMmTJFb9n69ethZ2eHXr16Abh3KrVBgwZ48cUXYWVlhe3bt2PcuHHQ6XQYP368kXvONMbsg6ysLHTp0gWurq6YNm0aatSogfPnz+udItm7dy8GDBiAjh07Yt68eQCAU6dO4fDhw6V+8NevXx/x8fF47bXXULt2belUiaurK+7cuYN27dohLS0NEyZMgL+/P7755hsMHToUt27dMtjm6tWrkZeXh1GjRkGpVMLZ2bnMsU+fPh1r164t8+jN9u3bUadOHbRq1arMbRa7e/curl+/rtdmZ2cHOzs7o9a//+fmnXfeAQB8/fXXcHBwQPfu3Y2uw9haMzIypN+rKkvQE2X16tUCgPjtt9+ktqioKAFAfPDBB1LbzZs3ha2trVAoFGLjxo1S+99//y0AiNmzZxtss1mzZqKgoEBq/+ijjwQA8d1330ltt2/fNqhp9OjRws7OTuTl5QkhhCgsLBT+/v7C19dX3Lx5U6+vTqeT/n/8+PHC2B+xrKwsYWNjI7p06SKKioqk9s8++0wAEF9++aXUNnv2bAFAXLt2rcztFvct6VGvXj2p3759+wQA0bBhQ719NGDAAKFQKES3bt30thsWFiZ8fX312oq3m5ycLLVduHBBqFQq8dJLL0ltI0aMEJ6enuL69et667/88stCrVZL/waLFi0SAMSmTZukPrm5uaJu3boCgNi3b58QQoiCggLh5uYmmjRpIvLz86W+K1euFABE27Ztpbb09HQBQKxevVpqK/75euedd/TqCQkJEc2aNZOeb968WQAQixYtktqKiopEhw4dDLZZkhMnTghbW1sBQDRp0kRMmjRJJCQkiNzcXIO+bdu21av7QZs2bTKo2dj9WpLU1FQBQIwcOVKv/Y033hAARGJiotTm6+srAIikpCSpLSsrSyiVSvH666+X+hrFpk6dKgCI06dPS20ajUaoVCoxYMAAqa2kesPDw0WdOnX02sraV/fX3b1791KXG7sPtm7davAe9aBJkyYJJycnUVhYWGZdxtRZ/Luwbt06qa2goECEhYUJBwcHodVqhRD/+/l2cnISWVlZJr/esGHDhEqlEpcvXxZC/O994ZtvvhFC3Pt3AiB69uxp0nhKev+5/z26NPe/173xxhuibt260rIWLVqIYcOGCSHuvfeMHz9eWla8Hz7++OMya+vSpYu4du2auHbtmvj999/Fyy+/LACIV1991egxPol4WqoKuX8SYo0aNVCvXj3Y29ujX79+Unu9evVQo0YNnDt3zmD9UaNG6U0kHTt2LKysrLBz506pzdbWVvr/7OxsXL9+Hc8//zxu374tHRI9fvw40tPTMXnyZIMjH8aceirJjz/+iIKCAkyePBkWFv/7sXzllVfg5ORkcA7bVJs3b8bevXv1HqtXrzboFxkZqbePQkNDIYQwOOQeGhqKjIwMFBYW6rWHhYWhWbNm0nMfHx/07NkTu3fvRlFREYQQ2Lx5MyIiIiCEwPXr16VHeHg4NBoNUlJSANybkO3p6Ym+fftK27Ozs8OoUaP0XjM5ORlZWVkYM2aM3ryCoUOHQq1WG72PHjy//vzzz+v9HO3atQvW1tZ45ZVXpDYLCwujjyI0aNAAqampGDx4MM6fP4/FixejV69ecHd3x6pVq4yu8+TJkxg+fDh69uyJGTNmAIBJ+7Ukxb8DDx5NKT568ODPX1BQEJ5//nnpuaurK+rVq1fi792Diuc33H/6ePPmzcjLy5NOSQH6v4sajQbXr19H27Ztce7cOWg0mjJfx1TG7oPi3/kdO3bg7t27JW6rRo0ayM3Nxd69e8utNg8PDwwYMEBqs7a2xsSJE5GTk4MDBw7o9e/Tpw9cXV1Nfp0ZM2agsLAQH374YYnLtVotAMDR0dGk7YaGhhq8/0RGRpq0jYEDByItLQ2//fab9N/yOCW1Z88euLq6wtXVFcHBwfjmm28wZMgQ6YhbVcXTUlWESqUy+GVVq9WoXbu2QaBQq9UGc2kA4Omnn9Z77uDgAE9PT+mcNgD89ddfmDFjBhITE6Vf5GLFb6hnz54FAOk0S3m4cOECgHvh7H42NjaoU6eOtPxRtWnTxqgJxT4+PnrPi8PBg6d21Go1dDodNBqN3uHbB/cxADzzzDO4ffs2rl27BgsLC9y6dQsrV64s9RL24sm1Fy5cQN26dQ3+fR/cR8X75sHXtra2Rp06dUod6/1K+vl66qmn9H6OLly4AE9PT4ND6cZesQbc2xfx8fEoKirCyZMnsWPHDnz00UcYNWoU/P390alTp4eur9Vq0bt3b9SqVQtr166V9s21a9eM3q8luXDhAiwsLAzG4uHhgRo1ahj8/D34cwIY7q/SNG7cGA0bNsSGDRuk+WLr16+Hi4sLwsPDpX6HDx/G7NmzceTIEdy+fVtvGxqNxqTgagxj90Hbtm3Rp08fxMTEYOHChWjXrh169eqFgQMHQqlUAgDGjRuHTZs2oVu3bqhVqxa6dOmCfv36oWvXro9c29NPP633hw9w71RW8fL7PXhK3lh16tTBkCFDsHLlSkybNs1guZOTE4B7f/iZwsXFpdSf7YKCAoPT5q6urrC0tNRrCwkJQWBgINavX48aNWrAw8PD5NO7JQkNDcV7770HhUIBOzs71K9fXxZXkTLcVBEP/qCX1S6EMPk1bt26hbZt28LJyQnvvPOOdC+SlJQUvPXWW9DpdCZvs6qp6P1cvA8HDx5c6lwVY+YQlbfSxleRr9eoUSM0atQIYWFhaN++Pb766qsyw83QoUNx+fJlHD16VPqgAcpvvxp75PFxfx4GDx6MadOmITk5GbVr18a+ffswevRoWFnde0s+e/YsOnbsiMDAQCxYsADe3t6wsbHBzp07sXDhwgr9XSxrHxTf9+WXX37B9u3bsXv3bgwfPhzz58/HL7/8AgcHB7i5uSE1NRW7d+/GDz/8gB9++AGrV69GZGSkwSTginD/US9TTZ8+HfHx8Zg3b540/6mYk5MTvLy8cOLEices8H9+/vlntG/fXq8tPT0dfn5+Bn0HDhyI2NhYODo6on///gZh71E8LHhVZQw31ciZM2f0folycnKQmZmJF154AcC9qxX+/fdfbNmyBW3atJH6PThrPiAgAABw4sSJh/5SmHKKqvgKmtOnT+sdbSgoKEB6enqV+eU7c+aMQds///wDOzs76ciIo6MjioqKyhyTr68vTpw4ASGE3r48ffq0Qb/i177/L7m7d+8iPT0dwcHBjzyeB19n3759uH37tt7Rm7S0tMfabvPmzQEAmZmZD+334YcfIiEhAVu2bEFgYKDeMldXV6P3a0l8fX2h0+lw5swZ6WgAcG+S8q1bt0q8wutxDBgwANHR0Vi/fj18fX1RVFSkd0pq+/btyM/Px7Zt2/SOEu3bt69c67ifqfvg2WefxbPPPov3338f69evx6BBg7Bx40bp9LmNjQ0iIiIQEREBnU6HcePGYcWKFZg5c6ZJR/uKa/vjjz+g0+n0PtCLT5WX579PQEAABg8ejBUrViA0NNRgeY8ePbBy5UocOXIEYWFhj/16wcHBBqfvPDw8Suw7cOBAzJo1C5mZmUZfqFFdcc5NNbJy5Uq9c+SxsbEoLCxEt27dAPzvr9H7//osKCjAsmXL9LbTtGlT+Pv7Y9GiRXqXaT+4rr29PQAY9ClJp06dYGNjg08//VRvG1988QU0Gk25XxFQUY4cOaI3tyMjIwPfffcdunTpAktLS1haWqJPnz7YvHlziX/9Xbt2Tfr/F154AZcvX9a7O+rt27cNTrs0b94crq6uWL58OQoKCqT2uLg4o/a9scLDw3H37l29+TE6nU665L8sBw8eLHGORvFcjwdPt93vxx9/xIwZMzB9+nSDv6YBmLRfS1Ic8BctWqTXvmDBAgAo958/Hx8fPP/88/j666+xbt06+Pv76119U9LvokajKXGeWHkxdh/cvHnT4AhVkyZNAEC6ZPzff//VW25hYSEdOSvtVgZl1XblyhV8/fXXUlthYSGWLFkCBwcHtG3b1uRtPsyMGTNw9+5dfPTRRwbL3nzzTdjb22PkyJG4evWqwfKzZ88+9JL3Bz311FPo1KmT3qO0e1EFBARg0aJFmDt3Llq2bGn8gKohHrmpRgoKCtCxY0f069cPp0+fxrJly/Dcc8/hxRdfBAC0atUKTz31FKKiojBx4kQoFArEx8cbvJFZWFggNjYWERERaNKkCYYNGwZPT0/8/fff+Ouvv7B7924AkCbWTpw4EeHh4Q+986qrqyuio6MRExODrl274sUXX5RqbNGixWPdAAsAvv322xLvUNy5c2e4u7s/1rbv17BhQ4SHh+tdCg5A7+67H374Ifbt24fQ0FC88sorCAoKwo0bN5CSkoIff/xROv/+yiuv4LPPPkNkZCSOHTsGT09PxMfHG8x5sba2xnvvvYfRo0ejQ4cO6N+/P9LT07F69Wqj59wYo1evXmjZsiVef/11pKWlITAwENu2bZPqLetI3bx583Ds2DH07t1b+qBLSUnB2rVr4ezs/NBLtQcMGABXV1c8/fTTWLdund6y4n9DY/drSYKDgxEVFYWVK1dKp2ePHj2KNWvWoFevXganDcrD4MGDMWrUKFy+fBnTp0/XW9alSxfpyMfo0aORk5ODVatWwc3NrcwjXA+TlpaG9957z6A9JCQE3bt3N2ofrFmzBsuWLcNLL72EgIAAZGdnY9WqVXBycpIC0siRI3Hjxg106NABtWvXxoULF7BkyRI0adJE76iQsUaNGoUVK1Zg6NChOHbsGPz8/PDtt9/i8OHDWLRokckTfMtSfPSmpFNoAQEBWL9+Pfr374/69evr3aH4559/li5Rryim3EPnp59+KvErHnr16lWucyafSGa4QoseorRLwe3t7Q36tm3bVjRo0MCg/cFLKYu3eeDAATFq1Cjx1FNPCQcHBzFo0CDx77//6q17+PBh8eyzzwpbW1vh5eUl3nzzTbF79269S4+LHTp0SHTu3Fk4OjoKe3t70bhxY7FkyRJpeWFhoXj11VeFq6urUCgURl0W/tlnn4nAwEBhbW0t3N3dxdixYw0uNy+vS8HvH9ODl3w+uO8evOy1pBrw/5djrlu3Tjz99NNCqVSKkJAQg/0mhBBXr14V48ePF97e3sLa2lp4eHiIjh07ipUrV+r1u3DhgnjxxReFnZ2dcHFxEZMmTRK7du0q8d9j2bJlwt/fXyiVStG8eXORlJRkcJlwaZeCl/TzVTzG+127dk0MHDhQODo6CrVaLYYOHSoOHz4sAOjdkqAkhw8fFuPHjxcNGzYUarVaWFtbCx8fHzF06FBx9uxZvb4P1m3Mv6Ep+7Ukd+/eFTExMcLf319YW1sLb29vER0dLd0CoVhpl1Qbe0l2sRs3bgilUikAiJMnTxos37Ztm2jcuLFQqVTCz89PzJs3T3z55ZcCgEhPTzf5dUu7JBmAGDFihNH7ICUlRQwYMED4+PgIpVIp3NzcRI8ePfRugfDtt9+KLl26CDc3N2FjYyN8fHzE6NGjRWZmplF1lrR/r169KoYNGyZcXFyEjY2NaNSokcHtB4y9BNqY1ztz5oywtLQs8X1BCCH++ecf8corrwg/Pz9hY2MjHB0dRevWrcWSJUv09ldZl+A/jLHvdcXvPcWK90Npj/j4+Meu7UmnEOIRZp5SlRIXF4dhw4bht99+k+Y3EJWXhIQEvPTSSzh06BBat25t7nKIiDjnhoiMd/+3HQP37my8ZMkSODk5oWnTpmaqiohIH+fcEJHRXn31Vdy5cwdhYWHIz8/Hli1b8PPPP+ODDz54rMtviYjKE8MNERmtQ4cOmD9/Pnbs2IG8vDzUrVsXS5YswYQJE8xdGhGRhHNuiIiISFY454aIiIhkheGGiIiIZKXazbnR6XS4fPkyHB0dH/kbrImIiKhyCSGQnZ0NLy+vMr9Xq9qFm8uXLxt8wzMRERFVDRkZGahdu/ZD+1S7cFN8m+6MjAy9bxUmIiKiJ5dWq4W3t7dRX7dR7cJN8akoJycnhhsiIqIqxpgpJZxQTERERLLCcENERESywnBDREREssJwQ0RERLLCcENERESywnBDREREssJwQ0RERLLCcENERESywnBDREREslLt7lBMRERAkU7gaPoNZGXnwc1RhZb+zrC04JcJkzww3BARVTO7TmQiZvtJZGrypDZPtQqzI4LQtaGnGSsjKh88LUVEVI3sOpGJsetS9IINAFzR5GHsuhTsOpFppsqIyg/DDRFRNVGkE4jZfhKihGXFbTHbT6JIV1IPoqqD4YaIqJo4mn7D4IjN/QSATE0ejqbfqLyiiCoAww0RUTWRlV16sHmUfkRPKoYbIqJqws1RVa79iJ5UDDdERNVES39neKpVKO2CbwXuXTXV0t+5MssiKncMN0RE1YSlhQKzI4IAwCDgFD+fHRHE+91QlcdwQ0RUjXRt6InYwU3hodY/9eShViF2cFPe54Zkwaw38UtKSsLHH3+MY8eOITMzE1u3bkWvXr1K7b9//360b9/eoD0zMxMeHh4VWCkRkXx0beiJzkEevEMxyZZZw01ubi6Cg4MxfPhw9O7d2+j1Tp8+DScnJ+m5m5tbRZRHRCRblhYKhAXUNHcZRBXCrOGmW7du6Natm8nrubm5oUaNGuVfEBEREVV5VXLOTZMmTeDp6YnOnTvj8OHDD+2bn58PrVar9yAiIiL5qlLhxtPTE8uXL8fmzZuxefNmeHt7o127dkhJSSl1nblz50KtVksPb2/vSqyYiIiIKptCCPFEfImIQqEoc0JxSdq2bQsfHx/Ex8eXuDw/Px/5+fnSc61WC29vb2g0Gr15O0RERPTk0mq1UKvVRn1+m3XOTXlo2bIlDh06VOpypVIJpVJZiRURERGROVWp01IlSU1Nhacn78tARERE95j1yE1OTg7S0tKk5+np6UhNTYWzszN8fHwQHR2NS5cuYe3atQCARYsWwd/fHw0aNEBeXh4+//xzJCYmYs+ePeYaAhERET1hzBpukpOT9W7KN2XKFABAVFQU4uLikJmZiYsXL0rLCwoK8Prrr+PSpUuws7ND48aN8eOPP5Z4Yz8iIiKqnp6YCcWVxZQJSURERPRkMOXzu8rPuSEiIiK6H8MNERERyQrDDREREckKww0RERHJCsMNERERyQrDDREREckKww0RERHJCsMNERERyQrDDREREckKww0RERHJCsMNERERyQrDDREREckKww0RERHJCsMNERERyQrDDREREckKww0RERHJCsMNERERyQrDDREREckKww0RERHJCsMNERERyQrDDREREckKww0RERHJCsMNERERyQrDDREREckKww0RERHJCsMNERERyQrDDREREckKww0RERHJCsMNERERyQrDDREREckKww0RERHJCsMNERERyQrDDREREckKww0RERHJCsMNERERyYpZw01SUhIiIiLg5eUFhUKBhIQEo9c9fPgwrKys0KRJkwqrj4iIiKoes4ab3NxcBAcHY+nSpSatd+vWLURGRqJjx44VVBkRERFVVVbmfPFu3bqhW7duJq83ZswYDBw4EJaWliYd7SEiIiL5q3JzblavXo1z585h9uzZRvXPz8+HVqvVexAREZF8Valwc+bMGUybNg3r1q2DlZVxB53mzp0LtVotPby9vSu4SiIiIjKnKhNuioqKMHDgQMTExOCZZ54xer3o6GhoNBrpkZGRUYFVEhERkbmZdc6NKbKzs5GcnIzjx49jwoQJAACdTgchBKysrLBnzx506NDBYD2lUgmlUlnZ5RIREZGZVJlw4+TkhD///FOvbdmyZUhMTMS3334Lf39/M1VGRERETxKzhpucnBykpaVJz9PT05GamgpnZ2f4+PggOjoaly5dwtq1a2FhYYGGDRvqre/m5gaVSmXQTkRERNWXWcNNcnIy2rdvLz2fMmUKACAqKgpxcXHIzMzExYsXzVUeERERVUEKIYQwdxGVSavVQq1WQ6PRwMnJydzlEBERkRFM+fyuMldLERERERmD4YaIiIhkheGGiIiIZIXhhoiIiGSF4YaIiIhkheGGiIiIZIXhhoiIiGSF4YaIiIhkheGGiIiIZIXhhoiIiGSF4YaIiIhkheGGiIiIZIXhhoiIiGSF4YaIiIhkheGGiIiIZIXhhoiIiGSF4YaIiIhkheGGiIiIZIXhhoiIiGSF4YaIiIhkheGGiIiIZIXhhoiIiGSF4YaIiIhkheGGiIiIZIXhhoiIiGSF4YaIiIhkheGGiIiIZIXhhoiIiGSF4YaIiIhkheGGiIiIZIXhhoiIiGSF4YaIiIhkheGGiIiIZIXhhoiIiGSF4YaIiIhkxazhJikpCREREfDy8oJCoUBCQsJD+x86dAitW7dGzZo1YWtri8DAQCxcuLByiiUiIqIqwcqcL56bm4vg4GAMHz4cvXv3LrO/vb09JkyYgMaNG8Pe3h6HDh3C6NGjYW9vj1GjRlVCxURERPSkUwghhLmLAACFQoGtW7eiV69eJq3Xu3dv2NvbIz4+3qj+Wq0WarUaGo0GTk5Oj1ApERERVTZTPr+r9Jyb48eP4+eff0bbtm1L7ZOfnw+tVqv3ICIiIvmqkuGmdu3aUCqVaN68OcaPH4+RI0eW2nfu3LlQq9XSw9vbuxIrJSIiospWJcPNwYMHkZycjOXLl2PRokXYsGFDqX2jo6Oh0WikR0ZGRiVWSkRERJXNrBOKH5W/vz8AoFGjRrh69SrmzJmDAQMGlNhXqVRCqVRWZnlERERkRlXyyM39dDod8vPzzV0GERERPSHMeuQmJycHaWlp0vP09HSkpqbC2dkZPj4+iI6OxqVLl7B27VoAwNKlS+Hj44PAwEAA9+6T88knn2DixIlmqZ+IiIiePGYNN8nJyWjfvr30fMqUKQCAqKgoxMXFITMzExcvXpSW63Q6REdHIz09HVZWVggICMC8efMwevToSq+diIiInkxPzH1uKgvvc0NERFT1VJv73BARERE9iOGGiIiIZIXhhoiIiGSF4YaIiIhkheGGiIiIZIXhhoiIiGSF4YaIiIhkheGGiIiIZIXhhoiIiGSF4YaIiIhkheGGiIiIZIXhhoiIiGSF4YaIiIhkheGGiIiIZIXhhoiIiGSF4YaIiIhkheGGiIiIZIXhhoiIiGSF4YaIiIhkheGGiIiIZIXhhoiIiGSF4YaIiIhkheGGiIiIZIXhhoiIiGSF4YaIiIhkheGGiIiIZIXhhoiIiGSF4YaIiIhkheGGiIiIZMXkcHPnzh3cvn1ben7hwgUsWrQIe/bsKdfCiIiIiB6FyeGmZ8+eWLt2LQDg1q1bCA0Nxfz589GzZ0/ExsaWe4FEREREpjA53KSkpOD5558HAHz77bdwd3fHhQsXsHbtWnz66aflXiARERGRKUwON7dv34ajoyMAYM+ePejduzcsLCzw7LPP4sKFC+VeIBEREZEpTA43devWRUJCAjIyMrB792506dIFAJCVlQUnJ6dyL5CIiIjIFCaHm1mzZuGNN96An58fQkNDERYWBuDeUZyQkJByL5CIiIjIFCaHm759++LixYtITk7Grl27pPaOHTti4cKFJm0rKSkJERER8PLygkKhQEJCwkP7b9myBZ07d4arqyucnJwQFhaG3bt3mzoEIiIikrFHus+Nh4cHQkJCYGFhAa1Wi4SEBDg6OiIwMNCk7eTm5iI4OBhLly41qn9SUhI6d+6MnTt34tixY2jfvj0iIiJw/PjxRxkGERERyZBCCCFMWaFfv35o06YNJkyYgDt37iA4OBjnz5+HEAIbN25Enz59Hq0QhQJbt25Fr169TFqvQYMG6N+/P2bNmmVUf61WC7VaDY1GwzlCREREVYQpn98mH7lJSkqSLgXfunUrhBC4desWPv30U7z33nuPVvEj0ul0yM7OhrOzc6W+LhERET25TA43Go1GChO7du1Cnz59YGdnh+7du+PMmTPlXuDDfPLJJ8jJyUG/fv1K7ZOfnw+tVqv3ICIiIvkyOdx4e3vjyJEjyM3Nxa5du6RLwW/evAmVSlXuBZZm/fr1iImJwaZNm+Dm5lZqv7lz50KtVksPb2/vSquRiIiIKp/J4Wby5MkYNGgQateuDS8vL7Rr1w7AvdNVjRo1Ku/6SrRx40aMHDkSmzZtQqdOnR7aNzo6GhqNRnpkZGRUSo1ERERkHlamrjBu3Di0bNkSGRkZ6Ny5Myws7uWjOnXqVMqcmw0bNmD48OHYuHEjunfvXmZ/pVIJpVJZ4XURERHRk8HkcAMAzZs3R/PmzSGEgBACCoXCqKDxoJycHKSlpUnP09PTkZqaCmdnZ/j4+CA6OhqXLl2Svqhz/fr1iIqKwuLFixEaGoorV64AAGxtbaFWqx9lKERERCQzj3Sfm7Vr16JRo0awtbWFra0tGjdujPj4eJO3k5ycjJCQEOnOxlOmTEFISIh0WXdmZiYuXrwo9V+5ciUKCwsxfvx4eHp6So9JkyY9yjCIiIhIhky+z82CBQswc+ZMTJgwAa1btwYAHDp0CEuXLsV7772H1157rUIKLS+8zw0REVHVY8rnt8nhxt/fHzExMYiMjNRrX7NmDebMmYP09HTTK65EDDdERERVT4XexC8zMxOtWrUyaG/VqhUyMzNN3RwRERFRuTI53NStWxebNm0yaP/666/x9NNPl0tRRERERI/K5KulYmJi0L9/fyQlJUlzbg4fPoyffvqpxNBDREREVJlMPnLTp08f/Prrr3BxcUFCQgISEhLg4uKCo0eP4qWXXqqIGomIiIiMZvKE4tJkZWXh888/x9tvv10em6swnFBMRERU9VTohOLSZGZmYubMmeW1OSIiIqJHUm7hhoiIiOhJwHBDREREssJwQ0RERLJi9KXgU6ZMeejya9euPXYxRERERI/L6HBz/PjxMvu0adPmsYohIiIielxGh5t9+/ZVZB1ERERE5YJzboiIiEhWGG6IiIhIVhhuiIiISFYYboiIiEhWGG6IiIhIVowONx999BHu3LkjPT98+DDy8/Ol59nZ2Rg3blz5VkdERERkIqO/FdzS0hKZmZlwc3MDADg5OSE1NRV16tQBAFy9ehVeXl4oKiqquGrLAb8VnIiIqOqpkG8FfzADGZmJiIiIiCoV59wQERGRrDDcEBERkawY/fULAPD555/DwcEBAFBYWIi4uDi4uLgAuDehmIiIiMjcjJ5Q7OfnB4VCUWa/9PT0xy6qInFCMRERUdVjyue30Uduzp8//7h1EREREVU4zrkhIiIiWTE63Bw5cgQ7duzQa1u7di38/f3h5uaGUaNG6d3Uj4iIiMgcjA4377zzDv766y/p+Z9//okRI0agU6dOmDZtGrZv3465c+dWSJFERERExjI63KSmpqJjx47S840bNyI0NBSrVq3ClClT8Omnn2LTpk0VUiQRERGRsYwONzdv3oS7u7v0/MCBA+jWrZv0vEWLFsjIyCjf6oiIiIhMZHS4cXd3ly7zLigoQEpKCp599llpeXZ2Nqytrcu/QiIiIiITGB1uXnjhBUybNg0HDx5EdHQ07Ozs8Pzzz0vL//jjDwQEBFRIkURERETGMvo+N++++y569+6Ntm3bwsHBAWvWrIGNjY20/Msvv0SXLl0qpEgiIiIiYxl9h+JiGo0GDg4OsLS01Gu/ceMGHBwc9ALPk4h3KCYiIqp6TPn8Nvkmfmq12iDYAICzs7PJwSYpKQkRERHw8vKCQqFAQkLCQ/tnZmZi4MCBeOaZZ2BhYYHJkyeb9HpEREQkf0aflho+fLhR/b788kujXzw3NxfBwcEYPnw4evfuXWb//Px8uLq6YsaMGVi4cKHRr0NERETVh9HhJi4uDr6+vggJCYGJZ7JK1a1bN73Lycvi5+eHxYsXAzAtRBEREVH1YXS4GTt2LDZs2ID09HQMGzYMgwcPhrOzc0XWRkRERGQyo+fcLF26FJmZmXjzzTexfft2eHt7o1+/fti9e3e5HcmpCPn5+dBqtXoPIiIiki+TJhQrlUoMGDAAe/fuxcmTJ9GgQQOMGzcOfn5+yMnJqagaH8vcuXOhVqulh7e3t7lLIiIiogpk8tVS0ooWFlAoFBBCoKioqDxrKlfR0dHQaDTSg18RQUREJG8mhZv8/Hxs2LABnTt3xjPPPIM///wTn332GS5evAgHB4eKqvGxKJVKODk56T2IiIhIvoyeUDxu3Dhs3LgR3t7eGD58ODZs2AAXF5fHevGcnBykpaVJz9PT05GamgpnZ2f4+PggOjoaly5dwtq1a6U+qamp0rrXrl1DamoqbGxsEBQU9Fi1EBERkTwYfYdiCwsL+Pj4ICQkBAqFotR+W7ZsMfrF9+/fj/bt2xu0R0VFIS4uDkOHDsX58+exf//+/xVcwmv7+vri/PnzRr0m71BMRERU9Zjy+W30kZvIyMiHhppH0a5du4deaRUXF2fQ9iRfmUVERETmZ9JN/IiIiIiedI98tRQRERHRk4jhhoiIiGSF4YaIiIhkheGGiIiIZIXhhoiIiGSF4YaIiIhkheGGiIiIZIXhhoiIiGSF4YaIiIhkheGGiIiIZIXhhoiIiGSF4YaIiIhkheGGiIiIZIXhhoiIiGSF4YaIiIhkheGGiIiIZIXhhoiIiGSF4YaIiIhkheGGiIiIZIXhhoiIiGSF4YaIiIhkheGGiIiIZIXhhoiIiGSF4YaIiIhkheGGiIiIZIXhhoiIiGSF4YaIiIhkheGGiIiIZIXhhoiIiGSF4YaIiIhkheGGiIiIZIXhhoiIiGSF4YaIiIhkheGGiIiIZIXhhoiIiGTFrOEmKSkJERER8PLygkKhQEJCQpnr7N+/H02bNoVSqUTdunURFxdX4XUSERFR1WHWcJObm4vg4GAsXbrUqP7p6eno3r072rdvj9TUVEyePBkjR47E7t27K7hSIiIiqiqszPni3bp1Q7du3Yzuv3z5cvj7+2P+/PkAgPr16+PQoUNYuHAhwsPDK6pMIiIiqkKq1JybI0eOoFOnTnpt4eHhOHLkSKnr5OfnQ6vV6j2IiIhIvqpUuLly5Qrc3d312tzd3aHVanHnzp0S15k7dy7UarX08Pb2roxSiYiIyEyqVLh5FNHR0dBoNNIjIyPD3CURERFRBTLrnBtTeXh44OrVq3ptV69ehZOTE2xtbUtcR6lUQqlUVkZ5RERE9ASoUuEmLCwMO3fu1Gvbu3cvwsLCzFQRERERFSvSCRxNv4Gs7Dy4OarQ0t8ZlhaKSq/DrOEmJycHaWlp0vP09HSkpqbC2dkZPj4+iI6OxqVLl7B27VoAwJgxY/DZZ5/hzTffxPDhw5GYmIhNmzbh+++/N9cQiIiICMCuE5mI2X4SmZo8qc1TrcLsiCB0behZqbWYdc5NcnIyQkJCEBISAgCYMmUKQkJCMGvWLABAZmYmLl68KPX39/fH999/j7179yI4OBjz58/H559/zsvAiYiIzGjXiUyMXZeiF2wA4IomD2PXpWDXicxKrUchhBCV+opmptVqoVarodFo4OTkZO5yiIiIqrQincBz8xINgk0xBQAPtQqH3urwWKeoTPn8lv3VUkRERFRxjqbfKDXYAIAAkKnJw9H0G5VWE8MNERERPbKs7NKDzaP0Kw8MN0RERPTI3BxV5dqvPDDcEBER0SNr6e8MT7UKpc2mUeDeVVMt/Z0rrSaGGyIiInpklhYKzI4IAgCDgFP8fHZEUKXe74bhhoiIiB5L14aeiB3cFB5q/VNPHmoVYgc3rfT73FSpOxQTERHRk6lrQ090DvLgHYqJiIhIPiwtFAgLqGnuMnhaioiIiOSF4YaIiIhkheGGiIiIZIXhhoiIiGSF4YaIiIhkheGGiIiIZIXhhoiIiGSF4YaIiIhkheGGiIiIZIXhhoiIiGSF4YaIiIhkheGGiIiIZIXhhoiIiGSF4YaIiIhkheGGiIiIZIXhhoiIiGSF4YaIiIhkheGGiIiIZIXhhoiIiGSF4YaIiIhkheGGiIiIZIXhhoiIiGSF4YaIiIhkheGGiIiIZIXhhoiIiGSF4YaIiIhkheGGiIiIZOWJCDdLly6Fn58fVCoVQkNDcfTo0VL73r17F++88w4CAgKgUqkQHByMXbt2VWK1RERE9CQze7j5+uuvMWXKFMyePRspKSkIDg5GeHg4srKySuw/Y8YMrFixAkuWLMHJkycxZswYvPTSSzh+/HglV05ERERPIoUQQpizgNDQULRo0QKfffYZAECn08Hb2xuvvvoqpk2bZtDfy8sL06dPx/jx46W2Pn36wNbWFuvWrSvz9bRaLdRqNTQaDZycnMptHEU6gaPpN5CVnQc3RxVa+jvD0kJRbtsnIiKqzkz5/LaqpJpKVFBQgGPHjiE6Olpqs7CwQKdOnXDkyJES18nPz4dKpdJrs7W1xaFDh0rtn5+fLz3XarXlULm+XScyEbP9JDI1eVKbp1qF2RFB6NrQs9xfj4iIiEpn1tNS169fR1FREdzd3fXa3d3dceXKlRLXCQ8Px4IFC3DmzBnodDrs3bsXW7ZsQWZmZon9586dC7VaLT28vb3LdQy7TmRi7LoUvWADAFc0eRi7LgW7TpRcFxEREVUMs8+5MdXixYvx9NNPIzAwEDY2NpgwYQKGDRsGC4uShxIdHQ2NRiM9MjIyyq2WIp1AzPaTKOm8XnFbzPaTKNKZ9cwfERFRtWLWcOPi4gJLS0tcvXpVr/3q1avw8PAocR1XV1ckJCQgNzcXFy5cwN9//w0HBwfUqVOnxP5KpRJOTk56j/JyNP2GwRGb+wkAmZo8HE2/UW6vSURERA9n1nBjY2ODZs2a4aeffpLadDodfvrpJ4SFhT10XZVKhVq1aqGwsBCbN29Gz549K7pcA1nZpQebR+lHREREj8+sE4oBYMqUKYiKikLz5s3RsmVLLFq0CLm5uRg2bBgAIDIyErVq1cLcuXMBAL/++isuXbqEJk2a4NKlS5gzZw50Oh3efPPNSq/dzVFVdicT+hEREdHjM3u46d+/P65du4ZZs2bhypUraNKkCXbt2iVNMr548aLefJq8vDzMmDED586dg4ODA1544QXEx8ejRo0alV57S39neKpVuKLJK3HejQKAh/reZeFERERUOcx+n5vKVt73uSm+WgqAXsApvsNN7OCmvByciIjoMZny+V3lrpZ60nRt6InYwU3hodY/9eShVjHYEBERmYHZT0vJQdeGnugc5ME7FBMRET0BGG7KiaWFAmEBNc1dBhERUbXH01JEREQkKww3REREJCsMN0RERCQrDDdEREQkKww3REREJCsMN0RERCQrDDdEREQkKww3REREJCsMN0RERCQrDDdEREQkKww3REREJCsMN0RERCQrDDdEREQkKww3REREJCsMN0RERCQrDDdEREQkKww3REREJCsMN0RERCQrDDdEREQkKww3REREJCsMN0RERCQrDDdEREQkKww3REREJCsMN0RERCQrDDdEREQkKww3REREJCsMN0RERCQrDDdEREQkKww3REREJCsMN0RERCQrDDdEREQkKww3REREJCtPRLhZunQp/Pz8oFKpEBoaiqNHjz60/6JFi1CvXj3Y2trC29sbr732GvLy8iqpWiIiInqSmT3cfP3115gyZQpmz56NlJQUBAcHIzw8HFlZWSX2X79+PaZNm4bZs2fj1KlT+OKLL/D111/j7bffruTKiYiI6Elk9nCzYMECvPLKKxg2bBiCgoKwfPly2NnZ4csvvyyx/88//4zWrVtj4MCB8PPzQ5cuXTBgwIAyj/YQERFR9WDWcFNQUIBjx46hU6dOUpuFhQU6deqEI0eOlLhOq1atcOzYMSnMnDt3Djt37sQLL7xQYv/8/HxotVq9B1FVUaQTOHL2X3yXeglHzv6LIp0wd0lERE88K3O++PXr11FUVAR3d3e9dnd3d/z9998lrjNw4EBcv34dzz33HIQQKCwsxJgxY0o9LTV37lzExMSUe+1EFW3XiUzEbD+JTM3/5pN5qlWYHRGErg09zVgZEdGTzeynpUy1f/9+fPDBB1i2bBlSUlKwZcsWfP/993j33XdL7B8dHQ2NRiM9MjIyKrliItPtOpGJsetS9IINAFzR5GHsuhTsOpFppsqIiJ58Zj1y4+LiAktLS1y9elWv/erVq/Dw8ChxnZkzZ2LIkCEYOXIkAKBRo0bIzc3FqFGjMH36dFhY6Oc1pVIJpVJZMQMgqgBFOoGY7SdR0gkoAUABIGb7SXQO8oClhaKSqyMievKZ9ciNjY0NmjVrhp9++klq0+l0+OmnnxAWFlbiOrdv3zYIMJaWlgAAITgfgaq+o+k3DI7Y3E8AyNTk4Wj6jcorioioCjHrkRsAmDJlCqKiotC8eXO0bNkSixYtQm5uLoYNGwYAiIyMRK1atTB37lwAQEREBBYsWICQkBCEhoYiLS0NM2fOREREhBRyiKqyrGzj7tlkbD8iourG7OGmf//+uHbtGmbNmoUrV66gSZMm2LVrlzTJ+OLFi3pHambMmAGFQoEZM2bg0qVLcHV1RUREBN5//31zDYGoXLk5qsq1HxFRdaMQ1excjlarhVqthkajgZOTk7nLITJQpBN4bl4irmjySpx3owDgoVbh0FsdOOeGiKoNUz6/q9zVUkRyZ2mhwOyIIAD3gsz9ip/PjghisCEiKgXDDdETqGtDT8QObgoPtf6pJw+1CrGDm/I+N0RED2H2OTdEVLKuDT3ROcgDR9NvICs7D26OKrT0d+YRGyKiMjDcED3BLC0UCAuoae4yiIiqFJ6WIiIiIllhuCEiIiJZYbghIiIiWWG4ISIiIllhuCEiIiJZYbghIiIiWWG4ISIiIllhuCEiIiJZYbghIiIiWal2dygu/hJ0rVZr5kqIiIjIWMWf28Wf4w9T7cJNdnY2AMDb29vMlRAREZGpsrOzoVarH9pHIYyJQDKi0+lw+fJlODo6QqGQxxcQarVaeHt7IyMjA05OTuYup8JxvPLG8cpfdRszx1s+hBDIzs6Gl5cXLCwePqum2h25sbCwQO3atc1dRoVwcnKqFr84xTheeeN45a+6jZnjfXxlHbEpxgnFREREJCsMN0RERCQrDDcyoFQqMXv2bCiVSnOXUik4XnnjeOWvuo2Z46181W5CMREREckbj9wQERGRrDDcEBERkaww3BAREZGsMNwQERGRrDDcVCGXLl3C4MGDUbNmTdja2qJRo0ZITk6WlgshMGvWLHh6esLW1hadOnXCmTNnzFjxoysqKsLMmTPh7+8PW1tbBAQE4N1339X7TpGqPt6kpCRERETAy8sLCoUCCQkJesuNGd+NGzcwaNAgODk5oUaNGhgxYgRycnIqcRTGe9h47969i7feeguNGjWCvb09vLy8EBkZicuXL+ttQy7jfdCYMWOgUCiwaNEivXa5jffUqVN48cUXoVarYW9vjxYtWuDixYvS8ry8PIwfPx41a9aEg4MD+vTpg6tXr1biKIxX1nhzcnIwYcIE1K5dG7a2tggKCsLy5cv1+lSl8c6dOxctWrSAo6Mj3Nzc0KtXL5w+fVqvjzHjuXjxIrp37w47Ozu4ublh6tSpKCwsLPd6GW6qiJs3b6J169awtrbGDz/8gJMnT2L+/Pl46qmnpD4fffQRPv30Uyxfvhy//vor7O3tER4ejry8PDNW/mjmzZuH2NhYfPbZZzh16hTmzZuHjz76CEuWLJH6VPXx5ubmIjg4GEuXLi1xuTHjGzRoEP766y/s3bsXO3bsQFJSEkaNGlVZQzDJw8Z7+/ZtpKSkYObMmUhJScGWLVtw+vRpvPjii3r95DLe+23duhW//PILvLy8DJbJabxnz57Fc889h8DAQOzfvx9//PEHZs6cCZVKJfV57bXXsH37dnzzzTc4cOAALl++jN69e1fWEExS1ninTJmCXbt2Yd26dTh16hQmT56MCRMmYNu2bVKfqjTeAwcOYPz48fjll1+wd+9e3L17F126dEFubq7Up6zxFBUVoXv37igoKMDPP/+MNWvWIC4uDrNmzSr/ggVVCW+99ZZ47rnnSl2u0+mEh4eH+Pjjj6W2W7duCaVSKTZs2FAZJZar7t27i+HDh+u19e7dWwwaNEgIIb/xAhBbt26VnhszvpMnTwoA4rfffpP6/PDDD0KhUIhLly5VWu2P4sHxluTo0aMCgLhw4YIQQp7j/e9//ytq1aolTpw4IXx9fcXChQulZXIbb//+/cXgwYNLXefWrVvC2tpafPPNN1LbqVOnBABx5MiRiiq1XJQ03gYNGoh33nlHr61p06Zi+vTpQoiqPV4hhMjKyhIAxIEDB4QQxo1n586dwsLCQly5ckXqExsbK5ycnER+fn651scjN1XEtm3b0Lx5c/znP/+Bm5sbQkJCsGrVKml5eno6rly5gk6dOkltarUaoaGhOHLkiDlKfiytWrXCTz/9hH/++QcA8Pvvv+PQoUPo1q0bAPmN90HGjO/IkSOoUaMGmjdvLvXp1KkTLCws8Ouvv1Z6zeVNo9FAoVCgRo0aAOQ3Xp1OhyFDhmDq1Klo0KCBwXI5jVen0+H777/HM888g/DwcLi5uSE0NFTvVM6xY8dw9+5dvZ/5wMBA+Pj4VMnf6VatWmHbtm24dOkShBDYt28f/vnnH3Tp0gVA1R+vRqMBADg7OwMwbjxHjhxBo0aN4O7uLvUJDw+HVqvFX3/9Va71MdxUEefOnUNsbCyefvpp7N69G2PHjsXEiROxZs0aAMCVK1cAQO+Hpvh58bKqZNq0aXj55ZcRGBgIa2trhISEYPLkyRg0aBAA+Y33QcaM78qVK3Bzc9NbbmVlBWdn5yq/D/Ly8vDWW29hwIAB0hfvyW288+bNg5WVFSZOnFjicjmNNysrCzk5Ofjwww/RtWtX7NmzBy+99BJ69+6NAwcOALg3XhsbGynMFquqv9NLlixBUFAQateuDRsbG3Tt2hVLly5FmzZtAFTt8ep0OkyePBmtW7dGw4YNARg3nitXrpT4nla8rDxVu28Fr6p0Oh2aN2+ODz74AAAQEhKCEydOYPny5YiKijJzdeVv06ZN+Oqrr7B+/Xo0aNAAqampmDx5Mry8vGQ5Xvqfu3fvol+/fhBCIDY21tzlVIhjx45h8eLFSElJgUKhMHc5FU6n0wEAevbsiddeew0A0KRJE/z8889Yvnw52rZta87yKsSSJUvwyy+/YNu2bfD19UVSUhLGjx8PLy8vvaMbVdH48eNx4sQJHDp0yNyllIpHbqoIT09PBAUF6bXVr19futLAw8MDAAxmpl+9elVaVpVMnTpVOnrTqFEjDBkyBK+99hrmzp0LQH7jfZAx4/Pw8EBWVpbe8sLCQty4caPK7oPiYHPhwgXs3btXOmoDyGu8Bw8eRFZWFnx8fGBlZQUrKytcuHABr7/+Ovz8/ADIa7wuLi6wsrIq8z2soKAAt27d0utTFX+n79y5g7fffhsLFixAREQEGjdujAkTJqB///745JNPAFTd8U6YMAE7duzAvn37ULt2bandmPF4eHiU+J5WvKw8MdxUEa1btza47O6ff/6Br68vAMDf3x8eHh746aefpOVarRa//vorwsLCKrXW8nD79m1YWOj/eFpaWkp/AcptvA8yZnxhYWG4desWjh07JvVJTEyETqdDaGhopdf8uIqDzZkzZ/Djjz+iZs2aesvlNN4hQ4bgjz/+QGpqqvTw8vLC1KlTsXv3bgDyGq+NjQ1atGjx0PewZs2awdraWu9n/vTp07h48WKV+52+e/cu7t69+9D3sKo2XiEEJkyYgK1btyIxMRH+/v56y40ZT1hYGP7880+90F78R8yDwbc8CqYq4OjRo8LKykq8//774syZM+Krr74SdnZ2Yt26dVKfDz/8UNSoUUN899134o8//hA9e/YU/v7+4s6dO2as/NFERUWJWrVqiR07doj09HSxZcsW4eLiIt58802pT1Ufb3Z2tjh+/Lg4fvy4ACAWLFggjh8/Ll0dZMz4unbtKkJCQsSvv/4qDh06JJ5++mkxYMAAcw3poR423oKCAvHiiy+K2rVri9TUVJGZmSk97r+KQi7jLcmDV0sJIa/xbtmyRVhbW4uVK1eKM2fOiCVLlghLS0tx8OBBaRtjxowRPj4+IjExUSQnJ4uwsDARFhZmriE9VFnjbdu2rWjQoIHYt2+fOHfunFi9erVQqVRi2bJl0jaq0njHjh0r1Gq12L9/v97v5+3bt6U+ZY2nsLBQNGzYUHTp0kWkpqaKXbt2CVdXVxEdHV3u9TLcVCHbt28XDRs2FEqlUgQGBoqVK1fqLdfpdGLmzJnC3d1dKJVK0bFjR3H69GkzVft4tFqtmDRpkvDx8REqlUrUqVNHTJ8+Xe+DrqqPd9++fQKAwSMqKkoIYdz4/v33XzFgwADh4OAgnJycxLBhw0R2drYZRlO2h403PT29xGUAxL59+6RtyGW8JSkp3MhtvF988YWoW7euUKlUIjg4WCQkJOht486dO2LcuHHiqaeeEnZ2duKll14SmZmZlTwS45Q13szMTDF06FDh5eUlVCqVqFevnpg/f77Q6XTSNqrSeEv7/Vy9erXUx5jxnD9/XnTr1k3Y2toKFxcX8frrr4u7d++We72K/y+aiIiISBY454aIiIhkheGGiIiIZIXhhoiIiGSF4YaIiIhkheGGiIiIZIXhhoiIiGSF4YaIiIhkheGGiMrVnDlz0KRJk3Lf7vnz56FQKJCamlpqn/3790OhUEjfbxMXF2fwLcXm0q5dO0yePNncZRBVCww3RNXU0KFDoVAoDB5du3Y1d2nlpn///vjnn38q/HWKiorw4YcfIjAwELa2tnB2dkZoaCg+//xzqc+WLVvw7rvvVngtRARYmbsAIjKfrl27YvXq1XptSqXSTNWUP1tbW9ja2lb468TExGDFihX47LPP0Lx5c2i1WiQnJ+PmzZtSH2dn5wqvg4ju4ZEbompMqVTCw8ND7/HUU09JyxUKBVasWIEePXrAzs4O9evXx5EjR5CWloZ27drB3t4erVq1wtmzZw22vWLFCnh7e8POzg79+vWDRqPRW/7555+jfv36UKlUCAwMxLJly/SWHz16FCEhIVCpVGjevDmOHz9u8Bo7d+7EM888A1tbW7Rv3x7nz5/XW/7gaaniU2bx8fHw8/ODWq3Gyy+/jOzsbKlPdnY2Bg0aBHt7e3h6emLhwoVlnlLatm0bxo0bh//85z/w9/dHcHAwRowYgTfeeEPqc/82ik+fPfgYOnSo1P+7775D06ZNoVKpUKdOHcTExKCwsLDUGojofxhuiOih3n33XURGRiI1NRWBgYEYOHAgRo8ejejoaCQnJ0MIgQkTJuitk5aWhk2bNmH79u3YtWsXjh8/jnHjxknLv/rqK8yaNQvvv/8+Tp06hQ8++AAzZ87EmjVrAAA5OTno0aMHgoKCcOzYMcyZM0cvKABARkYGevfujYiICKSmpmLkyJGYNm1ameM5e/YsEhISsGPHDuzYsQMHDhzAhx9+KC2fMmUKDh8+jG3btmHv3r04ePAgUlJSHrpNDw8PJCYm4tq1a2W+PgC0atUKmZmZ0iMxMREqlQpt2rQBABw8eBCRkZGYNGkSTp48iRUrViAuLg7vv/++UdsnqvbK/as4iahKiIqKEpaWlsLe3l7v8f7770t9AIgZM2ZIz48cOSIAiC+++EJq27Bhg1CpVNLz2bNnC0tLS/Hf//5Xavvhhx+EhYWF9A3BAQEBYv369Xr1vPvuuyIsLEwIIcSKFStEzZo1xZ07d6TlsbGxAoA4fvy4EEKI6OhoERQUpLeNt956SwAQN2/eFEIIsXr1aqFWq/Vqs7OzE1qtVmqbOnWqCA0NFULc+zZ6a2tr8c0330jLb926Jezs7MSkSZNK3Zd//fWXqF+/vrCwsBCNGjUSo0ePFjt37tTr07Zt2xK3cf36dVGnTh0xbtw4qa1jx47igw8+0OsXHx8vPD09S62BiP6Hc26IqrH27dsjNjZWr+3BuSGNGzeW/t/d3R0A0KhRI722vLw8aLVaODk5AQB8fHxQq1YtqU9YWBh0Oh1Onz4NR0dHnD17FiNGjMArr7wi9SksLIRarQYAnDp1Co0bN4ZKpdLbxv1OnTqF0NBQvbYH+5TEz88Pjo6O0nNPT09kZWUBAM6dO4e7d++iZcuW0nK1Wo169eo9dJtBQUE4ceIEjh07hsOHDyMpKQkREREYOnSo3qTiB929exd9+vSBr68vFi9eLLX//vvvOHz4sN6RmqKiIuTl5eH27duws7Mrc5xE1RnDDVE1Zm9vj7p16z60j7W1tfT/CoWi1DadTmfUa+bk5AAAVq1aZRBOLC0tjdrG47i/duBe/cbW/jAWFhZo0aIFWrRogcmTJ2PdunUYMmQIpk+fDn9//xLXGTt2LDIyMnD06FFYWf3v7TgnJwcxMTHo3bu3wTr3Bz4iKhnDDRGVu4sXL+Ly5cvw8vICAPzyyy+wsLBAvXr14O7uDi8vL5w7dw6DBg0qcf369esjPj4eeXl50of5L7/8YtBn27Ztem0P9jFVnTp1YG1tjd9++w0+Pj4AAI1Gg3/++UeaD2OsoKAgAEBubm6JyxcsWIBNmzbh559/Rs2aNfWWNW3aFKdPny4zeBJRyRhuiKqx/Px8XLlyRa/NysoKLi4uj7VdlUqFqKgofPLJJ9BqtZg4cSL69esHDw8PAPcunZ44cSLUajW6du2K/Px86dLpKVOmYODAgZg+fTpeeeUVREdH4/z58/jkk0/0XmPMmDGYP38+pk6dipEjR+LYsWOIi4t7rLodHR0RFRWFqVOnwtnZGW5ubpg9ezYsLCykI1Ql6du3L1q3bo1WrVrBw8MD6enpiI6OxjPPPIPAwECD/j/++CPefPNNLF26FC4uLtK/ga2tLdRqNWbNmoUePXrAx8cHffv2hYWFBX7//XecOHEC77333mONkag64NVSRNXYrl274Onpqfd47rnnHnu7devWRe/evfHCCy+gS5cuaNy4sd6l3iNHjsTnn3+O1atXo1GjRmjbti3i4uKk0zcODg7Yvn07/vzzT4SEhGD69OmYN2+e3mv4+Phg8+bNSEhIQHBwMJYvX44PPvjgsWtfsGABwsLC0KNHD3Tq1AmtW7eWLlkvTXh4OLZv346IiAg888wziIqKQmBgIPbs2aN3uqnYoUOHUFRUhDFjxujt+0mTJknb27FjB/bs2YMWLVrg2WefxcKFC+Hr6/vY4yOqDhRCCGHuIoiInlS5ubmoVasW5s+fjxEjRpi7HCIyAk9LERHd5/jx4/j777/RsmVLaDQavPPOOwCAnj17mrkyIjIWww0R0QM++eQTnD59GjY2NmjWrBkOHjz42POQiKjy8LQUERERyQonFBMREZGsMNwQERGRrDDcEBERkaww3BAREZGsMNwQERGRrDDcEBERkaww3BAREZGsMNwQERGRrDDcEBERkaz8H3M7K3MlVQCKAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the chart above, it can be seen that for NCF-MLP there was a general increase in the MSE loss as the embedding size increased, but it then jumped back down again for a large embedding size. This suggests that at certain intermediate sizes, there could be overfitting that's occuring which leads to increased MSE loss."
      ],
      "metadata": {
        "id": "gwiQTGyGQJBg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Changing hidden layer size\n",
        "hidden_layers = [10, 20, 30, 40]\n",
        "val_loss_results = []\n",
        "for hidden_size in hidden_layers:\n",
        "    model = my_NCF_MLP(num_users, num_items, emb_size=100, hidden_size=hidden_size)\n",
        "    print(f\"===== Hidden Layer Size of {hidden_size} =====\")\n",
        "    val_loss_result = train_epocs(model, epochs=10, lr=0.1, wd=0.0)\n",
        "    val_loss_results.append((val_loss_result))\n",
        "plt.figure()\n",
        "plt.scatter(hidden_layers, val_loss_results, marker='o')  # Line plot with circle markers\n",
        "plt.title(\"Impact of Hidden Layer Size on Val Loss for NCF-MLP\")\n",
        "plt.xlabel(\"Hidden Layer Size\")\n",
        "plt.ylabel(\"MSE Loss\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "561a7f0d-0b94-4cfa-cb48-6706d03f68ea",
        "id": "GCC9rkVhJ9p_"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== Hidden Layer Size of 10 =====\n",
            "Epoch 0: Training loss: 12.9803  Validation Loss: 5.2135\n",
            "Epoch 1: Training loss: 5.1727  Validation Loss: 27.0276\n",
            "Epoch 2: Training loss: 27.1880  Validation Loss: 1.3758\n",
            "Epoch 3: Training loss: 1.3642  Validation Loss: 4.0663\n",
            "Epoch 4: Training loss: 3.9822  Validation Loss: 7.1192\n",
            "Epoch 5: Training loss: 7.0364  Validation Loss: 6.2785\n",
            "Epoch 6: Training loss: 6.3063  Validation Loss: 4.5607\n",
            "Epoch 7: Training loss: 5.0140  Validation Loss: 2.8213\n",
            "Epoch 8: Training loss: 3.1617  Validation Loss: 1.1998\n",
            "Epoch 9: Training loss: 1.2368  Validation Loss: 1.0647\n",
            "test loss 1.065 \n",
            "===== Hidden Layer Size of 20 =====\n",
            "Epoch 0: Training loss: 13.5105  Validation Loss: 8.8966\n",
            "Epoch 1: Training loss: 8.8295  Validation Loss: 12.6079\n",
            "Epoch 2: Training loss: 12.7464  Validation Loss: 1.0836\n",
            "Epoch 3: Training loss: 1.0783  Validation Loss: 4.9246\n",
            "Epoch 4: Training loss: 4.8616  Validation Loss: 5.9688\n",
            "Epoch 5: Training loss: 5.8905  Validation Loss: 4.0147\n",
            "Epoch 6: Training loss: 3.9384  Validation Loss: 1.4315\n",
            "Epoch 7: Training loss: 1.3570  Validation Loss: 1.2394\n",
            "Epoch 8: Training loss: 1.1443  Validation Loss: 2.6362\n",
            "Epoch 9: Training loss: 2.4892  Validation Loss: 0.8749\n",
            "test loss 0.875 \n",
            "===== Hidden Layer Size of 30 =====\n",
            "Epoch 0: Training loss: 13.9219  Validation Loss: 5.7820\n",
            "Epoch 1: Training loss: 5.7398  Validation Loss: 58.8815\n",
            "Epoch 2: Training loss: 59.0855  Validation Loss: 1.1856\n",
            "Epoch 3: Training loss: 1.1993  Validation Loss: 7.8826\n",
            "Epoch 4: Training loss: 7.8419  Validation Loss: 9.6322\n",
            "Epoch 5: Training loss: 9.6422  Validation Loss: 7.8994\n",
            "Epoch 6: Training loss: 8.1843  Validation Loss: 5.0729\n",
            "Epoch 7: Training loss: 5.3017  Validation Loss: 2.6725\n",
            "Epoch 8: Training loss: 2.8906  Validation Loss: 7.9504\n",
            "Epoch 9: Training loss: 7.8038  Validation Loss: 10.3669\n",
            "test loss 10.367 \n",
            "===== Hidden Layer Size of 40 =====\n",
            "Epoch 0: Training loss: 12.3380  Validation Loss: 4.5918\n",
            "Epoch 1: Training loss: 4.5586  Validation Loss: 79.2082\n",
            "Epoch 2: Training loss: 79.4311  Validation Loss: 1.7630\n",
            "Epoch 3: Training loss: 1.7906  Validation Loss: 9.0383\n",
            "Epoch 4: Training loss: 9.0219  Validation Loss: 4.2660\n",
            "Epoch 5: Training loss: 4.5575  Validation Loss: 20.8550\n",
            "Epoch 6: Training loss: 21.9307  Validation Loss: 1.7605\n",
            "Epoch 7: Training loss: 1.9342  Validation Loss: 8.7818\n",
            "Epoch 8: Training loss: 8.7052  Validation Loss: 11.3893\n",
            "Epoch 9: Training loss: 11.2992  Validation Loss: 2.8350\n",
            "test loss 2.835 \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similar to the embedding size, there was a general increase in the MSE loss as the hidden layer size increased, but it then jumped back down again for a large hidden layer size. This suggests that at certain intermediate sizes, there could be overfitting that's occuring which leads to increased MSE loss.\n"
      ],
      "metadata": {
        "id": "1X44Ue-3S3fU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Changing regularization\n",
        "wds = [0.0, 0.01, 0.05, 0.1]\n",
        "val_loss_results = []\n",
        "for wd in wds:\n",
        "    model = my_NCF_MLP(num_users, num_items, emb_size=100, hidden_size=10)\n",
        "    print(f\"===== Regularization of {wd} =====\")\n",
        "    val_loss_result = train_epocs(model, epochs=10, lr=0.1, wd=wd)\n",
        "    val_loss_results.append((val_loss_result))\n",
        "plt.figure()\n",
        "plt.scatter(wds, val_loss_results, marker='o')  # Line plot with circle markers\n",
        "plt.title(\"Impact of Regularization on Val Loss for NCF-MLP\")\n",
        "plt.xlabel(\"Regularization\")\n",
        "plt.ylabel(\"MSE Loss\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RPxydYywLNOO",
        "outputId": "8125ac98-8641-4f5c-aa51-ccd59b11b62e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== Regularization of 0.0 =====\n",
            "Epoch 0: Training loss: 13.7428  Validation Loss: 9.0069\n",
            "Epoch 1: Training loss: 8.9385  Validation Loss: 4.0488\n",
            "Epoch 2: Training loss: 4.1341  Validation Loss: 1.3067\n",
            "Epoch 3: Training loss: 1.2811  Validation Loss: 1.4234\n",
            "Epoch 4: Training loss: 1.3554  Validation Loss: 2.0963\n",
            "Epoch 5: Training loss: 2.0034  Validation Loss: 1.2874\n",
            "Epoch 6: Training loss: 1.1626  Validation Loss: 1.2598\n",
            "Epoch 7: Training loss: 1.0760  Validation Loss: 1.6982\n",
            "Epoch 8: Training loss: 1.4835  Validation Loss: 0.9265\n",
            "Epoch 9: Training loss: 0.7399  Validation Loss: 1.1011\n",
            "test loss 1.101 \n",
            "===== Regularization of 0.01 =====\n",
            "Epoch 0: Training loss: 14.6178  Validation Loss: 14.6890\n",
            "Epoch 1: Training loss: 14.5831  Validation Loss: 10.4315\n",
            "Epoch 2: Training loss: 10.2606  Validation Loss: 9.5845\n",
            "Epoch 3: Training loss: 10.1883  Validation Loss: 1.8608\n",
            "Epoch 4: Training loss: 1.9193  Validation Loss: 2.6200\n",
            "Epoch 5: Training loss: 2.5832  Validation Loss: 3.9736\n",
            "Epoch 6: Training loss: 3.9167  Validation Loss: 3.4062\n",
            "Epoch 7: Training loss: 3.3410  Validation Loss: 2.4655\n",
            "Epoch 8: Training loss: 2.4458  Validation Loss: 2.3577\n",
            "Epoch 9: Training loss: 2.4011  Validation Loss: 1.9966\n",
            "test loss 1.997 \n",
            "===== Regularization of 0.05 =====\n",
            "Epoch 0: Training loss: 11.7017  Validation Loss: 12.1076\n",
            "Epoch 1: Training loss: 12.0158  Validation Loss: 8.8229\n",
            "Epoch 2: Training loss: 8.7580  Validation Loss: 8.1510\n",
            "Epoch 3: Training loss: 8.0962  Validation Loss: 3.8867\n",
            "Epoch 4: Training loss: 3.8729  Validation Loss: 1.1863\n",
            "Epoch 5: Training loss: 1.2121  Validation Loss: 1.3784\n",
            "Epoch 6: Training loss: 1.4146  Validation Loss: 2.9426\n",
            "Epoch 7: Training loss: 2.9179  Validation Loss: 1.9760\n",
            "Epoch 8: Training loss: 2.0018  Validation Loss: 1.2415\n",
            "Epoch 9: Training loss: 1.2773  Validation Loss: 1.4259\n",
            "test loss 1.426 \n",
            "===== Regularization of 0.1 =====\n",
            "Epoch 0: Training loss: 12.5277  Validation Loss: 13.7867\n",
            "Epoch 1: Training loss: 13.6850  Validation Loss: 11.0903\n",
            "Epoch 2: Training loss: 11.0092  Validation Loss: 2.4711\n",
            "Epoch 3: Training loss: 2.4709  Validation Loss: 6.0786\n",
            "Epoch 4: Training loss: 6.1988  Validation Loss: 1.0068\n",
            "Epoch 5: Training loss: 1.0126  Validation Loss: 4.8056\n",
            "Epoch 6: Training loss: 4.7642  Validation Loss: 6.4387\n",
            "Epoch 7: Training loss: 6.3854  Validation Loss: 4.6400\n",
            "Epoch 8: Training loss: 4.6088  Validation Loss: 2.0694\n",
            "Epoch 9: Training loss: 2.0759  Validation Loss: 1.2280\n",
            "test loss 1.228 \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the experiments, it can be seen that introducing regularization initially increases the MSE Loss but as we increase the regularization, the loss decreases. This is likely because when regularization is added, it restricts from fitting the data as closely as it could without regularization, which would lead to an increase in MSE loss but with higher regularization, it allows the model to generalize better which would lead to a decrease in the MSE loss."
      ],
      "metadata": {
        "id": "CyllcRmnTYrp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hyperparameter tuning experiments"
      ],
      "metadata": {
        "id": "1y02Ns9uJwdZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "i = 0\n",
        "for wd in [0.0, 0.01, 0.05, 0.1]:\n",
        "    for emb_size in [50, 100, 150, 200]:\n",
        "        for hidden_size in [10, 20, 30, 40]:\n",
        "            print(f\"===== Experiment {i} =====\")\n",
        "            print(f\"wd: {wd}, emb_size: {emb_size}, hidden_size: {hidden_size}\")\n",
        "            model = my_NCF_MLP(num_users, num_items, emb_size=emb_size, hidden_size=hidden_size)\n",
        "            test_loss_result = train_epocs(model, epochs=10, lr=0.1, wd=wd)\n",
        "            results.append((wd, emb_size, hidden_size, test_loss_result))\n",
        "            i += 1\n",
        "print(\"====== Best Performing Model ======\")\n",
        "best_res_idx = results.index(min(results, key=lambda x: x[3]))\n",
        "print(f\"Best result: {results[best_res_idx][3]}\")\n",
        "print(f\"Best hyperparameters: wd={results[best_res_idx][0]}, emb_size={results[best_res_idx][1]}, hidden_size={results[best_res_idx][2]}\")"
      ],
      "metadata": {
        "id": "2PiqtnB22qfC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46c3222a-7473-4888-c239-d3040d4b6abc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== Experiment 0 =====\n",
            "wd: 0.0, emb_size: 50, hidden_size: 10\n",
            "Epoch 0: Training loss: 11.7755  Validation Loss: 8.4260\n",
            "Epoch 1: Training loss: 8.3618  Validation Loss: 1.6230\n",
            "Epoch 2: Training loss: 1.6295  Validation Loss: 8.8421\n",
            "Epoch 3: Training loss: 8.8802  Validation Loss: 1.4802\n",
            "Epoch 4: Training loss: 1.4659  Validation Loss: 2.2385\n",
            "Epoch 5: Training loss: 2.1807  Validation Loss: 4.1029\n",
            "Epoch 6: Training loss: 4.0187  Validation Loss: 3.1165\n",
            "Epoch 7: Training loss: 3.0448  Validation Loss: 1.4820\n",
            "Epoch 8: Training loss: 1.4513  Validation Loss: 1.0204\n",
            "Epoch 9: Training loss: 1.0360  Validation Loss: 1.5209\n",
            "test loss 1.521 \n",
            "===== Experiment 1 =====\n",
            "wd: 0.0, emb_size: 50, hidden_size: 20\n",
            "Epoch 0: Training loss: 12.7438  Validation Loss: 7.3986\n",
            "Epoch 1: Training loss: 7.3412  Validation Loss: 10.6434\n",
            "Epoch 2: Training loss: 10.7663  Validation Loss: 1.0404\n",
            "Epoch 3: Training loss: 1.0315  Validation Loss: 2.5003\n",
            "Epoch 4: Training loss: 2.4457  Validation Loss: 4.4668\n",
            "Epoch 5: Training loss: 4.3988  Validation Loss: 4.3351\n",
            "Epoch 6: Training loss: 4.2641  Validation Loss: 2.9962\n",
            "Epoch 7: Training loss: 2.9175  Validation Loss: 1.1544\n",
            "Epoch 8: Training loss: 1.0463  Validation Loss: 1.7116\n",
            "Epoch 9: Training loss: 1.5356  Validation Loss: 2.6747\n",
            "test loss 2.675 \n",
            "===== Experiment 2 =====\n",
            "wd: 0.0, emb_size: 50, hidden_size: 30\n",
            "Epoch 0: Training loss: 11.8954  Validation Loss: 6.2758\n",
            "Epoch 1: Training loss: 6.2265  Validation Loss: 7.9483\n",
            "Epoch 2: Training loss: 8.0432  Validation Loss: 1.0524\n",
            "Epoch 3: Training loss: 1.0341  Validation Loss: 2.9975\n",
            "Epoch 4: Training loss: 2.9375  Validation Loss: 3.4706\n",
            "Epoch 5: Training loss: 3.3918  Validation Loss: 2.1537\n",
            "Epoch 6: Training loss: 2.0676  Validation Loss: 0.8014\n",
            "Epoch 7: Training loss: 0.7161  Validation Loss: 2.1824\n",
            "Epoch 8: Training loss: 2.0326  Validation Loss: 1.3241\n",
            "Epoch 9: Training loss: 1.1556  Validation Loss: 1.3668\n",
            "test loss 1.367 \n",
            "===== Experiment 3 =====\n",
            "wd: 0.0, emb_size: 50, hidden_size: 40\n",
            "Epoch 0: Training loss: 12.8944  Validation Loss: 7.2555\n",
            "Epoch 1: Training loss: 7.2029  Validation Loss: 8.9519\n",
            "Epoch 2: Training loss: 9.0643  Validation Loss: 1.0596\n",
            "Epoch 3: Training loss: 1.0454  Validation Loss: 3.4701\n",
            "Epoch 4: Training loss: 3.4049  Validation Loss: 3.7518\n",
            "Epoch 5: Training loss: 3.6678  Validation Loss: 1.8299\n",
            "Epoch 6: Training loss: 1.7337  Validation Loss: 1.0077\n",
            "Epoch 7: Training loss: 0.8862  Validation Loss: 2.4910\n",
            "Epoch 8: Training loss: 2.3110  Validation Loss: 0.9680\n",
            "Epoch 9: Training loss: 0.7708  Validation Loss: 1.5676\n",
            "test loss 1.568 \n",
            "===== Experiment 4 =====\n",
            "wd: 0.0, emb_size: 100, hidden_size: 10\n",
            "Epoch 0: Training loss: 11.2032  Validation Loss: 7.5098\n",
            "Epoch 1: Training loss: 7.4508  Validation Loss: 2.6718\n",
            "Epoch 2: Training loss: 2.7411  Validation Loss: 0.8505\n",
            "Epoch 3: Training loss: 0.8116  Validation Loss: 0.9151\n",
            "Epoch 4: Training loss: 0.8256  Validation Loss: 0.9303\n",
            "Epoch 5: Training loss: 0.8028  Validation Loss: 0.8986\n",
            "Epoch 6: Training loss: 0.7377  Validation Loss: 1.0816\n",
            "Epoch 7: Training loss: 0.9196  Validation Loss: 0.8988\n",
            "Epoch 8: Training loss: 0.7195  Validation Loss: 0.7938\n",
            "Epoch 9: Training loss: 0.6347  Validation Loss: 1.0120\n",
            "test loss 1.012 \n",
            "===== Experiment 5 =====\n",
            "wd: 0.0, emb_size: 100, hidden_size: 20\n",
            "Epoch 0: Training loss: 14.0667  Validation Loss: 4.1286\n",
            "Epoch 1: Training loss: 4.0934  Validation Loss: 100.8320\n",
            "Epoch 2: Training loss: 101.1565  Validation Loss: 2.4351\n",
            "Epoch 3: Training loss: 2.4126  Validation Loss: 9.2617\n",
            "Epoch 4: Training loss: 9.1771  Validation Loss: 8.2803\n",
            "Epoch 5: Training loss: 8.3523  Validation Loss: 3.2781\n",
            "Epoch 6: Training loss: 3.8295  Validation Loss: 3.8723\n",
            "Epoch 7: Training loss: 4.2238  Validation Loss: 1.4388\n",
            "Epoch 8: Training loss: 1.4856  Validation Loss: 4.8569\n",
            "Epoch 9: Training loss: 4.8108  Validation Loss: 1.9583\n",
            "test loss 1.958 \n",
            "===== Experiment 6 =====\n",
            "wd: 0.0, emb_size: 100, hidden_size: 30\n",
            "Epoch 0: Training loss: 13.1819  Validation Loss: 1.9101\n",
            "Epoch 1: Training loss: 1.9173  Validation Loss: 209.6654\n",
            "Epoch 2: Training loss: 208.7335  Validation Loss: 2.4377\n",
            "Epoch 3: Training loss: 2.2651  Validation Loss: 9.4275\n",
            "Epoch 4: Training loss: 9.9080  Validation Loss: 4.0143\n",
            "Epoch 5: Training loss: 4.4460  Validation Loss: 2.3980\n",
            "Epoch 6: Training loss: 2.4152  Validation Loss: 1.2009\n",
            "Epoch 7: Training loss: 1.2129  Validation Loss: 4.5708\n",
            "Epoch 8: Training loss: 4.5968  Validation Loss: 9.5456\n",
            "Epoch 9: Training loss: 9.4551  Validation Loss: 1.0145\n",
            "test loss 1.014 \n",
            "===== Experiment 7 =====\n",
            "wd: 0.0, emb_size: 100, hidden_size: 40\n",
            "Epoch 0: Training loss: 14.1821  Validation Loss: 6.0914\n",
            "Epoch 1: Training loss: 6.0402  Validation Loss: 107.4053\n",
            "Epoch 2: Training loss: 107.6314  Validation Loss: 2.7131\n",
            "Epoch 3: Training loss: 2.7942  Validation Loss: 6.8762\n",
            "Epoch 4: Training loss: 6.8946  Validation Loss: 8.8997\n",
            "Epoch 5: Training loss: 9.1011  Validation Loss: 11.5886\n",
            "Epoch 6: Training loss: 12.5653  Validation Loss: 1.9265\n",
            "Epoch 7: Training loss: 2.0034  Validation Loss: 8.5561\n",
            "Epoch 8: Training loss: 8.4975  Validation Loss: 4.4711\n",
            "Epoch 9: Training loss: 4.4048  Validation Loss: 6.0084\n",
            "test loss 6.008 \n",
            "===== Experiment 8 =====\n",
            "wd: 0.0, emb_size: 150, hidden_size: 10\n",
            "Epoch 0: Training loss: 12.9208  Validation Loss: 4.8696\n",
            "Epoch 1: Training loss: 4.8433  Validation Loss: 38.0922\n",
            "Epoch 2: Training loss: 38.2349  Validation Loss: 1.3039\n",
            "Epoch 3: Training loss: 1.2907  Validation Loss: 4.8809\n",
            "Epoch 4: Training loss: 4.8017  Validation Loss: 7.6757\n",
            "Epoch 5: Training loss: 7.6028  Validation Loss: 5.8879\n",
            "Epoch 6: Training loss: 6.0982  Validation Loss: 3.2585\n",
            "Epoch 7: Training loss: 3.5562  Validation Loss: 1.1912\n",
            "Epoch 8: Training loss: 1.1912  Validation Loss: 2.8531\n",
            "Epoch 9: Training loss: 2.7003  Validation Loss: 6.8221\n",
            "test loss 6.822 \n",
            "===== Experiment 9 =====\n",
            "wd: 0.0, emb_size: 150, hidden_size: 20\n",
            "Epoch 0: Training loss: 14.0762  Validation Loss: 4.9446\n",
            "Epoch 1: Training loss: 4.9088  Validation Loss: 105.9398\n",
            "Epoch 2: Training loss: 106.2157  Validation Loss: 2.2729\n",
            "Epoch 3: Training loss: 2.2863  Validation Loss: 9.5777\n",
            "Epoch 4: Training loss: 9.5617  Validation Loss: 5.9992\n",
            "Epoch 5: Training loss: 6.2849  Validation Loss: 21.0826\n",
            "Epoch 6: Training loss: 22.3517  Validation Loss: 2.3267\n",
            "Epoch 7: Training loss: 2.5948  Validation Loss: 6.0573\n",
            "Epoch 8: Training loss: 6.0306  Validation Loss: 13.2227\n",
            "Epoch 9: Training loss: 13.1490  Validation Loss: 13.4732\n",
            "test loss 13.473 \n",
            "===== Experiment 10 =====\n",
            "wd: 0.0, emb_size: 150, hidden_size: 30\n",
            "Epoch 0: Training loss: 14.1105  Validation Loss: 2.8761\n",
            "Epoch 1: Training loss: 2.8681  Validation Loss: 345.5641\n",
            "Epoch 2: Training loss: 344.7894  Validation Loss: 4.8914\n",
            "Epoch 3: Training loss: 4.8899  Validation Loss: 14.5860\n",
            "Epoch 4: Training loss: 14.6904  Validation Loss: 12.1585\n",
            "Epoch 5: Training loss: 12.7987  Validation Loss: 1.3605\n",
            "Epoch 6: Training loss: 1.4535  Validation Loss: 23.9694\n",
            "Epoch 7: Training loss: 23.8253  Validation Loss: 1.3995\n",
            "Epoch 8: Training loss: 1.4430  Validation Loss: 23.9406\n",
            "Epoch 9: Training loss: 23.9981  Validation Loss: 1.4440\n",
            "test loss 1.444 \n",
            "===== Experiment 11 =====\n",
            "wd: 0.0, emb_size: 150, hidden_size: 40\n",
            "Epoch 0: Training loss: 12.5999  Validation Loss: 2.5212\n",
            "Epoch 1: Training loss: 2.5161  Validation Loss: 284.9206\n",
            "Epoch 2: Training loss: 284.2487  Validation Loss: 3.9735\n",
            "Epoch 3: Training loss: 3.9331  Validation Loss: 10.9262\n",
            "Epoch 4: Training loss: 11.0924  Validation Loss: 9.7627\n",
            "Epoch 5: Training loss: 10.3261  Validation Loss: 3.8764\n",
            "Epoch 6: Training loss: 3.8557  Validation Loss: 4.3719\n",
            "Epoch 7: Training loss: 4.3190  Validation Loss: 11.8657\n",
            "Epoch 8: Training loss: 11.9470  Validation Loss: 2.3279\n",
            "Epoch 9: Training loss: 2.2549  Validation Loss: 5.1923\n",
            "test loss 5.192 \n",
            "===== Experiment 12 =====\n",
            "wd: 0.0, emb_size: 200, hidden_size: 10\n",
            "Epoch 0: Training loss: 12.0338  Validation Loss: 1.4254\n",
            "Epoch 1: Training loss: 1.4479  Validation Loss: 202.3410\n",
            "Epoch 2: Training loss: 200.3976  Validation Loss: 2.7326\n",
            "Epoch 3: Training loss: 2.5121  Validation Loss: 9.4997\n",
            "Epoch 4: Training loss: 9.4999  Validation Loss: 4.2422\n",
            "Epoch 5: Training loss: 4.7250  Validation Loss: 3.9366\n",
            "Epoch 6: Training loss: 4.2809  Validation Loss: 2.2586\n",
            "Epoch 7: Training loss: 2.3109  Validation Loss: 3.3895\n",
            "Epoch 8: Training loss: 3.3844  Validation Loss: 1.2918\n",
            "Epoch 9: Training loss: 1.3226  Validation Loss: 3.1680\n",
            "test loss 3.168 \n",
            "===== Experiment 13 =====\n",
            "wd: 0.0, emb_size: 200, hidden_size: 20\n",
            "Epoch 0: Training loss: 13.5567  Validation Loss: 5.0314\n",
            "Epoch 1: Training loss: 5.0034  Validation Loss: 80.2351\n",
            "Epoch 2: Training loss: 80.3660  Validation Loss: 1.8735\n",
            "Epoch 3: Training loss: 1.8869  Validation Loss: 6.4367\n",
            "Epoch 4: Training loss: 6.4247  Validation Loss: 9.2709\n",
            "Epoch 5: Training loss: 9.2045  Validation Loss: 6.2420\n",
            "Epoch 6: Training loss: 6.1380  Validation Loss: 1.8381\n",
            "Epoch 7: Training loss: 2.0028  Validation Loss: 1.8857\n",
            "Epoch 8: Training loss: 1.7606  Validation Loss: 6.2386\n",
            "Epoch 9: Training loss: 6.4026  Validation Loss: 1.1559\n",
            "test loss 1.156 \n",
            "===== Experiment 14 =====\n",
            "wd: 0.0, emb_size: 200, hidden_size: 30\n",
            "Epoch 0: Training loss: 13.3261  Validation Loss: 1.1788\n",
            "Epoch 1: Training loss: 1.2014  Validation Loss: 440.8266\n",
            "Epoch 2: Training loss: 437.8071  Validation Loss: 4.6439\n",
            "Epoch 3: Training loss: 4.3284  Validation Loss: 10.1717\n",
            "Epoch 4: Training loss: 10.2180  Validation Loss: 13.0268\n",
            "Epoch 5: Training loss: 14.2558  Validation Loss: 4.7629\n",
            "Epoch 6: Training loss: 4.7464  Validation Loss: 4.9364\n",
            "Epoch 7: Training loss: 4.9195  Validation Loss: 6.7463\n",
            "Epoch 8: Training loss: 6.9071  Validation Loss: 2.0908\n",
            "Epoch 9: Training loss: 2.1297  Validation Loss: 4.2655\n",
            "test loss 4.265 \n",
            "===== Experiment 15 =====\n",
            "wd: 0.0, emb_size: 200, hidden_size: 40\n",
            "Epoch 0: Training loss: 12.4982  Validation Loss: 2.2761\n",
            "Epoch 1: Training loss: 2.2753  Validation Loss: 468.0819\n",
            "Epoch 2: Training loss: 466.2806  Validation Loss: 7.4941\n",
            "Epoch 3: Training loss: 7.3762  Validation Loss: 12.9803\n",
            "Epoch 4: Training loss: 12.8675  Validation Loss: 6.9289\n",
            "Epoch 5: Training loss: 7.5919  Validation Loss: 3.4005\n",
            "Epoch 6: Training loss: 3.3455  Validation Loss: 1.2704\n",
            "Epoch 7: Training loss: 1.2876  Validation Loss: 2.6832\n",
            "Epoch 8: Training loss: 2.7387  Validation Loss: 24.9412\n",
            "Epoch 9: Training loss: 24.8998  Validation Loss: 17.3011\n",
            "test loss 17.301 \n",
            "===== Experiment 16 =====\n",
            "wd: 0.01, emb_size: 50, hidden_size: 10\n",
            "Epoch 0: Training loss: 12.6911  Validation Loss: 11.6791\n",
            "Epoch 1: Training loss: 11.5977  Validation Loss: 5.6564\n",
            "Epoch 2: Training loss: 5.5431  Validation Loss: 2.9641\n",
            "Epoch 3: Training loss: 2.9660  Validation Loss: 1.7219\n",
            "Epoch 4: Training loss: 1.7334  Validation Loss: 1.1279\n",
            "Epoch 5: Training loss: 1.1097  Validation Loss: 1.1627\n",
            "Epoch 6: Training loss: 1.1411  Validation Loss: 1.0185\n",
            "Epoch 7: Training loss: 0.9854  Validation Loss: 0.9679\n",
            "Epoch 8: Training loss: 0.9316  Validation Loss: 1.1557\n",
            "Epoch 9: Training loss: 1.1257  Validation Loss: 1.1440\n",
            "test loss 1.144 \n",
            "===== Experiment 17 =====\n",
            "wd: 0.01, emb_size: 50, hidden_size: 20\n",
            "Epoch 0: Training loss: 11.9717  Validation Loss: 11.1754\n",
            "Epoch 1: Training loss: 11.0954  Validation Loss: 6.5044\n",
            "Epoch 2: Training loss: 6.3801  Validation Loss: 4.2756\n",
            "Epoch 3: Training loss: 4.4778  Validation Loss: 1.3780\n",
            "Epoch 4: Training loss: 1.3931  Validation Loss: 1.5929\n",
            "Epoch 5: Training loss: 1.5567  Validation Loss: 1.6092\n",
            "Epoch 6: Training loss: 1.5831  Validation Loss: 1.4513\n",
            "Epoch 7: Training loss: 1.4374  Validation Loss: 1.4165\n",
            "Epoch 8: Training loss: 1.3966  Validation Loss: 1.1281\n",
            "Epoch 9: Training loss: 1.0989  Validation Loss: 1.2051\n",
            "test loss 1.205 \n",
            "===== Experiment 18 =====\n",
            "wd: 0.01, emb_size: 50, hidden_size: 30\n",
            "Epoch 0: Training loss: 12.4026  Validation Loss: 11.2117\n",
            "Epoch 1: Training loss: 11.1317  Validation Loss: 4.8575\n",
            "Epoch 2: Training loss: 4.7643  Validation Loss: 7.3868\n",
            "Epoch 3: Training loss: 7.7228  Validation Loss: 2.7019\n",
            "Epoch 4: Training loss: 2.6866  Validation Loss: 2.2080\n",
            "Epoch 5: Training loss: 2.2214  Validation Loss: 1.4940\n",
            "Epoch 6: Training loss: 1.5067  Validation Loss: 1.3685\n",
            "Epoch 7: Training loss: 1.3450  Validation Loss: 1.3501\n",
            "Epoch 8: Training loss: 1.3161  Validation Loss: 1.3717\n",
            "Epoch 9: Training loss: 1.3477  Validation Loss: 1.2694\n",
            "test loss 1.269 \n",
            "===== Experiment 19 =====\n",
            "wd: 0.01, emb_size: 50, hidden_size: 40\n",
            "Epoch 0: Training loss: 14.3057  Validation Loss: 12.9402\n",
            "Epoch 1: Training loss: 12.8587  Validation Loss: 4.5532\n",
            "Epoch 2: Training loss: 4.4576  Validation Loss: 14.9067\n",
            "Epoch 3: Training loss: 15.4679  Validation Loss: 4.1105\n",
            "Epoch 4: Training loss: 4.1125  Validation Loss: 4.3979\n",
            "Epoch 5: Training loss: 4.4102  Validation Loss: 2.7580\n",
            "Epoch 6: Training loss: 2.7977  Validation Loss: 2.4495\n",
            "Epoch 7: Training loss: 2.4538  Validation Loss: 2.0742\n",
            "Epoch 8: Training loss: 2.0864  Validation Loss: 2.0137\n",
            "Epoch 9: Training loss: 1.9829  Validation Loss: 1.8514\n",
            "test loss 1.851 \n",
            "===== Experiment 20 =====\n",
            "wd: 0.01, emb_size: 100, hidden_size: 10\n",
            "Epoch 0: Training loss: 13.5974  Validation Loss: 13.9472\n",
            "Epoch 1: Training loss: 13.8240  Validation Loss: 6.9236\n",
            "Epoch 2: Training loss: 6.7471  Validation Loss: 5.9980\n",
            "Epoch 3: Training loss: 6.2461  Validation Loss: 1.6734\n",
            "Epoch 4: Training loss: 1.7016  Validation Loss: 2.2477\n",
            "Epoch 5: Training loss: 2.2067  Validation Loss: 3.0193\n",
            "Epoch 6: Training loss: 2.9759  Validation Loss: 2.6752\n",
            "Epoch 7: Training loss: 2.6300  Validation Loss: 1.4917\n",
            "Epoch 8: Training loss: 1.4880  Validation Loss: 1.2573\n",
            "Epoch 9: Training loss: 1.2573  Validation Loss: 0.9140\n",
            "test loss 0.914 \n",
            "===== Experiment 21 =====\n",
            "wd: 0.01, emb_size: 100, hidden_size: 20\n",
            "Epoch 0: Training loss: 13.0348  Validation Loss: 11.9600\n",
            "Epoch 1: Training loss: 11.8813  Validation Loss: 6.8070\n",
            "Epoch 2: Training loss: 6.7192  Validation Loss: 3.2633\n",
            "Epoch 3: Training loss: 3.3732  Validation Loss: 3.8820\n",
            "Epoch 4: Training loss: 3.7736  Validation Loss: 4.0875\n",
            "Epoch 5: Training loss: 4.0419  Validation Loss: 2.6381\n",
            "Epoch 6: Training loss: 2.5783  Validation Loss: 3.1694\n",
            "Epoch 7: Training loss: 3.1707  Validation Loss: 1.6635\n",
            "Epoch 8: Training loss: 1.6229  Validation Loss: 2.3869\n",
            "Epoch 9: Training loss: 2.3553  Validation Loss: 2.3042\n",
            "test loss 2.304 \n",
            "===== Experiment 22 =====\n",
            "wd: 0.01, emb_size: 100, hidden_size: 30\n",
            "Epoch 0: Training loss: 12.0712  Validation Loss: 11.5872\n",
            "Epoch 1: Training loss: 11.5042  Validation Loss: 6.7750\n",
            "Epoch 2: Training loss: 6.6974  Validation Loss: 2.2695\n",
            "Epoch 3: Training loss: 2.2705  Validation Loss: 9.3721\n",
            "Epoch 4: Training loss: 9.3029  Validation Loss: 4.0818\n",
            "Epoch 5: Training loss: 4.1178  Validation Loss: 3.4524\n",
            "Epoch 6: Training loss: 3.3832  Validation Loss: 2.5745\n",
            "Epoch 7: Training loss: 2.5289  Validation Loss: 1.8004\n",
            "Epoch 8: Training loss: 1.7816  Validation Loss: 1.6632\n",
            "Epoch 9: Training loss: 1.6077  Validation Loss: 2.3384\n",
            "test loss 2.338 \n",
            "===== Experiment 23 =====\n",
            "wd: 0.01, emb_size: 100, hidden_size: 40\n",
            "Epoch 0: Training loss: 12.8159  Validation Loss: 9.8767\n",
            "Epoch 1: Training loss: 9.8303  Validation Loss: 1.7309\n",
            "Epoch 2: Training loss: 1.7612  Validation Loss: 4.2133\n",
            "Epoch 3: Training loss: 4.1786  Validation Loss: 10.5638\n",
            "Epoch 4: Training loss: 10.9664  Validation Loss: 2.2858\n",
            "Epoch 5: Training loss: 2.1917  Validation Loss: 3.6138\n",
            "Epoch 6: Training loss: 3.6194  Validation Loss: 2.9910\n",
            "Epoch 7: Training loss: 3.0525  Validation Loss: 2.1503\n",
            "Epoch 8: Training loss: 2.1469  Validation Loss: 1.9792\n",
            "Epoch 9: Training loss: 1.9604  Validation Loss: 1.7915\n",
            "test loss 1.791 \n",
            "===== Experiment 24 =====\n",
            "wd: 0.01, emb_size: 150, hidden_size: 10\n",
            "Epoch 0: Training loss: 15.4392  Validation Loss: 19.6550\n",
            "Epoch 1: Training loss: 19.4576  Validation Loss: 8.9801\n",
            "Epoch 2: Training loss: 8.8177  Validation Loss: 2.9522\n",
            "Epoch 3: Training loss: 2.9526  Validation Loss: 3.4624\n",
            "Epoch 4: Training loss: 3.6055  Validation Loss: 1.4838\n",
            "Epoch 5: Training loss: 1.4707  Validation Loss: 3.3857\n",
            "Epoch 6: Training loss: 3.3038  Validation Loss: 5.0074\n",
            "Epoch 7: Training loss: 4.9076  Validation Loss: 4.5646\n",
            "Epoch 8: Training loss: 4.4805  Validation Loss: 2.8314\n",
            "Epoch 9: Training loss: 2.7848  Validation Loss: 1.6267\n",
            "test loss 1.627 \n",
            "===== Experiment 25 =====\n",
            "wd: 0.01, emb_size: 150, hidden_size: 20\n",
            "Epoch 0: Training loss: 14.5269  Validation Loss: 12.1920\n",
            "Epoch 1: Training loss: 12.1162  Validation Loss: 4.9311\n",
            "Epoch 2: Training loss: 4.8367  Validation Loss: 6.9108\n",
            "Epoch 3: Training loss: 7.0226  Validation Loss: 8.3545\n",
            "Epoch 4: Training loss: 8.3115  Validation Loss: 3.9541\n",
            "Epoch 5: Training loss: 3.9834  Validation Loss: 1.9747\n",
            "Epoch 6: Training loss: 1.9108  Validation Loss: 2.7375\n",
            "Epoch 7: Training loss: 2.7427  Validation Loss: 1.8949\n",
            "Epoch 8: Training loss: 1.8612  Validation Loss: 1.7832\n",
            "Epoch 9: Training loss: 1.7367  Validation Loss: 2.3701\n",
            "test loss 2.370 \n",
            "===== Experiment 26 =====\n",
            "wd: 0.01, emb_size: 150, hidden_size: 30\n",
            "Epoch 0: Training loss: 12.4701  Validation Loss: 11.1548\n",
            "Epoch 1: Training loss: 11.0776  Validation Loss: 2.5238\n",
            "Epoch 2: Training loss: 2.4862  Validation Loss: 12.2558\n",
            "Epoch 3: Training loss: 12.3335  Validation Loss: 13.5425\n",
            "Epoch 4: Training loss: 13.1273  Validation Loss: 2.6578\n",
            "Epoch 5: Training loss: 2.6042  Validation Loss: 2.7860\n",
            "Epoch 6: Training loss: 2.6655  Validation Loss: 2.6093\n",
            "Epoch 7: Training loss: 2.6092  Validation Loss: 2.4388\n",
            "Epoch 8: Training loss: 2.4605  Validation Loss: 2.1854\n",
            "Epoch 9: Training loss: 2.1598  Validation Loss: 2.1795\n",
            "test loss 2.179 \n",
            "===== Experiment 27 =====\n",
            "wd: 0.01, emb_size: 150, hidden_size: 40\n",
            "Epoch 0: Training loss: 13.5182  Validation Loss: 12.5340\n",
            "Epoch 1: Training loss: 12.4517  Validation Loss: 3.1036\n",
            "Epoch 2: Training loss: 3.0581  Validation Loss: 15.8305\n",
            "Epoch 3: Training loss: 16.1062  Validation Loss: 10.0809\n",
            "Epoch 4: Training loss: 9.7180  Validation Loss: 2.7154\n",
            "Epoch 5: Training loss: 2.6411  Validation Loss: 2.8136\n",
            "Epoch 6: Training loss: 2.7803  Validation Loss: 2.6132\n",
            "Epoch 7: Training loss: 2.5709  Validation Loss: 2.5663\n",
            "Epoch 8: Training loss: 2.5417  Validation Loss: 2.3698\n",
            "Epoch 9: Training loss: 2.3646  Validation Loss: 2.4041\n",
            "test loss 2.404 \n",
            "===== Experiment 28 =====\n",
            "wd: 0.01, emb_size: 200, hidden_size: 10\n",
            "Epoch 0: Training loss: 13.6808  Validation Loss: 15.4755\n",
            "Epoch 1: Training loss: 15.3413  Validation Loss: 9.2749\n",
            "Epoch 2: Training loss: 9.1415  Validation Loss: 9.6943\n",
            "Epoch 3: Training loss: 10.2015  Validation Loss: 2.0294\n",
            "Epoch 4: Training loss: 2.1152  Validation Loss: 2.2015\n",
            "Epoch 5: Training loss: 2.1905  Validation Loss: 3.5528\n",
            "Epoch 6: Training loss: 3.5625  Validation Loss: 4.7433\n",
            "Epoch 7: Training loss: 4.8430  Validation Loss: 3.1126\n",
            "Epoch 8: Training loss: 3.0789  Validation Loss: 2.6217\n",
            "Epoch 9: Training loss: 2.5162  Validation Loss: 2.3395\n",
            "test loss 2.339 \n",
            "===== Experiment 29 =====\n",
            "wd: 0.01, emb_size: 200, hidden_size: 20\n",
            "Epoch 0: Training loss: 13.9004  Validation Loss: 11.8979\n",
            "Epoch 1: Training loss: 11.8221  Validation Loss: 3.6385\n",
            "Epoch 2: Training loss: 3.5715  Validation Loss: 8.2466\n",
            "Epoch 3: Training loss: 8.3594  Validation Loss: 18.2805\n",
            "Epoch 4: Training loss: 17.8939  Validation Loss: 3.8728\n",
            "Epoch 5: Training loss: 3.8707  Validation Loss: 3.0736\n",
            "Epoch 6: Training loss: 3.0600  Validation Loss: 4.4605\n",
            "Epoch 7: Training loss: 4.6089  Validation Loss: 1.7913\n",
            "Epoch 8: Training loss: 1.8378  Validation Loss: 2.8447\n",
            "Epoch 9: Training loss: 2.7791  Validation Loss: 3.9763\n",
            "test loss 3.976 \n",
            "===== Experiment 30 =====\n",
            "wd: 0.01, emb_size: 200, hidden_size: 30\n",
            "Epoch 0: Training loss: 13.1931  Validation Loss: 11.4278\n",
            "Epoch 1: Training loss: 11.3646  Validation Loss: 2.2314\n",
            "Epoch 2: Training loss: 2.2020  Validation Loss: 9.7624\n",
            "Epoch 3: Training loss: 9.8617  Validation Loss: 20.7227\n",
            "Epoch 4: Training loss: 20.1867  Validation Loss: 4.6936\n",
            "Epoch 5: Training loss: 4.5865  Validation Loss: 4.3384\n",
            "Epoch 6: Training loss: 4.3701  Validation Loss: 3.3568\n",
            "Epoch 7: Training loss: 3.3536  Validation Loss: 3.3785\n",
            "Epoch 8: Training loss: 3.2798  Validation Loss: 4.5954\n",
            "Epoch 9: Training loss: 4.4823  Validation Loss: 2.7120\n",
            "test loss 2.712 \n",
            "===== Experiment 31 =====\n",
            "wd: 0.01, emb_size: 200, hidden_size: 40\n",
            "Epoch 0: Training loss: 13.7771  Validation Loss: 6.4458\n",
            "Epoch 1: Training loss: 6.4346  Validation Loss: 32.0441\n",
            "Epoch 2: Training loss: 32.5582  Validation Loss: 11.5880\n",
            "Epoch 3: Training loss: 11.3412  Validation Loss: 13.9811\n",
            "Epoch 4: Training loss: 14.7306  Validation Loss: 5.6685\n",
            "Epoch 5: Training loss: 5.5082  Validation Loss: 9.8033\n",
            "Epoch 6: Training loss: 9.6714  Validation Loss: 10.5956\n",
            "Epoch 7: Training loss: 10.5179  Validation Loss: 9.4561\n",
            "Epoch 8: Training loss: 9.4150  Validation Loss: 5.6498\n",
            "Epoch 9: Training loss: 5.6020  Validation Loss: 3.2417\n",
            "test loss 3.242 \n",
            "===== Experiment 32 =====\n",
            "wd: 0.05, emb_size: 50, hidden_size: 10\n",
            "Epoch 0: Training loss: 13.8608  Validation Loss: 13.8438\n",
            "Epoch 1: Training loss: 13.7442  Validation Loss: 11.9416\n",
            "Epoch 2: Training loss: 11.8451  Validation Loss: 6.3637\n",
            "Epoch 3: Training loss: 6.2967  Validation Loss: 1.5733\n",
            "Epoch 4: Training loss: 1.6524  Validation Loss: 1.7127\n",
            "Epoch 5: Training loss: 1.7892  Validation Loss: 1.7496\n",
            "Epoch 6: Training loss: 1.7154  Validation Loss: 3.2345\n",
            "Epoch 7: Training loss: 3.1803  Validation Loss: 2.9390\n",
            "Epoch 8: Training loss: 2.8870  Validation Loss: 1.6633\n",
            "Epoch 9: Training loss: 1.6396  Validation Loss: 1.2005\n",
            "test loss 1.201 \n",
            "===== Experiment 33 =====\n",
            "wd: 0.05, emb_size: 50, hidden_size: 20\n",
            "Epoch 0: Training loss: 14.9871  Validation Loss: 14.2966\n",
            "Epoch 1: Training loss: 14.1962  Validation Loss: 10.5376\n",
            "Epoch 2: Training loss: 10.4606  Validation Loss: 9.3441\n",
            "Epoch 3: Training loss: 9.2244  Validation Loss: 4.9367\n",
            "Epoch 4: Training loss: 4.8177  Validation Loss: 6.1114\n",
            "Epoch 5: Training loss: 6.2352  Validation Loss: 1.8419\n",
            "Epoch 6: Training loss: 1.8155  Validation Loss: 1.5435\n",
            "Epoch 7: Training loss: 1.5268  Validation Loss: 1.3327\n",
            "Epoch 8: Training loss: 1.3418  Validation Loss: 1.3313\n",
            "Epoch 9: Training loss: 1.3811  Validation Loss: 1.7083\n",
            "test loss 1.708 \n",
            "===== Experiment 34 =====\n",
            "wd: 0.05, emb_size: 50, hidden_size: 30\n",
            "Epoch 0: Training loss: 12.6128  Validation Loss: 11.6575\n",
            "Epoch 1: Training loss: 11.5720  Validation Loss: 7.1725\n",
            "Epoch 2: Training loss: 7.1122  Validation Loss: 4.6601\n",
            "Epoch 3: Training loss: 4.5628  Validation Loss: 7.6863\n",
            "Epoch 4: Training loss: 7.8867  Validation Loss: 2.1825\n",
            "Epoch 5: Training loss: 2.1297  Validation Loss: 1.7375\n",
            "Epoch 6: Training loss: 1.7254  Validation Loss: 1.1852\n",
            "Epoch 7: Training loss: 1.1981  Validation Loss: 1.5601\n",
            "Epoch 8: Training loss: 1.5983  Validation Loss: 1.0830\n",
            "Epoch 9: Training loss: 1.0959  Validation Loss: 1.2222\n",
            "test loss 1.222 \n",
            "===== Experiment 35 =====\n",
            "wd: 0.05, emb_size: 50, hidden_size: 40\n",
            "Epoch 0: Training loss: 13.1605  Validation Loss: 11.1788\n",
            "Epoch 1: Training loss: 11.1033  Validation Loss: 5.8150\n",
            "Epoch 2: Training loss: 5.7428  Validation Loss: 3.7898\n",
            "Epoch 3: Training loss: 3.8518  Validation Loss: 1.5626\n",
            "Epoch 4: Training loss: 1.5462  Validation Loss: 1.4789\n",
            "Epoch 5: Training loss: 1.5037  Validation Loss: 1.0067\n",
            "Epoch 6: Training loss: 1.0124  Validation Loss: 1.6020\n",
            "Epoch 7: Training loss: 1.6233  Validation Loss: 1.9231\n",
            "Epoch 8: Training loss: 1.9341  Validation Loss: 1.3886\n",
            "Epoch 9: Training loss: 1.3912  Validation Loss: 1.2374\n",
            "test loss 1.237 \n",
            "===== Experiment 36 =====\n",
            "wd: 0.05, emb_size: 100, hidden_size: 10\n",
            "Epoch 0: Training loss: 11.7166  Validation Loss: 15.3857\n",
            "Epoch 1: Training loss: 15.2623  Validation Loss: 8.7572\n",
            "Epoch 2: Training loss: 8.6867  Validation Loss: 5.4737\n",
            "Epoch 3: Training loss: 5.4205  Validation Loss: 1.4601\n",
            "Epoch 4: Training loss: 1.5312  Validation Loss: 1.4248\n",
            "Epoch 5: Training loss: 1.4905  Validation Loss: 1.8656\n",
            "Epoch 6: Training loss: 1.8326  Validation Loss: 3.4552\n",
            "Epoch 7: Training loss: 3.4197  Validation Loss: 1.6589\n",
            "Epoch 8: Training loss: 1.6906  Validation Loss: 1.2817\n",
            "Epoch 9: Training loss: 1.3278  Validation Loss: 0.9607\n",
            "test loss 0.961 \n",
            "===== Experiment 37 =====\n",
            "wd: 0.05, emb_size: 100, hidden_size: 20\n",
            "Epoch 0: Training loss: 15.0312  Validation Loss: 15.5159\n",
            "Epoch 1: Training loss: 15.4057  Validation Loss: 8.8902\n",
            "Epoch 2: Training loss: 8.8336  Validation Loss: 8.6455\n",
            "Epoch 3: Training loss: 8.5338  Validation Loss: 5.4532\n",
            "Epoch 4: Training loss: 5.5458  Validation Loss: 1.4601\n",
            "Epoch 5: Training loss: 1.4753  Validation Loss: 1.3978\n",
            "Epoch 6: Training loss: 1.3814  Validation Loss: 2.2225\n",
            "Epoch 7: Training loss: 2.1815  Validation Loss: 1.5924\n",
            "Epoch 8: Training loss: 1.6157  Validation Loss: 1.2785\n",
            "Epoch 9: Training loss: 1.3013  Validation Loss: 1.1385\n",
            "test loss 1.138 \n",
            "===== Experiment 38 =====\n",
            "wd: 0.05, emb_size: 100, hidden_size: 30\n",
            "Epoch 0: Training loss: 12.1039  Validation Loss: 11.6370\n",
            "Epoch 1: Training loss: 11.5521  Validation Loss: 6.2770\n",
            "Epoch 2: Training loss: 6.2313  Validation Loss: 3.8698\n",
            "Epoch 3: Training loss: 3.8697  Validation Loss: 7.6187\n",
            "Epoch 4: Training loss: 7.7833  Validation Loss: 1.2458\n",
            "Epoch 5: Training loss: 1.2461  Validation Loss: 3.1130\n",
            "Epoch 6: Training loss: 3.0771  Validation Loss: 2.2441\n",
            "Epoch 7: Training loss: 2.3039  Validation Loss: 2.1726\n",
            "Epoch 8: Training loss: 2.1748  Validation Loss: 1.1971\n",
            "Epoch 9: Training loss: 1.1753  Validation Loss: 1.6855\n",
            "test loss 1.686 \n",
            "===== Experiment 39 =====\n",
            "wd: 0.05, emb_size: 100, hidden_size: 40\n",
            "Epoch 0: Training loss: 12.7147  Validation Loss: 10.0767\n",
            "Epoch 1: Training loss: 10.0112  Validation Loss: 3.0268\n",
            "Epoch 2: Training loss: 2.9977  Validation Loss: 3.1704\n",
            "Epoch 3: Training loss: 3.1586  Validation Loss: 5.5307\n",
            "Epoch 4: Training loss: 5.4758  Validation Loss: 1.4579\n",
            "Epoch 5: Training loss: 1.4457  Validation Loss: 2.7495\n",
            "Epoch 6: Training loss: 2.7642  Validation Loss: 4.1008\n",
            "Epoch 7: Training loss: 4.0811  Validation Loss: 1.3191\n",
            "Epoch 8: Training loss: 1.3344  Validation Loss: 2.7851\n",
            "Epoch 9: Training loss: 2.8636  Validation Loss: 2.1790\n",
            "test loss 2.179 \n",
            "===== Experiment 40 =====\n",
            "wd: 0.05, emb_size: 150, hidden_size: 10\n",
            "Epoch 0: Training loss: 12.8408  Validation Loss: 16.5878\n",
            "Epoch 1: Training loss: 16.4555  Validation Loss: 8.7929\n",
            "Epoch 2: Training loss: 8.7393  Validation Loss: 9.5933\n",
            "Epoch 3: Training loss: 9.5199  Validation Loss: 5.5448\n",
            "Epoch 4: Training loss: 5.5060  Validation Loss: 1.9880\n",
            "Epoch 5: Training loss: 1.9819  Validation Loss: 1.5270\n",
            "Epoch 6: Training loss: 1.5290  Validation Loss: 2.7120\n",
            "Epoch 7: Training loss: 2.6660  Validation Loss: 2.0199\n",
            "Epoch 8: Training loss: 2.0646  Validation Loss: 1.7623\n",
            "Epoch 9: Training loss: 1.7844  Validation Loss: 0.9960\n",
            "test loss 0.996 \n",
            "===== Experiment 41 =====\n",
            "wd: 0.05, emb_size: 150, hidden_size: 20\n",
            "Epoch 0: Training loss: 12.6158  Validation Loss: 12.1824\n",
            "Epoch 1: Training loss: 12.0936  Validation Loss: 5.1179\n",
            "Epoch 2: Training loss: 5.0857  Validation Loss: 5.7266\n",
            "Epoch 3: Training loss: 5.6704  Validation Loss: 3.8349\n",
            "Epoch 4: Training loss: 3.9626  Validation Loss: 1.8752\n",
            "Epoch 5: Training loss: 1.8855  Validation Loss: 2.4069\n",
            "Epoch 6: Training loss: 2.3910  Validation Loss: 2.6485\n",
            "Epoch 7: Training loss: 2.6909  Validation Loss: 3.6393\n",
            "Epoch 8: Training loss: 3.6481  Validation Loss: 1.2534\n",
            "Epoch 9: Training loss: 1.2854  Validation Loss: 1.9032\n",
            "test loss 1.903 \n",
            "===== Experiment 42 =====\n",
            "wd: 0.05, emb_size: 150, hidden_size: 30\n",
            "Epoch 0: Training loss: 13.5290  Validation Loss: 13.8926\n",
            "Epoch 1: Training loss: 13.7946  Validation Loss: 8.0869\n",
            "Epoch 2: Training loss: 8.0277  Validation Loss: 5.4665\n",
            "Epoch 3: Training loss: 5.4797  Validation Loss: 7.0787\n",
            "Epoch 4: Training loss: 7.2094  Validation Loss: 2.0779\n",
            "Epoch 5: Training loss: 2.0929  Validation Loss: 5.6221\n",
            "Epoch 6: Training loss: 5.5328  Validation Loss: 2.6292\n",
            "Epoch 7: Training loss: 2.6902  Validation Loss: 2.2828\n",
            "Epoch 8: Training loss: 2.3152  Validation Loss: 1.0816\n",
            "Epoch 9: Training loss: 1.0903  Validation Loss: 2.7981\n",
            "test loss 2.798 \n",
            "===== Experiment 43 =====\n",
            "wd: 0.05, emb_size: 150, hidden_size: 40\n",
            "Epoch 0: Training loss: 13.2499  Validation Loss: 9.6447\n",
            "Epoch 1: Training loss: 9.5835  Validation Loss: 1.8118\n",
            "Epoch 2: Training loss: 1.8182  Validation Loss: 4.5351\n",
            "Epoch 3: Training loss: 4.5046  Validation Loss: 9.9520\n",
            "Epoch 4: Training loss: 10.2199  Validation Loss: 1.9857\n",
            "Epoch 5: Training loss: 2.0052  Validation Loss: 4.9459\n",
            "Epoch 6: Training loss: 4.8977  Validation Loss: 3.5973\n",
            "Epoch 7: Training loss: 3.8083  Validation Loss: 3.4363\n",
            "Epoch 8: Training loss: 3.5033  Validation Loss: 2.9145\n",
            "Epoch 9: Training loss: 2.9589  Validation Loss: 3.8398\n",
            "test loss 3.840 \n",
            "===== Experiment 44 =====\n",
            "wd: 0.05, emb_size: 200, hidden_size: 10\n",
            "Epoch 0: Training loss: 13.4259  Validation Loss: 15.1168\n",
            "Epoch 1: Training loss: 15.0061  Validation Loss: 10.0979\n",
            "Epoch 2: Training loss: 10.0301  Validation Loss: 4.2355\n",
            "Epoch 3: Training loss: 4.2465  Validation Loss: 9.3054\n",
            "Epoch 4: Training loss: 9.3812  Validation Loss: 1.0048\n",
            "Epoch 5: Training loss: 1.0090  Validation Loss: 6.1182\n",
            "Epoch 6: Training loss: 6.0566  Validation Loss: 3.5878\n",
            "Epoch 7: Training loss: 3.6564  Validation Loss: 2.8496\n",
            "Epoch 8: Training loss: 2.9748  Validation Loss: 0.9506\n",
            "Epoch 9: Training loss: 0.9722  Validation Loss: 2.3369\n",
            "test loss 2.337 \n",
            "===== Experiment 45 =====\n",
            "wd: 0.05, emb_size: 200, hidden_size: 20\n",
            "Epoch 0: Training loss: 12.5699  Validation Loss: 19.6314\n",
            "Epoch 1: Training loss: 19.4771  Validation Loss: 8.6021\n",
            "Epoch 2: Training loss: 8.5415  Validation Loss: 3.0458\n",
            "Epoch 3: Training loss: 3.2200  Validation Loss: 3.0661\n",
            "Epoch 4: Training loss: 3.1555  Validation Loss: 2.8058\n",
            "Epoch 5: Training loss: 2.7799  Validation Loss: 5.8791\n",
            "Epoch 6: Training loss: 5.8083  Validation Loss: 4.6632\n",
            "Epoch 7: Training loss: 4.6950  Validation Loss: 1.6496\n",
            "Epoch 8: Training loss: 1.7338  Validation Loss: 1.0604\n",
            "Epoch 9: Training loss: 1.0955  Validation Loss: 1.5011\n",
            "test loss 1.501 \n",
            "===== Experiment 46 =====\n",
            "wd: 0.05, emb_size: 200, hidden_size: 30\n",
            "Epoch 0: Training loss: 12.1131  Validation Loss: 8.4643\n",
            "Epoch 1: Training loss: 8.4061  Validation Loss: 1.3520\n",
            "Epoch 2: Training loss: 1.3882  Validation Loss: 2.5803\n",
            "Epoch 3: Training loss: 2.6674  Validation Loss: 4.3351\n",
            "Epoch 4: Training loss: 4.4002  Validation Loss: 3.1249\n",
            "Epoch 5: Training loss: 3.0833  Validation Loss: 6.5988\n",
            "Epoch 6: Training loss: 6.7423  Validation Loss: 2.1790\n",
            "Epoch 7: Training loss: 2.2315  Validation Loss: 1.4096\n",
            "Epoch 8: Training loss: 1.4070  Validation Loss: 2.1548\n",
            "Epoch 9: Training loss: 2.1898  Validation Loss: 2.2696\n",
            "test loss 2.270 \n",
            "===== Experiment 47 =====\n",
            "wd: 0.05, emb_size: 200, hidden_size: 40\n",
            "Epoch 0: Training loss: 13.1064  Validation Loss: 10.1916\n",
            "Epoch 1: Training loss: 10.1233  Validation Loss: 1.2305\n",
            "Epoch 2: Training loss: 1.2885  Validation Loss: 1.8574\n",
            "Epoch 3: Training loss: 1.9371  Validation Loss: 3.4533\n",
            "Epoch 4: Training loss: 3.5177  Validation Loss: 5.5060\n",
            "Epoch 5: Training loss: 5.4544  Validation Loss: 7.3741\n",
            "Epoch 6: Training loss: 7.3120  Validation Loss: 3.3935\n",
            "Epoch 7: Training loss: 3.5027  Validation Loss: 1.8277\n",
            "Epoch 8: Training loss: 1.8804  Validation Loss: 4.1967\n",
            "Epoch 9: Training loss: 4.1643  Validation Loss: 1.5095\n",
            "test loss 1.510 \n",
            "===== Experiment 48 =====\n",
            "wd: 0.1, emb_size: 50, hidden_size: 10\n",
            "Epoch 0: Training loss: 11.3186  Validation Loss: 10.7732\n",
            "Epoch 1: Training loss: 10.6943  Validation Loss: 9.3298\n",
            "Epoch 2: Training loss: 9.2590  Validation Loss: 7.6516\n",
            "Epoch 3: Training loss: 7.5957  Validation Loss: 4.8997\n",
            "Epoch 4: Training loss: 4.8700  Validation Loss: 2.4906\n",
            "Epoch 5: Training loss: 2.4797  Validation Loss: 1.5573\n",
            "Epoch 6: Training loss: 1.5554  Validation Loss: 1.8497\n",
            "Epoch 7: Training loss: 1.8305  Validation Loss: 2.5142\n",
            "Epoch 8: Training loss: 2.4782  Validation Loss: 1.6232\n",
            "Epoch 9: Training loss: 1.5991  Validation Loss: 1.4784\n",
            "test loss 1.478 \n",
            "===== Experiment 49 =====\n",
            "wd: 0.1, emb_size: 50, hidden_size: 20\n",
            "Epoch 0: Training loss: 12.3108  Validation Loss: 12.1605\n",
            "Epoch 1: Training loss: 12.0717  Validation Loss: 9.1599\n",
            "Epoch 2: Training loss: 9.0925  Validation Loss: 7.1904\n",
            "Epoch 3: Training loss: 7.1370  Validation Loss: 3.7109\n",
            "Epoch 4: Training loss: 3.6920  Validation Loss: 1.2740\n",
            "Epoch 5: Training loss: 1.2944  Validation Loss: 1.0359\n",
            "Epoch 6: Training loss: 1.0688  Validation Loss: 0.9687\n",
            "Epoch 7: Training loss: 0.9881  Validation Loss: 1.1863\n",
            "Epoch 8: Training loss: 1.1899  Validation Loss: 1.0890\n",
            "Epoch 9: Training loss: 1.1047  Validation Loss: 1.8176\n",
            "test loss 1.818 \n",
            "===== Experiment 50 =====\n",
            "wd: 0.1, emb_size: 50, hidden_size: 30\n",
            "Epoch 0: Training loss: 13.9494  Validation Loss: 13.4564\n",
            "Epoch 1: Training loss: 13.3597  Validation Loss: 9.7391\n",
            "Epoch 2: Training loss: 9.6690  Validation Loss: 7.6337\n",
            "Epoch 3: Training loss: 7.5774  Validation Loss: 3.0475\n",
            "Epoch 4: Training loss: 3.0375  Validation Loss: 1.5024\n",
            "Epoch 5: Training loss: 1.5804  Validation Loss: 1.2616\n",
            "Epoch 6: Training loss: 1.3144  Validation Loss: 0.9489\n",
            "Epoch 7: Training loss: 0.9697  Validation Loss: 0.9625\n",
            "Epoch 8: Training loss: 0.9750  Validation Loss: 1.0486\n",
            "Epoch 9: Training loss: 1.0767  Validation Loss: 1.4545\n",
            "test loss 1.455 \n",
            "===== Experiment 51 =====\n",
            "wd: 0.1, emb_size: 50, hidden_size: 40\n",
            "Epoch 0: Training loss: 12.0728  Validation Loss: 11.0987\n",
            "Epoch 1: Training loss: 11.0198  Validation Loss: 6.4731\n",
            "Epoch 2: Training loss: 6.4213  Validation Loss: 3.1089\n",
            "Epoch 3: Training loss: 3.0834  Validation Loss: 2.0749\n",
            "Epoch 4: Training loss: 2.1860  Validation Loss: 1.0681\n",
            "Epoch 5: Training loss: 1.0991  Validation Loss: 1.0408\n",
            "Epoch 6: Training loss: 1.0723  Validation Loss: 3.0398\n",
            "Epoch 7: Training loss: 3.0984  Validation Loss: 1.9841\n",
            "Epoch 8: Training loss: 2.0303  Validation Loss: 1.4480\n",
            "Epoch 9: Training loss: 1.4449  Validation Loss: 2.0445\n",
            "test loss 2.044 \n",
            "===== Experiment 52 =====\n",
            "wd: 0.1, emb_size: 100, hidden_size: 10\n",
            "Epoch 0: Training loss: 13.1409  Validation Loss: 16.5406\n",
            "Epoch 1: Training loss: 16.4182  Validation Loss: 11.1501\n",
            "Epoch 2: Training loss: 11.0686  Validation Loss: 11.0866\n",
            "Epoch 3: Training loss: 11.0056  Validation Loss: 8.4236\n",
            "Epoch 4: Training loss: 8.3609  Validation Loss: 5.4049\n",
            "Epoch 5: Training loss: 5.3587  Validation Loss: 4.2102\n",
            "Epoch 6: Training loss: 4.1502  Validation Loss: 5.2381\n",
            "Epoch 7: Training loss: 5.1444  Validation Loss: 3.9529\n",
            "Epoch 8: Training loss: 3.8973  Validation Loss: 2.6038\n",
            "Epoch 9: Training loss: 2.5658  Validation Loss: 1.9860\n",
            "test loss 1.986 \n",
            "===== Experiment 53 =====\n",
            "wd: 0.1, emb_size: 100, hidden_size: 20\n",
            "Epoch 0: Training loss: 12.2242  Validation Loss: 15.1357\n",
            "Epoch 1: Training loss: 15.0182  Validation Loss: 8.6659\n",
            "Epoch 2: Training loss: 8.6057  Validation Loss: 6.1812\n",
            "Epoch 3: Training loss: 6.1428  Validation Loss: 1.1996\n",
            "Epoch 4: Training loss: 1.2236  Validation Loss: 2.3973\n",
            "Epoch 5: Training loss: 2.4844  Validation Loss: 2.1599\n",
            "Epoch 6: Training loss: 2.1400  Validation Loss: 1.8609\n",
            "Epoch 7: Training loss: 1.8696  Validation Loss: 1.0873\n",
            "Epoch 8: Training loss: 1.1172  Validation Loss: 1.1049\n",
            "Epoch 9: Training loss: 1.1468  Validation Loss: 1.0345\n",
            "test loss 1.035 \n",
            "===== Experiment 54 =====\n",
            "wd: 0.1, emb_size: 100, hidden_size: 30\n",
            "Epoch 0: Training loss: 13.4832  Validation Loss: 13.4771\n",
            "Epoch 1: Training loss: 13.3820  Validation Loss: 7.1970\n",
            "Epoch 2: Training loss: 7.1444  Validation Loss: 4.4267\n",
            "Epoch 3: Training loss: 4.4364  Validation Loss: 2.8608\n",
            "Epoch 4: Training loss: 2.9338  Validation Loss: 1.8004\n",
            "Epoch 5: Training loss: 1.8515  Validation Loss: 3.4343\n",
            "Epoch 6: Training loss: 3.4017  Validation Loss: 1.5141\n",
            "Epoch 7: Training loss: 1.5462  Validation Loss: 1.0941\n",
            "Epoch 8: Training loss: 1.1299  Validation Loss: 1.3652\n",
            "Epoch 9: Training loss: 1.4370  Validation Loss: 1.5179\n",
            "test loss 1.518 \n",
            "===== Experiment 55 =====\n",
            "wd: 0.1, emb_size: 100, hidden_size: 40\n",
            "Epoch 0: Training loss: 13.0249  Validation Loss: 11.1272\n",
            "Epoch 1: Training loss: 11.0508  Validation Loss: 5.1288\n",
            "Epoch 2: Training loss: 5.0872  Validation Loss: 3.8298\n",
            "Epoch 3: Training loss: 3.8332  Validation Loss: 2.1225\n",
            "Epoch 4: Training loss: 2.1898  Validation Loss: 1.6037\n",
            "Epoch 5: Training loss: 1.6018  Validation Loss: 2.1377\n",
            "Epoch 6: Training loss: 2.1208  Validation Loss: 1.1950\n",
            "Epoch 7: Training loss: 1.2404  Validation Loss: 1.5429\n",
            "Epoch 8: Training loss: 1.6251  Validation Loss: 1.4145\n",
            "Epoch 9: Training loss: 1.4366  Validation Loss: 1.0139\n",
            "test loss 1.014 \n",
            "===== Experiment 56 =====\n",
            "wd: 0.1, emb_size: 150, hidden_size: 10\n",
            "Epoch 0: Training loss: 12.6955  Validation Loss: 15.2722\n",
            "Epoch 1: Training loss: 15.1598  Validation Loss: 10.9954\n",
            "Epoch 2: Training loss: 10.9143  Validation Loss: 3.2311\n",
            "Epoch 3: Training loss: 3.2164  Validation Loss: 4.3699\n",
            "Epoch 4: Training loss: 4.4919  Validation Loss: 1.0707\n",
            "Epoch 5: Training loss: 1.0780  Validation Loss: 4.9238\n",
            "Epoch 6: Training loss: 4.8802  Validation Loss: 5.8848\n",
            "Epoch 7: Training loss: 5.8396  Validation Loss: 4.0105\n",
            "Epoch 8: Training loss: 3.9880  Validation Loss: 1.4920\n",
            "Epoch 9: Training loss: 1.5099  Validation Loss: 1.2518\n",
            "test loss 1.252 \n",
            "===== Experiment 57 =====\n",
            "wd: 0.1, emb_size: 150, hidden_size: 20\n",
            "Epoch 0: Training loss: 12.1164  Validation Loss: 15.0673\n",
            "Epoch 1: Training loss: 14.9573  Validation Loss: 9.0368\n",
            "Epoch 2: Training loss: 8.9721  Validation Loss: 7.7855\n",
            "Epoch 3: Training loss: 7.7339  Validation Loss: 1.6887\n",
            "Epoch 4: Training loss: 1.6961  Validation Loss: 4.5430\n",
            "Epoch 5: Training loss: 4.6636  Validation Loss: 3.1590\n",
            "Epoch 6: Training loss: 3.1312  Validation Loss: 4.8362\n",
            "Epoch 7: Training loss: 4.8021  Validation Loss: 2.5520\n",
            "Epoch 8: Training loss: 2.5466  Validation Loss: 1.6465\n",
            "Epoch 9: Training loss: 1.7300  Validation Loss: 1.4772\n",
            "test loss 1.477 \n",
            "===== Experiment 58 =====\n",
            "wd: 0.1, emb_size: 150, hidden_size: 30\n",
            "Epoch 0: Training loss: 12.9109  Validation Loss: 12.9931\n",
            "Epoch 1: Training loss: 12.8996  Validation Loss: 8.1830\n",
            "Epoch 2: Training loss: 8.1247  Validation Loss: 4.9507\n",
            "Epoch 3: Training loss: 4.9537  Validation Loss: 2.3425\n",
            "Epoch 4: Training loss: 2.3876  Validation Loss: 2.5717\n",
            "Epoch 5: Training loss: 2.5722  Validation Loss: 4.0601\n",
            "Epoch 6: Training loss: 4.0267  Validation Loss: 2.3844\n",
            "Epoch 7: Training loss: 2.3803  Validation Loss: 2.4470\n",
            "Epoch 8: Training loss: 2.4361  Validation Loss: 1.0708\n",
            "Epoch 9: Training loss: 1.1084  Validation Loss: 2.1286\n",
            "test loss 2.129 \n",
            "===== Experiment 59 =====\n",
            "wd: 0.1, emb_size: 150, hidden_size: 40\n",
            "Epoch 0: Training loss: 13.0530  Validation Loss: 12.1540\n",
            "Epoch 1: Training loss: 12.0673  Validation Loss: 7.2005\n",
            "Epoch 2: Training loss: 7.1464  Validation Loss: 1.9673\n",
            "Epoch 3: Training loss: 2.0054  Validation Loss: 1.3535\n",
            "Epoch 4: Training loss: 1.3870  Validation Loss: 5.9714\n",
            "Epoch 5: Training loss: 5.9089  Validation Loss: 4.8327\n",
            "Epoch 6: Training loss: 4.7821  Validation Loss: 1.7404\n",
            "Epoch 7: Training loss: 1.7635  Validation Loss: 1.0237\n",
            "Epoch 8: Training loss: 1.0528  Validation Loss: 1.1549\n",
            "Epoch 9: Training loss: 1.1957  Validation Loss: 1.4964\n",
            "test loss 1.496 \n",
            "===== Experiment 60 =====\n",
            "wd: 0.1, emb_size: 200, hidden_size: 10\n",
            "Epoch 0: Training loss: 13.1219  Validation Loss: 18.2198\n",
            "Epoch 1: Training loss: 18.0915  Validation Loss: 10.4096\n",
            "Epoch 2: Training loss: 10.3353  Validation Loss: 5.8089\n",
            "Epoch 3: Training loss: 5.7700  Validation Loss: 1.0581\n",
            "Epoch 4: Training loss: 1.0913  Validation Loss: 1.1586\n",
            "Epoch 5: Training loss: 1.2049  Validation Loss: 2.8444\n",
            "Epoch 6: Training loss: 2.8104  Validation Loss: 4.3939\n",
            "Epoch 7: Training loss: 4.3620  Validation Loss: 2.1576\n",
            "Epoch 8: Training loss: 2.1611  Validation Loss: 1.0752\n",
            "Epoch 9: Training loss: 1.1140  Validation Loss: 1.1863\n",
            "test loss 1.186 \n",
            "===== Experiment 61 =====\n",
            "wd: 0.1, emb_size: 200, hidden_size: 20\n",
            "Epoch 0: Training loss: 13.1978  Validation Loss: 15.5198\n",
            "Epoch 1: Training loss: 15.4131  Validation Loss: 7.8186\n",
            "Epoch 2: Training loss: 7.7640  Validation Loss: 6.2365\n",
            "Epoch 3: Training loss: 6.2078  Validation Loss: 1.1795\n",
            "Epoch 4: Training loss: 1.2154  Validation Loss: 1.0324\n",
            "Epoch 5: Training loss: 1.0566  Validation Loss: 2.7469\n",
            "Epoch 6: Training loss: 2.7284  Validation Loss: 2.0791\n",
            "Epoch 7: Training loss: 2.0903  Validation Loss: 1.1328\n",
            "Epoch 8: Training loss: 1.1622  Validation Loss: 1.0739\n",
            "Epoch 9: Training loss: 1.1048  Validation Loss: 1.1977\n",
            "test loss 1.198 \n",
            "===== Experiment 62 =====\n",
            "wd: 0.1, emb_size: 200, hidden_size: 30\n",
            "Epoch 0: Training loss: 13.0908  Validation Loss: 14.7737\n",
            "Epoch 1: Training loss: 14.6650  Validation Loss: 5.8021\n",
            "Epoch 2: Training loss: 5.7665  Validation Loss: 1.8158\n",
            "Epoch 3: Training loss: 1.8683  Validation Loss: 10.2283\n",
            "Epoch 4: Training loss: 10.2319  Validation Loss: 2.6052\n",
            "Epoch 5: Training loss: 2.5996  Validation Loss: 5.7657\n",
            "Epoch 6: Training loss: 5.7883  Validation Loss: 3.6455\n",
            "Epoch 7: Training loss: 3.7587  Validation Loss: 1.0122\n",
            "Epoch 8: Training loss: 1.0257  Validation Loss: 2.8638\n",
            "Epoch 9: Training loss: 2.8445  Validation Loss: 4.2097\n",
            "test loss 4.210 \n",
            "===== Experiment 63 =====\n",
            "wd: 0.1, emb_size: 200, hidden_size: 40\n",
            "Epoch 0: Training loss: 14.0053  Validation Loss: 8.5959\n",
            "Epoch 1: Training loss: 8.5361  Validation Loss: 1.1594\n",
            "Epoch 2: Training loss: 1.1948  Validation Loss: 3.1937\n",
            "Epoch 3: Training loss: 3.1996  Validation Loss: 9.5013\n",
            "Epoch 4: Training loss: 9.7236  Validation Loss: 3.9572\n",
            "Epoch 5: Training loss: 3.9258  Validation Loss: 6.7327\n",
            "Epoch 6: Training loss: 6.6804  Validation Loss: 1.8811\n",
            "Epoch 7: Training loss: 1.8930  Validation Loss: 1.2142\n",
            "Epoch 8: Training loss: 1.2576  Validation Loss: 1.3882\n",
            "Epoch 9: Training loss: 1.4008  Validation Loss: 1.4350\n",
            "test loss 1.435 \n",
            "====== Best Performing Model ======\n",
            "Best result: 0.9139562249183655\n",
            "Best hyperparameters: wd=0.01, emb_size=100, hidden_size=10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the experiments, the best performing model based on the lowest validation loss had the following hyperparameters:\n",
        "\n",
        "\n",
        "*   Embedding size of 100\n",
        "*   Regularization of 0.01\n",
        "*   Hidden layer size of 10\n"
      ],
      "metadata": {
        "id": "5s9nj6cbNqNi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparison of the best NCF-GMF and NCF-MLP models"
      ],
      "metadata": {
        "id": "q573mVcK22rG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The below table summarizes the results for the best NCF-GMF and NCF-MLP models. Overall, the NCF-MLP model achieved a lower validation loss than the NCF-GMF model.\n",
        "\n",
        "\n",
        "| Model       | Hyperparameters    | Val Loss Result   |\n",
        "|-------------|--------------------|-------------------|\n",
        "| NCF-GMF     | wd=0.0, emb_size=100 | 1.8510          |\n",
        "| NCF-MLP     | wd=0.01, emb_size=100, hidden_size=10 | 0.9140 |          "
      ],
      "metadata": {
        "id": "SsrbJN8r272U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Change to Binary Ratings (1 or 0)"
      ],
      "metadata": {
        "id": "n70Cj_al3FGB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def binarize_data(df):\n",
        "    \"\"\" Encodes rating data to be 1 or 0.\"\"\"\n",
        "    df = df.copy()\n",
        "    df[\"rating\"] = df[\"rating\"].apply(lambda x: 1.0 if x >= 3 else 0.0)\n",
        "    return df"
      ],
      "metadata": {
        "id": "Cd_Dgz3F3NiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_bin = binarize_data(df_train)\n",
        "df_val_bin = binarize_data(df_val)"
      ],
      "metadata": {
        "id": "Ehu0Ow9eQBso"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_bin.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "yHwMnXjGQJf0",
        "outputId": "273a2773-8f89-4b77-b581-ee56d5e4b3ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   userId  movieId  rating  timestamp\n",
              "0       0        0     1.0  964982703\n",
              "1       0        1     1.0  964981247\n",
              "2       0        2     1.0  964982224\n",
              "3       0        3     1.0  964983815\n",
              "6       0        4     1.0  964980868"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-19e1d267-106e-4a3e-9518-a2ec611788b2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>964982703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>964981247</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>964982224</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>964983815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>964980868</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-19e1d267-106e-4a3e-9518-a2ec611788b2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-19e1d267-106e-4a3e-9518-a2ec611788b2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-19e1d267-106e-4a3e-9518-a2ec611788b2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6c01732d-2063-4d30-96ab-ddc609df0fb4\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6c01732d-2063-4d30-96ab-ddc609df0fb4')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6c01732d-2063-4d30-96ab-ddc609df0fb4 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# NCF-GMF Model - switch train loop to use binarized data\n",
        "def train_epocs(model, epochs=10, lr=0.01, wd=0.0):\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
        "    model.train()\n",
        "    for i in range(epochs):\n",
        "        # Train\n",
        "        users = torch.LongTensor(df_train_bin.userId.values) # .cuda()\n",
        "        items = torch.LongTensor(df_train_bin.movieId.values) #.cuda()\n",
        "        ratings = torch.FloatTensor(df_train_bin.rating.values) #.cuda()\n",
        "\n",
        "        y_hat = model(users, items)\n",
        "        loss = F.mse_loss(y_hat, ratings)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Val\n",
        "        users_val = torch.LongTensor(df_val_bin.userId.values) # .cuda()\n",
        "        items_val = torch.LongTensor(df_val_bin.movieId.values) #.cuda()\n",
        "        ratings_val = torch.FloatTensor(df_val_bin.rating.values) #.cuda()\n",
        "\n",
        "        y_hat_val = model(users_val, items_val)\n",
        "        loss_val = F.mse_loss(y_hat_val, ratings_val)\n",
        "\n",
        "        # Display loss\n",
        "        print(f\"Epoch {i}: Training loss: {loss.item():.4f}  Validation loss: {loss_val.item():.4f}\")\n",
        "\n",
        "    final_val_loss_value = test_loss(model)\n",
        "    return final_val_loss_value\n",
        "\n",
        "def test_loss(model):\n",
        "    model.eval()\n",
        "    users = torch.LongTensor(df_val_bin.userId.values) #.cuda()\n",
        "    items = torch.LongTensor(df_val_bin.movieId.values) #.cuda()\n",
        "    ratings = torch.FloatTensor(df_val_bin.rating.values) #.cuda()\n",
        "    y_hat = model(users, items)\n",
        "    loss = F.mse_loss(y_hat, ratings)\n",
        "    print(\"test loss %.3f \" % loss.item())\n",
        "    return loss.item()\n",
        "\n",
        "# Best NCF-GMF Model\n",
        "model = MF(num_users, num_items, emb_size=100)\n",
        "val_loss_result = train_epocs(model, epochs=10, lr=0.1, wd=0.0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0wM33D2hU5Y",
        "outputId": "ab7b8f41-a8b9-4850-ef75-a3775e45a2d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: Training loss: 0.7124  Validation loss: 0.6897\n",
            "Epoch 1: Training loss: 0.6684  Validation loss: 0.2764\n",
            "Epoch 2: Training loss: 0.2617  Validation loss: 0.5413\n",
            "Epoch 3: Training loss: 0.5215  Validation loss: 0.5745\n",
            "Epoch 4: Training loss: 0.5458  Validation loss: 0.4907\n",
            "Epoch 5: Training loss: 0.4491  Validation loss: 0.3998\n",
            "Epoch 6: Training loss: 0.3496  Validation loss: 0.3715\n",
            "Epoch 7: Training loss: 0.3202  Validation loss: 0.2689\n",
            "Epoch 8: Training loss: 0.2262  Validation loss: 0.2001\n",
            "Epoch 9: Training loss: 0.1691  Validation loss: 0.2296\n",
            "test loss 0.230 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# NCF-MLP Model - switch train loop to use binarized data\n",
        "def train_epocs(model, epochs=10, lr=0.01, wd=0.0):\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        # Train\n",
        "        users = torch.LongTensor(df_train_bin.userId.values) # .cuda()\n",
        "        items = torch.LongTensor(df_train_bin.movieId.values) #.cuda()\n",
        "        ratings = torch.FloatTensor(df_train_bin.rating.values) #.cuda()\n",
        "\n",
        "        y_hat = model(users, items)\n",
        "        loss = F.mse_loss(y_hat, ratings)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Val\n",
        "        users_val = torch.LongTensor(df_val_bin.userId.values) # .cuda()\n",
        "        items_val = torch.LongTensor(df_val_bin.movieId.values) #.cuda()\n",
        "        ratings_val = torch.FloatTensor(df_val_bin.rating.values) #.cuda()\n",
        "\n",
        "        y_hat_val = model(users_val, items_val)\n",
        "        loss_val = F.mse_loss(y_hat_val, ratings_val)\n",
        "\n",
        "        print(f'Epoch {epoch}: Training loss: {loss.item():.4f}  Validation Loss: {loss_val.item():.4f}')\n",
        "\n",
        "    # Val result\n",
        "    final_val_loss_result = test_loss(model)\n",
        "    return final_val_loss_result\n",
        "\n",
        "def test_loss(model):\n",
        "    model.eval()\n",
        "    users = torch.LongTensor(df_val_bin.userId.values) #.cuda()\n",
        "    items = torch.LongTensor(df_val_bin.movieId.values) #.cuda()\n",
        "    ratings = torch.FloatTensor(df_val_bin.rating.values) #.cuda()\n",
        "    y_hat = model(users, items)\n",
        "    loss = F.mse_loss(y_hat, ratings)\n",
        "    print(\"test loss %.3f \" % loss.item())\n",
        "    return loss.item()\n",
        "\n",
        "# Best NCF-MLP Model\n",
        "model = my_NCF_MLP(num_users, num_items, emb_size=100, hidden_size=10)\n",
        "val_loss_result = train_epocs(model, epochs=10, lr=0.1, wd=0.01)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "paxPPE2VQRpJ",
        "outputId": "f26e4276-0e8c-4332-e39a-90cbd88e3780"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: Training loss: 0.6702  Validation Loss: 0.7594\n",
            "Epoch 1: Training loss: 0.7479  Validation Loss: 0.2823\n",
            "Epoch 2: Training loss: 0.2819  Validation Loss: 0.3694\n",
            "Epoch 3: Training loss: 0.3830  Validation Loss: 0.2585\n",
            "Epoch 4: Training loss: 0.2624  Validation Loss: 0.1839\n",
            "Epoch 5: Training loss: 0.1908  Validation Loss: 0.2264\n",
            "Epoch 6: Training loss: 0.2384  Validation Loss: 0.2183\n",
            "Epoch 7: Training loss: 0.2309  Validation Loss: 0.1679\n",
            "Epoch 8: Training loss: 0.1749  Validation Loss: 0.1598\n",
            "Epoch 9: Training loss: 0.1617  Validation Loss: 0.1737\n",
            "test loss 0.174 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the best NCF-GMF and NCF-MLP models, the following table summarizes the results that were obtained with using binary ratings. Consistent with previous findings, the NCF-MLP model exhibited a lower validation loss than the NCF-GMF model. Notably, the validation loss for both models was lower compared to their performance with non-binarized ratings. This result aligns with expectations, as predicting binary ratings is generally simpler than predicting a broader range of ratings (1-5). To change the model implementation to better conform to the dataset, we can incorporate a sigmoid activation function at the end to ensure the output values are between 0 and 1 to align with the binary ratings.\n",
        "\n",
        "| Model       | Hyperparameters    | Val Loss Result   |\n",
        "|-------------|--------------------|-------------------|\n",
        "| NCF-GMF     | wd=0.0, emb_size=100 | 0.230          |\n",
        "| NCF-MLP     | wd=0.01, emb_size=100, hidden_size=10 | 0.174  |    "
      ],
      "metadata": {
        "id": "ZgKSEl313IpU"
      }
    }
  ]
}