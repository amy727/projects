{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1o2aiO9UP-L"
      },
      "source": [
        "# ECE324 Mini-Project 1\n",
        "\n",
        "Amy Chen, 1005915495"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lW0QZ5e2uT-J"
      },
      "source": [
        "## Initial Setup\n",
        "\n",
        "The initial setup contains the library imports and functions for data preprocessing. As mentioned in the function descriptions, the 7 selected features that were used for parts 1 and 2 are: Age, Sex, Juvenile misdemeanor count, Juvenile felonies count, Priors count, Charge degree, and Charge description. One-hot encoding was applied to the following features: Sex, Charge degree, and Charge description."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S6cd3lHmUKlp"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "voKtSbJ1xI19"
      },
      "outputs": [],
      "source": [
        "# Functions for data preprocessing that are used in both part 1 and part 2\n",
        "\n",
        "def encode_and_bind(og_df, feature_to_encode):\n",
        "    \"\"\"\n",
        "    Performs one-hot encoding and concatenates the encoded columns into the dataframe\n",
        "    \"\"\"\n",
        "    encoding = pd.get_dummies(og_df[[feature_to_encode]])\n",
        "    new_df = pd.concat([og_df, encoding], axis=1)\n",
        "    new_df = new_df.drop([feature_to_encode], axis=1)\n",
        "    return new_df\n",
        "\n",
        "def selected_features(og_df):\n",
        "    \"\"\"\n",
        "    Selects the features and performs one-hot encoding on certain features\n",
        "    The 7 selected features are:\n",
        "      - Age\n",
        "      - Sex\n",
        "      - Juvenile misdemeanor count\n",
        "      - Juvenile felonies count\n",
        "      - Priors count\n",
        "      - Charge degree\n",
        "      - Charge description\n",
        "    One-hot encoding is applied to the following features:\n",
        "      - Sex\n",
        "      - Charge degree\n",
        "      - Charge description\n",
        "    The race and two-year-recividism are kept in the dataset for now but will be removed later\n",
        "    \"\"\"\n",
        "    new_df = og_df[['age', 'sex', 'juv_misd_count', 'juv_fel_count', 'priors_count', 'c_charge_degree', 'c_charge_desc', 'race', 'two_year_recid']]\n",
        "    new_df = encode_and_bind(new_df, 'sex')\n",
        "    new_df = encode_and_bind(new_df, 'c_charge_degree')\n",
        "    new_df = encode_and_bind(new_df, 'c_charge_desc')\n",
        "    return new_df\n",
        "\n",
        "def drop_selected_features(og_df):\n",
        "    \"\"\"\n",
        "    Drops the race and two-year recividism columns that are not used as model inputs\n",
        "    \"\"\"\n",
        "    new_df = og_df.drop(['race'], axis=1)\n",
        "    new_df = new_df.drop(['two_year_recid'], axis=1)\n",
        "    return new_df\n",
        "\n",
        "def drop_rows(og_df):\n",
        "    \"\"\"\n",
        "    Drops the rows for all other races other than Caucasian and African-American\n",
        "    \"\"\"\n",
        "    new_df = og_df.drop(og_df[og_df.race == 'Hispanic'].index)\n",
        "    new_df = new_df.drop(new_df[new_df.race == 'Other'].index)\n",
        "    new_df = new_df.drop(new_df[new_df.race == 'Native American'].index)\n",
        "    new_df = new_df.drop(new_df[new_df.race == 'Asian'].index)\n",
        "    return new_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRfX-KIfPZH9"
      },
      "source": [
        "## Part 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFIMxkuDsgI9"
      },
      "source": [
        "The following class defines the Logistic Regresssion model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5tfZ8UqZ2UGV"
      },
      "outputs": [],
      "source": [
        "class LogisticRegression(torch.nn.Module):\n",
        "     \n",
        "     def __init__(self, input_dim, output_dim):\n",
        "         super(LogisticRegression, self).__init__()\n",
        "         self.linear = torch.nn.Linear(input_dim, output_dim)\n",
        "     \n",
        "     def forward(self, x):\n",
        "         y_pred = torch.sigmoid(self.linear(x))\n",
        "         return y_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2Dm3wZPsmY0"
      },
      "source": [
        "Data preprocessing was done using the functions that were defined earlier. Only the seven features that was mentioned by the paper by Dressel et al. were used and one-hot encoding was performed on the non-numerical features. As well, the inputs were all converted into torch tensors so that they were in the correct format that was needed for the model. The testing data was also separated into two groups based on race (Caucasian and African-American) in order to determine if FPR parity and calibration are satisfied."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jf-fLzoqVQlN",
        "outputId": "dc9813fe-241d-4466-adba-a221ccfa38e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==== Base Rates ====\n",
            "\n",
            "Caucasians:\n",
            "Total number: 2454\n",
            "Number that recidivated: 966\n",
            "Recidivism Rate: 39.3643%\n",
            "\n",
            "African-Americans:\n",
            "Total number: 3696\n",
            "Number that recidivated: 1901\n",
            "Recidivism Rate: 51.4340%\n"
          ]
        }
      ],
      "source": [
        "# Read in data as a dataframe\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/propublica/compas-analysis/master/compas-scores-two-years.csv')\n",
        "\n",
        "# Get selected features from dataset and split into training and test set\n",
        "df = selected_features(df)\n",
        "data_train, data_test = train_test_split(df, test_size=0.20, random_state=25)\n",
        "\n",
        "# Print base rates from dataset\n",
        "c = df.loc[df['race'] == 'Caucasian']\n",
        "aa = df.loc[df['race'] == 'African-American']\n",
        "c_recidivate = c.loc[c['two_year_recid'] == 1]\n",
        "aa_recidivate = aa.loc[aa['two_year_recid'] == 1]\n",
        "print(\"==== Base Rates ====\")\n",
        "print(\"\\nCaucasians:\")\n",
        "print(\"Total number: %d\" %(len(c)))\n",
        "print(\"Number that recidivated: %d\" %(len(c_recidivate)))\n",
        "print(\"Recidivism Rate: %.4f%%\" %(100.0*len(c_recidivate)/len(c)))\n",
        "print(\"\\nAfrican-Americans:\")\n",
        "print(\"Total number: %d\" %(len(aa)))\n",
        "print(\"Number that recidivated: %d\" %(len(aa_recidivate)))\n",
        "print(\"Recidivism Rate: %.4f%%\" %(100.0*len(aa_recidivate)/len(aa)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gs-85gfGy-Uc"
      },
      "outputs": [],
      "source": [
        "# ==== Training Data ====\n",
        "x_train = drop_selected_features(data_train) # Training input data\n",
        "y_train = data_train['two_year_recid'] # Training labels\n",
        "\n",
        "x_train_tensor = torch.tensor(x_train.values.astype(np.float32)) # Training input data tensor\n",
        "y_train_tensor = torch.tensor(y_train.values.astype(np.float32)) # Training labels tensor\n",
        "\n",
        "# ==== Testing Data with features ====\n",
        "\n",
        "# Testing inputs and labels for Caucasian race\n",
        "x_test_c = data_test.loc[data_test['race'] == 'Caucasian']\n",
        "y_test_c = x_test_c['two_year_recid']\n",
        "x_test_c = drop_selected_features(x_test_c)\n",
        "\n",
        "# Testing inputs and labels for African-American race\n",
        "x_test_aa = data_test.loc[data_test['race'] == 'African-American']\n",
        "y_test_aa = x_test_aa['two_year_recid']\n",
        "x_test_aa = drop_selected_features(x_test_aa)\n",
        "\n",
        "# Testing tensors\n",
        "x_test_c_tensor = torch.tensor(x_test_c.values.astype(np.float32))\n",
        "y_test_c_tensor = torch.tensor(y_test_c.values.astype(np.float32))\n",
        "x_test_aa_tensor = torch.tensor(x_test_aa.values.astype(np.float32))\n",
        "y_test_aa_tensor = torch.tensor(y_test_aa.values.astype(np.float32))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSI_8HcKsyT7"
      },
      "source": [
        "The following defines the logistic regression model with binary cross-entropy loss and the SGD optimizer with a learning rate of 0.001."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UyIVw-dFCAmr"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "input_dim = len(x_train.columns)\n",
        "output_dim = 1\n",
        "learningRate = 0.001\n",
        "numEpochs = 200\n",
        "\n",
        "# Model, loss, and optimizer initializations\n",
        "model = LogisticRegression(input_dim,output_dim) # Initialize logistic regression model\n",
        "lossFunc = torch.nn.BCELoss() # Binary Cross-Entropy Loss\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learningRate) # Initialize SGD optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPM_9hJntC_2"
      },
      "source": [
        "The model was trained for a total of 200 epochs and the training loss and accuracy is plotted below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "zUwDNz5RC0qp",
        "outputId": "5a046ada-8e3c-4bd9-bbfc-f8f69ba119c5"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# ==== Model Training ====\n",
        "\n",
        "# Variables to keep track of loss and accuracy\n",
        "train_losses = []\n",
        "train_accuracies = []\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(numEpochs):\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Model predictions\n",
        "    y_train_pred = torch.squeeze(model(x_train_tensor))\n",
        "\n",
        "    # Get loss\n",
        "    train_loss = lossFunc(y_train_pred, y_train_tensor)\n",
        "\n",
        "    train_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Append loss and accuracy to arrays\n",
        "    train_losses.append(100.0*train_loss.detach().numpy())\n",
        "    train_acc = 100.0*(np.sum(y_train_pred.round().detach().numpy() == y_train_tensor.detach().numpy())/len(y_train_tensor))\n",
        "    train_accuracies.append(train_acc)\n",
        "\n",
        "    #print('=== Epoch %04d  Training Loss %.4f Training Accuracy %.4f Testing Loss %.4f Testing Accuracy %.4f ===' % (epoch + 1, train_loss, train_acc, test_loss, test_acc))\n",
        "\n",
        "# Plot Loss and Accuracy\n",
        "plt.title(\"Training Loss and Accuracy\")\n",
        "plt.plot(train_losses, label=\"Training Loss\")\n",
        "plt.plot(train_accuracies, label=\"Training Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss/Accuracy (%)\")\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJyWiY_--M8V"
      },
      "source": [
        "### Part 1a) Model Satisfies Calibration but Not FPR Parity\n",
        "\n",
        "From the test results, we can calculate the FPR, PPV, and NPV of both the racial groups using the following formulas:\n",
        "\n",
        "> FPR (%) = 100 * FP / (FP + TN)\n",
        ">\n",
        "> PPV (%) = 100 * TP / (TP + FP)\n",
        ">\n",
        "> NPV (%) = 100 * FN / (TN + FN)\n",
        ">\n",
        "> where TP = True Positives, TN = True Negatives, FP = False Positives, FN = False Negatives\n",
        "\n",
        "To see if FPR parity is satisfied (ie. there is equal FPR across race groups), we calculate the FPR for the two racial groups and see if the difference is less than 5%. To see if calibration is satisfied (ie. the proportion that would reoffend if released is equal across race groups), we check for PPV and NPV parity such that there is a less than 5% difference in both the PPV and NPV for the two racial groups.\n",
        "\n",
        "From the results we can see that for the model we were unable to satisfy FPR parity but satisfied both PPV and NPV parity and so therefore satisfied calibration.\n",
        "\n",
        "The difference in base rates in the dataset show that there is a higher recidivism rate for African Americans which may bias the model to have a higher tendency to classify those as African American as recidivating. Therefore, this would lead to a higher FPR for African American's and a lower FPR for Caucasian's, resulting in a higher FPR difference between the two racial groups such that FPR parity is not satisfied."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwfC03uaw0uH",
        "outputId": "b57b333e-bfcc-4bc6-86a4-2d6e872d524a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "====== Test Results for Race: African American ======\n",
            "TN: 318, FP: 53, FN: 240, TP: 140\n",
            "Recidivism Number: 380, Total Number: 751, Recidivism Rate: 0.5060\n",
            "False Positive Rate (FPR): 14.2857%\n",
            "Positive Predictive Value (PPV): 72.5389%\n",
            "Negative Predictive Value (NPV): 43.0108%\n",
            "\n",
            "\n",
            "====== Test Results for Race: Caucasian ======\n",
            "TN: 260, FP: 13, FN: 169, TP: 37\n",
            "Recidivism Number: 206, Total Number: 479, Recidivism Rate: 0.4301\n",
            "False Positive Rate (FPR): 4.7619%\n",
            "Positive Predictive Value (PPV): 74.0000%\n",
            "Negative Predictive Value (NPV): 39.3939%\n",
            "\n",
            "\n",
            "====== Test Results ======\n",
            "Testing Accuracy: 61.3821%\n",
            "Difference in FPR between races: 9.5238%\n",
            "Difference in PPV between races: 1.4611%\n",
            "Difference in NPV between races: 3.6168%\n"
          ]
        }
      ],
      "source": [
        "# ==== Test Results ====\n",
        "\n",
        "# Get predictions\n",
        "y_test_pred_c = torch.squeeze(model(x_test_c_tensor)).round().detach().numpy()\n",
        "y_test_pred_aa = torch.squeeze(model(x_test_aa_tensor)).round().detach().numpy()\n",
        "\n",
        "# Results for African American Race\n",
        "aa_cm = confusion_matrix(y_test_aa_tensor.detach().numpy(), y_test_pred_aa)\n",
        "aa_tn, aa_fp, aa_fn, aa_tp = aa_cm.ravel()\n",
        "aa_fpr = 100.0*aa_fp/(aa_fp+aa_tn)\n",
        "aa_ppv = 100.0*aa_tp/(aa_tp+aa_fp)\n",
        "aa_npv = 100.0*aa_fn/(aa_tn+aa_fn)\n",
        "print(\"====== Test Results for Race: African American ======\")\n",
        "print(\"TN: %d, FP: %d, FN: %d, TP: %d\" %(aa_tn, aa_fp, aa_fn, aa_tp))\n",
        "print(\"Recidivism Number: %d, Total Number: %d, Recidivism Rate: %.4f\" %(np.sum(y_test_aa_tensor.detach().numpy()), \n",
        "                                                  len(y_test_aa_tensor), \n",
        "                                                  np.sum(y_test_aa_tensor.detach().numpy())/len(y_test_aa_tensor)))\n",
        "print(\"False Positive Rate (FPR): %.4f%%\" %(aa_fpr))\n",
        "print(\"Positive Predictive Value (PPV): %.4f%%\" %(aa_ppv))\n",
        "print(\"Negative Predictive Value (NPV): %.4f%%\" %(aa_npv))\n",
        "print(\"\\n\")\n",
        "\n",
        "# Results for Caucasian Race\n",
        "c_cm = confusion_matrix(y_test_c_tensor.detach().numpy(), y_test_pred_c)\n",
        "c_tn, c_fp, c_fn, c_tp = c_cm.ravel()\n",
        "c_fpr = 100.0*c_fp/(c_fp+c_tn)\n",
        "c_ppv = 100.0*c_tp/(c_tp+c_fp)\n",
        "c_npv = 100.0*c_fn/(c_tn+c_fn)\n",
        "print(\"====== Test Results for Race: Caucasian ======\")\n",
        "print(\"TN: %d, FP: %d, FN: %d, TP: %d\" %(c_tn, c_fp, c_fn, c_tp))\n",
        "print(\"Recidivism Number: %d, Total Number: %d, Recidivism Rate: %.4f\" %(np.sum(y_test_c_tensor.detach().numpy()), \n",
        "                                                  len(y_test_c_tensor), \n",
        "                                                  np.sum(y_test_c_tensor.detach().numpy())/len(y_test_c_tensor)))\n",
        "print(\"False Positive Rate (FPR): %.4f%%\" %(c_fpr))\n",
        "print(\"Positive Predictive Value (PPV): %.4f%%\" %(c_ppv))\n",
        "print(\"Negative Predictive Value (NPV): %.4f%%\" %(c_npv))\n",
        "print(\"\\n\")\n",
        "\n",
        "# Test Results\n",
        "print(\"====== Test Results ======\")\n",
        "print(\"Testing Accuracy: %.4f%%\" %(100.0*(aa_tn + aa_tp + c_tn + c_tp)/(aa_tn + aa_fp + aa_fn + aa_tp + c_tn + c_fp + c_fn + c_tp)))\n",
        "print(\"Difference in FPR between races: %.4f%%\" %(abs(aa_fpr - c_fpr)))\n",
        "print(\"Difference in PPV between races: %.4f%%\" %(abs(aa_ppv - c_ppv)))\n",
        "print(\"Difference in NPV between races: %.4f%%\" %(abs(aa_npv - c_npv)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJnK_lCu-R2b"
      },
      "source": [
        "### Part 1b) Threshold Adjustment Satisifes FPR parity but not calibration\n",
        "\n",
        "The same calculations as above were used to determine if FPR parity and calibration are satisfied.\n",
        "\n",
        "The threshold was adjusted with the threshold for African-Americans being 0.7 and the threshold for Caucasians being 0.6. From the results below it can be seen that adjusting the thresholds led to FPR parity being satisfied but calibration was not satisfied."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fq0EYbtpeDoj",
        "outputId": "7efede00-d2c3-412f-99a2-51a72817d071"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "====== Test Results for Race: African American ======\n",
            "TN: 368, FP: 3, FN: 361, TP: 19\n",
            "False Positive Rate (FPR): 0.8086%\n",
            "Positive Predictive Value (PPV): 86.3636%\n",
            "Negative Predictive Value (NPV): 49.5199%\n",
            "\n",
            "\n",
            "====== Test Results for Race: Caucasian ======\n",
            "TN: 271, FP: 2, FN: 198, TP: 8\n",
            "False Positive Rate (FPR): 0.7326%\n",
            "Positive Predictive Value (PPV): 80.0000%\n",
            "Negative Predictive Value (NPV): 42.2175%\n",
            "\n",
            "\n",
            "====== Test Results ======\n",
            "Testing Accuracy: 54.1463%\n",
            "Difference in FPR between races: 0.0760%\n",
            "Difference in PPV between races: 6.3636%\n",
            "Difference in NPV between races: 7.3024%\n"
          ]
        }
      ],
      "source": [
        "# ==== Test Results with Threshold Adjustment ====\n",
        "\n",
        "# Get predictions\n",
        "y_test_pred_c = torch.squeeze(model(x_test_c_tensor)).detach().numpy()\n",
        "y_test_pred_c = np.where(y_test_pred_c > 0.6, 1, 0)\n",
        "y_test_pred_aa = torch.squeeze(model(x_test_aa_tensor)).detach().numpy()\n",
        "y_test_pred_aa = np.where(y_test_pred_aa > 0.7, 1, 0)\n",
        "\n",
        "# Results for African American Race\n",
        "aa_cm = confusion_matrix(y_test_aa_tensor.detach().numpy(), y_test_pred_aa)\n",
        "aa_tn, aa_fp, aa_fn, aa_tp = aa_cm.ravel()\n",
        "aa_fpr = 100.0*aa_fp/(aa_fp+aa_tn)\n",
        "aa_ppv = 100.0*aa_tp/(aa_tp+aa_fp)\n",
        "aa_npv = 100.0*aa_fn/(aa_tn+aa_fn)\n",
        "print(\"====== Test Results for Race: African American ======\")\n",
        "print(\"TN: %d, FP: %d, FN: %d, TP: %d\" %(aa_tn, aa_fp, aa_fn, aa_tp))\n",
        "print(\"False Positive Rate (FPR): %.4f%%\" %(aa_fpr))\n",
        "print(\"Positive Predictive Value (PPV): %.4f%%\" %(aa_ppv))\n",
        "print(\"Negative Predictive Value (NPV): %.4f%%\" %(aa_npv))\n",
        "print(\"\\n\")\n",
        "\n",
        "# Results for Caucasian Race\n",
        "c_cm = confusion_matrix(y_test_c_tensor.detach().numpy(), y_test_pred_c)\n",
        "c_tn, c_fp, c_fn, c_tp = c_cm.ravel()\n",
        "c_fpr = 100.0*c_fp/(c_fp+c_tn)\n",
        "c_ppv = 100.0*c_tp/(c_tp+c_fp)\n",
        "c_npv = 100.0*c_fn/(c_tn+c_fn)\n",
        "print(\"====== Test Results for Race: Caucasian ======\")\n",
        "print(\"TN: %d, FP: %d, FN: %d, TP: %d\" %(c_tn, c_fp, c_fn, c_tp))\n",
        "print(\"False Positive Rate (FPR): %.4f%%\" %(c_fpr))\n",
        "print(\"Positive Predictive Value (PPV): %.4f%%\" %(c_ppv))\n",
        "print(\"Negative Predictive Value (NPV): %.4f%%\" %(c_npv))\n",
        "print(\"\\n\")\n",
        "\n",
        "# Test Results\n",
        "print(\"====== Test Results ======\")\n",
        "print(\"Testing Accuracy: %.4f%%\" %(100.0*(aa_tn + aa_tp + c_tn + c_tp)/(aa_tn + aa_fp + aa_fn + aa_tp + c_tn + c_fp + c_fn + c_tp)))\n",
        "print(\"Difference in FPR between races: %.4f%%\" %(abs(aa_fpr - c_fpr)))\n",
        "print(\"Difference in PPV between races: %.4f%%\" %(abs(aa_ppv - c_ppv)))\n",
        "print(\"Difference in NPV between races: %.4f%%\" %(abs(aa_npv - c_npv)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_P5OxtiPczb"
      },
      "source": [
        "## Part 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SEcuWIMvV2g"
      },
      "source": [
        "The following classes define the main predictive network (N) and the adversarial network (A) based on the paper by Wadsworth et al. The adversarial network consists of an 100-unit hidden layer with ReLU activation and a sigmoid output layer and predicts the demographic (1 for Caucasian, 0 for African American). The main predictive networ consists of two 256-unit hidden layers with ReLU activation. The sigmoid output layer is added to the end of the main model during training to output the prediction for two-year recidivism."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LGP9VkKnPg5k"
      },
      "outputs": [],
      "source": [
        "class Adversary(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    The adversarial network (A). It consists of an 100-unit hidden layer with ReLU activation\n",
        "    and a sigmoid output layer.\n",
        "    \"\"\"\n",
        "     \n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(Adversary, self).__init__()\n",
        "        self.linear1 = torch.nn.Linear(input_dim, 100)\n",
        "        self.linearOut = torch.nn.Linear(100, output_dim)\n",
        "        self.activation = torch.nn.ReLU()\n",
        "        self.sigmoid = torch.nn.Sigmoid()\n",
        "     \n",
        "    def forward(self, x):\n",
        "        x = self.linear1(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.linearOut(x)\n",
        "        x = self.sigmoid(x)\n",
        "        return x\n",
        "\n",
        "class MainModel(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    The main predictive network (N). It consists of two 256-unit hidden layers with ReLU activation.\n",
        "    The sigmoid output layer is not defined here but will be implemented later during model training.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(MainModel, self).__init__()\n",
        "        self.linear1 = torch.nn.Linear(input_dim, 256)\n",
        "        self.linear2 = torch.nn.Linear(256, 256)\n",
        "        self.linearOut = torch.nn.Linear(256, output_dim)\n",
        "        self.activation = torch.nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear1(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.linear2(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.linearOut(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvRvK8jJxGvG"
      },
      "source": [
        "The following functions were used for model training and plotting. For each epoch in the training loop, the adversary was first optimized, then the whole network was optimized together using the Adam optimizer. \n",
        "\n",
        "To get the model predictions, the resulting logits from the main network are fed into the adversary model to get the adversarial predictions on the demographic, and the logits are also fed through a sigmoid output layer to get the main predictive model predictions on the two-year recidivism.\n",
        "\n",
        "The loss for both the main predictive network (Ly) and the adversarial network (Ld) were determined using the binary cross-entropy loss function. The loss for the whole model was calculated as L = Ly - alpha*Ld following the Wadsworth et al. paper. \n",
        "\n",
        "\n",
        "The validation loss, accuracy and FPR differences between the two race groups were also determined in the training loop.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "147JtTdVlloF"
      },
      "outputs": [],
      "source": [
        "def part2_train(input_dim, output_dim, learningRate, alpha, numEpochs, train_tensors, validation_tensors):\n",
        "    \"\"\"\n",
        "    This function creates and trains the model\n",
        "    \"\"\"\n",
        "    x_train_tensor, y_train_tensor, y_train_adv_tensor = train_tensors\n",
        "    x_valid_tensor, y_valid_tensor, y_valid_adv_tensor, x_valid_c_tensor, y_valid_c_tensor, x_valid_aa_tensor, y_valid_aa_tensor = validation_tensors\n",
        "\n",
        "    # Model, loss, and optimizer initializations\n",
        "    main_model = MainModel(input_dim, output_dim) # Initialize main model\n",
        "    adversary = Adversary(output_dim, output_dim) # Initialize adversary model\n",
        "    lossFunc = torch.nn.BCELoss() # Binary Cross-Entropy Loss\n",
        "    optimizer_adv = torch.optim.Adam(adversary.parameters(), lr=learningRate) # Optimizer for adversary\n",
        "    optimizer_all = torch.optim.Adam(list(main_model.parameters()) + list(adversary.parameters()), lr=learningRate) # Optimizer for all\n",
        "\n",
        "    # Variables to keep track of loss/accuracy and fpr\n",
        "    train_losses_L = [] # Training combined loss\n",
        "    train_accuracies = [] # Training accuracy\n",
        "    valid_losses_L = [] # Validation combined loss\n",
        "    valid_accuracies = [] # Validation accuracy\n",
        "    valid_fpr_diff = []\n",
        "\n",
        "    # Training Loop\n",
        "    for epoch in range(numEpochs):\n",
        "\n",
        "        # ========= Optimize A ==========\n",
        "        optimizer_adv.zero_grad()\n",
        "\n",
        "        # Get model predictions for A\n",
        "        y_adversary = torch.squeeze(adversary(main_model(x_train_tensor)))\n",
        "\n",
        "        # Loss function for model A\n",
        "        Ld = lossFunc(y_adversary, y_train_adv_tensor)\n",
        "\n",
        "        Ld.backward()\n",
        "        optimizer_adv.step()\n",
        "\n",
        "\n",
        "        # ========= Optimize A + N ========== \n",
        "        optimizer_all.zero_grad()\n",
        "\n",
        "        # Training model predictions\n",
        "        logits = main_model(x_train_tensor)\n",
        "        y_train_pred = torch.squeeze(torch.sigmoid(logits))\n",
        "        y_adversary = torch.squeeze(adversary(logits))\n",
        "\n",
        "        # Training Loss for combined model\n",
        "        Ly = lossFunc(y_train_pred, y_train_tensor)\n",
        "        Ld = lossFunc(y_adversary, y_train_adv_tensor)\n",
        "        L = Ly - alpha*Ld\n",
        "\n",
        "        # Validation Model predictions\n",
        "        valid_logits = main_model(x_valid_tensor)\n",
        "        y_valid_pred = torch.squeeze(torch.sigmoid(valid_logits))\n",
        "        y_valid_adversary = torch.squeeze(adversary(valid_logits))\n",
        "        y_valid_pred_c = torch.squeeze(torch.sigmoid(main_model(x_valid_c_tensor))).round().detach().numpy()\n",
        "        y_valid_pred_aa = torch.squeeze(torch.sigmoid(main_model(x_valid_aa_tensor))).round().detach().numpy()\n",
        "\n",
        "        # Validation FPR\n",
        "        aa_tn, aa_fp, aa_fn, aa_tp = confusion_matrix(y_valid_aa_tensor.detach().numpy(), y_valid_pred_aa).ravel()\n",
        "        aa_fpr = 100.0*aa_fp/(aa_fp+aa_tn)\n",
        "        c_tn, c_fp, c_fn, c_tp = confusion_matrix(y_valid_c_tensor.detach().numpy(), y_valid_pred_c).ravel()\n",
        "        c_fpr = 100.0*c_fp/(c_fp+c_tn)\n",
        "\n",
        "        # Validation Loss\n",
        "        Ly_valid = lossFunc(y_valid_pred, y_valid_tensor)\n",
        "        Ld_valid = lossFunc(y_valid_adversary, y_valid_adv_tensor)\n",
        "        L_valid = Ly_valid - alpha*Ld_valid\n",
        "\n",
        "        # Optimize A + N\n",
        "        L.backward()\n",
        "        optimizer_all.step()\n",
        "\n",
        "        # Get loss/accuracy and fpr and append to arrays\n",
        "        train_losses_L.append(L.detach().numpy())\n",
        "        valid_losses_L.append(L_valid.detach().numpy())\n",
        "\n",
        "        train_acc = 100.0*(np.sum(y_train_pred.round().detach().numpy() == y_train_tensor.detach().numpy())/len(y_train_tensor))\n",
        "        train_accuracies.append(train_acc)\n",
        "\n",
        "        valid_acc = 100.0*(np.sum(y_valid_pred.round().detach().numpy() == y_valid_tensor.detach().numpy())/len(y_valid_tensor))\n",
        "        valid_accuracies.append(valid_acc)\n",
        "\n",
        "        valid_fpr_diff.append(abs(aa_fpr - c_fpr))\n",
        "\n",
        "        #print('=== Epoch %04d  Train Loss %.4f Train Accuracy %.4f Valid Loss %.4f Valid Accuracy %.4f ===' % (epoch + 1, L, train_acc, L_valid, valid_acc))\n",
        "\n",
        "    return (main_model, train_losses_L, train_accuracies, valid_losses_L, valid_accuracies, valid_fpr_diff)\n",
        "    \n",
        "\n",
        "def part2_plot(train_losses_L, train_accuracies, valid_losses_L, valid_accuracies):\n",
        "    \"\"\"\n",
        "    This function plots the loss and accuracies for the model\n",
        "    \"\"\"\n",
        "\n",
        "    #Plot Loss\n",
        "    plt.title(\"Loss\")\n",
        "    plt.plot(train_losses_L, label=\"Train Combined Loss (L)\")\n",
        "    plt.plot(valid_losses_L, label=\"Validation Combined Loss (L)\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend(loc='best')\n",
        "    plt.show()\n",
        "\n",
        "    #Plot Accuracy\n",
        "    plt.title(\"Accuracy\")\n",
        "    plt.plot(train_accuracies, label=\"Train Accuracy\")\n",
        "    plt.plot(valid_accuracies, label=\"Validation Accuracy\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Accuracy (%)\")\n",
        "    plt.legend(loc='best')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RBOxEWYvLc3"
      },
      "source": [
        "Data preprocessing was first performed using the functions that were defined earlier. The same 7 features that were used in part 1 were also used in part 2 as these features were the most relevant to the classification results as seen in the paper by Wadsworth et al. Similar to part 1, one-hot encoding was performed on the non-numerical features and the inputs were all converted into torch tensors so that they would be in the correct input format for the model. However, following Wadsworth et al., instead of training the model on data from all racial groups, only data from the two racial groups (Caucasians and African-Americans) were used for this part. \n",
        "\n",
        "The data was split into an 80% training and 20% testing set. The training dataset was further split so that 20% of it was used as a validation set that was used to select hyperparameters and prevent overfitting. The testing data was also separated into two groups based on race (Caucasian and African-American) in order to determine if FPR parity and calibration are satisfied."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_NZo-seywoJ"
      },
      "outputs": [],
      "source": [
        "# Read in data as a dataframe\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/propublica/compas-analysis/master/compas-scores-two-years.csv')\n",
        "\n",
        "# Get selected features from dataset\n",
        "df = selected_features(df)\n",
        "\n",
        "# We will only be using data from 2 races: Caucasians and African-Americans\n",
        "df = drop_rows(df)\n",
        "\n",
        "# Split the data into a training, validation, and testing set\n",
        "data_train, data_test = train_test_split(df, test_size=0.20, random_state=25)\n",
        "data_train, data_valid = train_test_split(data_train, test_size=0.20, random_state=25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bou44hhMywoK"
      },
      "outputs": [],
      "source": [
        "# ==== Training Data ====\n",
        "\n",
        "# Training inputs and labels for main network and labels for adversarial network\n",
        "x_train = drop_selected_features(data_train)\n",
        "y_train = data_train['two_year_recid']\n",
        "y_train_adv = data_train['race']\n",
        "y_train_adv = y_train_adv.replace({'Caucasian': 1, 'African-American': 0})\n",
        "\n",
        "# Training input and label tensors\n",
        "x_train_tensor = torch.tensor(x_train.values.astype(np.float32))\n",
        "y_train_tensor = torch.tensor(y_train.values.astype(np.float32))\n",
        "y_train_adv_tensor = torch.tensor(y_train_adv.values.astype(np.float32))\n",
        "train_tensors = (x_train_tensor, y_train_tensor, y_train_adv_tensor)\n",
        "\n",
        "# ==== Validation Data ====\n",
        "\n",
        "# Validation inputs and labels for main network and labels for adversarial network \n",
        "x_valid = drop_selected_features(data_valid)\n",
        "y_valid = data_valid['two_year_recid']\n",
        "y_valid_adv = data_valid['race']\n",
        "y_valid_adv = y_valid_adv.replace({'Caucasian': 1, 'African-American': 0})\n",
        "\n",
        "# Validation inputs and labels for Caucasian race\n",
        "x_valid_c = data_valid.loc[data_valid['race'] == 'Caucasian']\n",
        "y_valid_c = x_valid_c['two_year_recid']\n",
        "x_valid_c = drop_selected_features(x_valid_c)\n",
        "\n",
        "# Validation input and label tensors for African American race\n",
        "x_valid_aa = data_valid.loc[data_valid['race'] == 'African-American']\n",
        "y_valid_aa = x_valid_aa['two_year_recid']\n",
        "x_valid_aa = drop_selected_features(x_valid_aa)\n",
        "\n",
        "# Validation input and label tensors\n",
        "x_valid_tensor = torch.tensor(x_valid.values.astype(np.float32))\n",
        "y_valid_tensor = torch.tensor(y_valid.values.astype(np.float32))\n",
        "y_valid_adv_tensor = torch.tensor(y_valid_adv.values.astype(np.float32))\n",
        "x_valid_c_tensor = torch.tensor(x_valid_c.values.astype(np.float32))\n",
        "y_valid_c_tensor = torch.tensor(y_valid_c.values.astype(np.float32))\n",
        "x_valid_aa_tensor = torch.tensor(x_valid_aa.values.astype(np.float32))\n",
        "y_valid_aa_tensor = torch.tensor(y_valid_aa.values.astype(np.float32))\n",
        "validation_tensors = (x_valid_tensor, y_valid_tensor, y_valid_adv_tensor, x_valid_c_tensor, y_valid_c_tensor, x_valid_aa_tensor, y_valid_aa_tensor)\n",
        "\n",
        "# ==== Testing Data with features ====\n",
        "\n",
        "# Testing inputs and labels for Caucasian race\n",
        "x_test_c = data_test.loc[data_test['race'] == 'Caucasian']\n",
        "y_test_c = x_test_c['two_year_recid']\n",
        "x_test_c = drop_selected_features(x_test_c)\n",
        "\n",
        "# Testing input and label tensors for African American race\n",
        "x_test_aa = data_test.loc[data_test['race'] == 'African-American']\n",
        "y_test_aa = x_test_aa['two_year_recid']\n",
        "x_test_aa = drop_selected_features(x_test_aa)\n",
        "\n",
        "# Testing tensors\n",
        "x_test_c_tensor = torch.tensor(x_test_c.values.astype(np.float32))\n",
        "y_test_c_tensor = torch.tensor(y_test_c.values.astype(np.float32))\n",
        "x_test_aa_tensor = torch.tensor(x_test_aa.values.astype(np.float32))\n",
        "y_test_aa_tensor = torch.tensor(y_test_aa.values.astype(np.float32))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EX8WjyUdzZLg"
      },
      "source": [
        "The hyperparameters were selected using grid search based on the results on the validation set for loss, accuracy, and FPR differences between the two racial groups. The model was trained with the following ranges for learning rate and number of epochs:\n",
        "\n",
        "* Values for the learning rate: either 0.0001 like the paper or a smaller rate such as 0.00005 or 0.00001\n",
        "* Number of epochs: ranging from 50 to 500 inclusive with a step size of 50\n",
        "\n",
        "The alpha of 1 was kept the same as Wadsworth et al. had already performed extensive validation/testing to arrive at that value in their paper.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 989
        },
        "id": "UYA9GvnixNE5",
        "outputId": "ad8ec76a-af04-4c14-953f-8a7b9019d21c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-c45b097e-e086-4d07-a7fa-733f644ec44f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>numEpochs</th>\n",
              "      <th>lr</th>\n",
              "      <th>alpha</th>\n",
              "      <th>L_train</th>\n",
              "      <th>L_valid</th>\n",
              "      <th>Acc_train</th>\n",
              "      <th>Acc_valid</th>\n",
              "      <th>FPR_Diff_valid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>50</td>\n",
              "      <td>0.00010</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.09024638</td>\n",
              "      <td>-0.08581215</td>\n",
              "      <td>62.931911</td>\n",
              "      <td>63.617886</td>\n",
              "      <td>6.085806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>50</td>\n",
              "      <td>0.00005</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.03400588</td>\n",
              "      <td>-0.03146243</td>\n",
              "      <td>57.748984</td>\n",
              "      <td>56.504065</td>\n",
              "      <td>0.396900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>50</td>\n",
              "      <td>0.00001</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.0031166673</td>\n",
              "      <td>0.0039168</td>\n",
              "      <td>53.810976</td>\n",
              "      <td>51.626016</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>100</td>\n",
              "      <td>0.00010</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.08340508</td>\n",
              "      <td>-0.08806872</td>\n",
              "      <td>65.929878</td>\n",
              "      <td>65.447154</td>\n",
              "      <td>14.915265</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>100</td>\n",
              "      <td>0.00005</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.027760506</td>\n",
              "      <td>-0.028615475</td>\n",
              "      <td>62.322154</td>\n",
              "      <td>63.211382</td>\n",
              "      <td>4.337554</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>100</td>\n",
              "      <td>0.00001</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.021614075</td>\n",
              "      <td>-0.018578649</td>\n",
              "      <td>55.716463</td>\n",
              "      <td>54.369919</td>\n",
              "      <td>0.349650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>150</td>\n",
              "      <td>0.00010</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.09495932</td>\n",
              "      <td>-0.10201186</td>\n",
              "      <td>65.955285</td>\n",
              "      <td>66.260163</td>\n",
              "      <td>11.869212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>150</td>\n",
              "      <td>0.00005</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.04910153</td>\n",
              "      <td>-0.053759396</td>\n",
              "      <td>64.303862</td>\n",
              "      <td>64.329268</td>\n",
              "      <td>8.728659</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>150</td>\n",
              "      <td>0.00001</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.014201462</td>\n",
              "      <td>-0.008318484</td>\n",
              "      <td>56.453252</td>\n",
              "      <td>55.386179</td>\n",
              "      <td>0.201600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>200</td>\n",
              "      <td>0.00010</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.11369336</td>\n",
              "      <td>-0.11815393</td>\n",
              "      <td>68.546748</td>\n",
              "      <td>67.378049</td>\n",
              "      <td>18.499968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>200</td>\n",
              "      <td>0.00005</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.1042487</td>\n",
              "      <td>-0.113690734</td>\n",
              "      <td>66.565041</td>\n",
              "      <td>66.158537</td>\n",
              "      <td>15.756316</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>200</td>\n",
              "      <td>0.00001</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.013252914</td>\n",
              "      <td>-0.00917542</td>\n",
              "      <td>59.222561</td>\n",
              "      <td>58.333333</td>\n",
              "      <td>2.145152</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>250</td>\n",
              "      <td>0.00010</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.1502313</td>\n",
              "      <td>-0.1374743</td>\n",
              "      <td>69.308943</td>\n",
              "      <td>67.378049</td>\n",
              "      <td>23.388773</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>250</td>\n",
              "      <td>0.00005</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.06818855</td>\n",
              "      <td>-0.06884706</td>\n",
              "      <td>66.768293</td>\n",
              "      <td>66.565041</td>\n",
              "      <td>14.760915</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>250</td>\n",
              "      <td>0.00001</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.047744095</td>\n",
              "      <td>-0.046385646</td>\n",
              "      <td>62.982724</td>\n",
              "      <td>64.024390</td>\n",
              "      <td>7.484407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>300</td>\n",
              "      <td>0.00010</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.0910036</td>\n",
              "      <td>-0.07097864</td>\n",
              "      <td>69.054878</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>13.362313</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>300</td>\n",
              "      <td>0.00005</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.09307188</td>\n",
              "      <td>-0.0928424</td>\n",
              "      <td>67.581301</td>\n",
              "      <td>66.971545</td>\n",
              "      <td>16.805267</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>300</td>\n",
              "      <td>0.00001</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.108742</td>\n",
              "      <td>-0.11089498</td>\n",
              "      <td>62.982724</td>\n",
              "      <td>63.211382</td>\n",
              "      <td>5.386505</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>350</td>\n",
              "      <td>0.00010</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.07823622</td>\n",
              "      <td>-0.05392641</td>\n",
              "      <td>69.690041</td>\n",
              "      <td>68.089431</td>\n",
              "      <td>17.948718</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>350</td>\n",
              "      <td>0.00005</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.05950892</td>\n",
              "      <td>-0.055784523</td>\n",
              "      <td>68.495935</td>\n",
              "      <td>67.886179</td>\n",
              "      <td>16.402066</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>350</td>\n",
              "      <td>0.00001</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.015875876</td>\n",
              "      <td>-0.013944149</td>\n",
              "      <td>60.467480</td>\n",
              "      <td>60.772358</td>\n",
              "      <td>2.992503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>400</td>\n",
              "      <td>0.00010</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.17229092</td>\n",
              "      <td>-0.12939239</td>\n",
              "      <td>69.588415</td>\n",
              "      <td>66.158537</td>\n",
              "      <td>12.010962</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>400</td>\n",
              "      <td>0.00005</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.08098221</td>\n",
              "      <td>-0.079759896</td>\n",
              "      <td>67.454268</td>\n",
              "      <td>66.463415</td>\n",
              "      <td>14.061614</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>400</td>\n",
              "      <td>0.00001</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.08294958</td>\n",
              "      <td>-0.07871133</td>\n",
              "      <td>58.358740</td>\n",
              "      <td>57.012195</td>\n",
              "      <td>0.746551</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>450</td>\n",
              "      <td>0.00010</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.10357493</td>\n",
              "      <td>-0.06296438</td>\n",
              "      <td>70.401423</td>\n",
              "      <td>67.581301</td>\n",
              "      <td>18.446418</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>450</td>\n",
              "      <td>0.00005</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.092428565</td>\n",
              "      <td>-0.085975945</td>\n",
              "      <td>68.877033</td>\n",
              "      <td>68.597561</td>\n",
              "      <td>19.199269</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>450</td>\n",
              "      <td>0.00001</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.059149623</td>\n",
              "      <td>-0.060360372</td>\n",
              "      <td>64.888211</td>\n",
              "      <td>64.329268</td>\n",
              "      <td>12.918163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>500</td>\n",
              "      <td>0.00010</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.11509961</td>\n",
              "      <td>-0.059232533</td>\n",
              "      <td>70.680894</td>\n",
              "      <td>65.548780</td>\n",
              "      <td>15.346815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>500</td>\n",
              "      <td>0.00005</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.16412193</td>\n",
              "      <td>-0.14494348</td>\n",
              "      <td>69.181911</td>\n",
              "      <td>68.191057</td>\n",
              "      <td>22.541423</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>500</td>\n",
              "      <td>0.00001</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.059672832</td>\n",
              "      <td>-0.059401274</td>\n",
              "      <td>63.236789</td>\n",
              "      <td>64.634146</td>\n",
              "      <td>7.383607</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c45b097e-e086-4d07-a7fa-733f644ec44f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c45b097e-e086-4d07-a7fa-733f644ec44f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c45b097e-e086-4d07-a7fa-733f644ec44f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "    numEpochs       lr  alpha  ...  Acc_train  Acc_valid  FPR_Diff_valid\n",
              "0          50  0.00010      1  ...  62.931911  63.617886        6.085806\n",
              "1          50  0.00005      1  ...  57.748984  56.504065        0.396900\n",
              "2          50  0.00001      1  ...  53.810976  51.626016        0.000000\n",
              "3         100  0.00010      1  ...  65.929878  65.447154       14.915265\n",
              "4         100  0.00005      1  ...  62.322154  63.211382        4.337554\n",
              "5         100  0.00001      1  ...  55.716463  54.369919        0.349650\n",
              "6         150  0.00010      1  ...  65.955285  66.260163       11.869212\n",
              "7         150  0.00005      1  ...  64.303862  64.329268        8.728659\n",
              "8         150  0.00001      1  ...  56.453252  55.386179        0.201600\n",
              "9         200  0.00010      1  ...  68.546748  67.378049       18.499968\n",
              "10        200  0.00005      1  ...  66.565041  66.158537       15.756316\n",
              "11        200  0.00001      1  ...  59.222561  58.333333        2.145152\n",
              "12        250  0.00010      1  ...  69.308943  67.378049       23.388773\n",
              "13        250  0.00005      1  ...  66.768293  66.565041       14.760915\n",
              "14        250  0.00001      1  ...  62.982724  64.024390        7.484407\n",
              "15        300  0.00010      1  ...  69.054878  66.666667       13.362313\n",
              "16        300  0.00005      1  ...  67.581301  66.971545       16.805267\n",
              "17        300  0.00001      1  ...  62.982724  63.211382        5.386505\n",
              "18        350  0.00010      1  ...  69.690041  68.089431       17.948718\n",
              "19        350  0.00005      1  ...  68.495935  67.886179       16.402066\n",
              "20        350  0.00001      1  ...  60.467480  60.772358        2.992503\n",
              "21        400  0.00010      1  ...  69.588415  66.158537       12.010962\n",
              "22        400  0.00005      1  ...  67.454268  66.463415       14.061614\n",
              "23        400  0.00001      1  ...  58.358740  57.012195        0.746551\n",
              "24        450  0.00010      1  ...  70.401423  67.581301       18.446418\n",
              "25        450  0.00005      1  ...  68.877033  68.597561       19.199269\n",
              "26        450  0.00001      1  ...  64.888211  64.329268       12.918163\n",
              "27        500  0.00010      1  ...  70.680894  65.548780       15.346815\n",
              "28        500  0.00005      1  ...  69.181911  68.191057       22.541423\n",
              "29        500  0.00001      1  ...  63.236789  64.634146        7.383607\n",
              "\n",
              "[30 rows x 8 columns]"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_dim = len(x_train.columns)\n",
        "output_dim = 1\n",
        "#learningRate = 0.0001\n",
        "#numEpochs = 500\n",
        "alpha = 1\n",
        "\n",
        "data = []\n",
        "\n",
        "for numEpochs in range(50, 550, 50):\n",
        "    for learningRate in [0.0001, 0.00005, 0.00001]:\n",
        "        main_model, train_losses_L, train_accuracies, valid_losses_L, valid_accuracies, valid_fpr_diff = part2_train(input_dim, \n",
        "                    output_dim, learningRate, alpha, numEpochs, train_tensors, validation_tensors)\n",
        "        \n",
        "        L = train_losses_L[-1]\n",
        "        train_acc = train_accuracies[-1]\n",
        "        L_valid = valid_losses_L[-1]\n",
        "        valid_acc = valid_accuracies[-1]\n",
        "        data.append({'numEpochs': numEpochs, 'lr': learningRate, 'alpha': alpha, 'L_train': L, \n",
        "                     'L_valid': L_valid, 'Acc_train': train_acc, 'Acc_valid': valid_acc, 'FPR_Diff_valid': valid_fpr_diff[-1]})\n",
        "        \n",
        "        #print('=== Num Epochs %04d  Train Loss %.4f Train Accuracy %.4f Valid Loss %.4f Valid Accuracy %.4f ===' % (numEpochs, L, train_acc, L_valid, valid_acc))\n",
        "\n",
        "data_df = pd.DataFrame(data)\n",
        "data_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcAQKp7_JzJE"
      },
      "source": [
        "Based on the training and validation results seen below, the following hyperparameters were chosen as they achieved FPR parity on the validation set and have the highest validation accuracy and low validation loss:\n",
        "\n",
        "*   Learning rate = 0.00001\n",
        "*   Alpha = 1\n",
        "*   Number of Epochs = 350"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "GnoNeYmgYMJB",
        "outputId": "18d6ae06-98b0-4042-e5a9-d639be86a4ae"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-fcfce858-bfc7-4904-9f97-2fd14afe5722\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>numEpochs</th>\n",
              "      <th>lr</th>\n",
              "      <th>alpha</th>\n",
              "      <th>L_train</th>\n",
              "      <th>L_valid</th>\n",
              "      <th>Acc_train</th>\n",
              "      <th>Acc_valid</th>\n",
              "      <th>FPR_Diff_valid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>50</td>\n",
              "      <td>0.00005</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.03400588</td>\n",
              "      <td>-0.03146243</td>\n",
              "      <td>57.748984</td>\n",
              "      <td>56.504065</td>\n",
              "      <td>0.396900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>50</td>\n",
              "      <td>0.00001</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.0031166673</td>\n",
              "      <td>0.0039168</td>\n",
              "      <td>53.810976</td>\n",
              "      <td>51.626016</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>100</td>\n",
              "      <td>0.00001</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.021614075</td>\n",
              "      <td>-0.018578649</td>\n",
              "      <td>55.716463</td>\n",
              "      <td>54.369919</td>\n",
              "      <td>0.349650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>150</td>\n",
              "      <td>0.00001</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.014201462</td>\n",
              "      <td>-0.008318484</td>\n",
              "      <td>56.453252</td>\n",
              "      <td>55.386179</td>\n",
              "      <td>0.201600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>200</td>\n",
              "      <td>0.00001</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.013252914</td>\n",
              "      <td>-0.00917542</td>\n",
              "      <td>59.222561</td>\n",
              "      <td>58.333333</td>\n",
              "      <td>2.145152</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>350</td>\n",
              "      <td>0.00001</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.015875876</td>\n",
              "      <td>-0.013944149</td>\n",
              "      <td>60.467480</td>\n",
              "      <td>60.772358</td>\n",
              "      <td>2.992503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>400</td>\n",
              "      <td>0.00001</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.08294958</td>\n",
              "      <td>-0.07871133</td>\n",
              "      <td>58.358740</td>\n",
              "      <td>57.012195</td>\n",
              "      <td>0.746551</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fcfce858-bfc7-4904-9f97-2fd14afe5722')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fcfce858-bfc7-4904-9f97-2fd14afe5722 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fcfce858-bfc7-4904-9f97-2fd14afe5722');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "    numEpochs       lr  alpha  ...  Acc_train  Acc_valid  FPR_Diff_valid\n",
              "1          50  0.00005      1  ...  57.748984  56.504065        0.396900\n",
              "2          50  0.00001      1  ...  53.810976  51.626016        0.000000\n",
              "5         100  0.00001      1  ...  55.716463  54.369919        0.349650\n",
              "8         150  0.00001      1  ...  56.453252  55.386179        0.201600\n",
              "11        200  0.00001      1  ...  59.222561  58.333333        2.145152\n",
              "20        350  0.00001      1  ...  60.467480  60.772358        2.992503\n",
              "23        400  0.00001      1  ...  58.358740  57.012195        0.746551\n",
              "\n",
              "[7 rows x 8 columns]"
            ]
          },
          "execution_count": 132,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check the hyperparameters that satisfy FPR parity for the validation set \n",
        "# (a tighter bound of less than 4% difference is used for FPR parity)\n",
        "data_df.loc[data_df[\"FPR_Diff_valid\"]<4]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2y_lQCD0mRU"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "**Testing Results:**\n",
        "\n",
        "The FPR values for each racial group was determined and the difference was calculated to be 4.9070% which is less than the 9.5238% found in part 1a. The model achieved a testing accuracy of 58.8618% which is only a slight decrease of less than 3% from the accuracy seen in part 1a. Therefore, we can conclude that Wadsworth et al.'s method does produce a smaller FPR disparity while still maintaining a good testing accuracy. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 811
        },
        "id": "OiNzUrZW7sGP",
        "outputId": "4a1a8884-d34f-47e1-c7e5-543710fbdacd"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "====== Test Results for Race: African American ======\n",
            "TN: 346, FP: 25, FN: 288, TP: 92\n",
            "False Positive Rate (FPR): 6.7385%\n",
            "\n",
            "\n",
            "====== Test Results for Race: Caucasian ======\n",
            "TN: 268, FP: 5, FN: 188, TP: 18\n",
            "False Positive Rate (FPR): 1.8315%\n",
            "\n",
            "\n",
            "====== Test Results ======\n",
            "Testing Accuracy: 58.8618%\n",
            "Difference in FPR between races: 4.9070%\n"
          ]
        }
      ],
      "source": [
        "# ==== Test Results =====\n",
        "\n",
        "# Selected model hyperparameters\n",
        "input_dim = len(x_train.columns)\n",
        "output_dim = 1\n",
        "learningRate = 0.00001\n",
        "alpha = 1\n",
        "numEpochs = 350\n",
        "\n",
        "# Train model and plot training and validation loss/accuracy\n",
        "main_model, train_losses_L, train_accuracies, valid_losses_L, valid_accuracies, valid_fpr_diff = part2_train(input_dim, \n",
        "                    output_dim, learningRate, alpha, numEpochs, train_tensors, validation_tensors)\n",
        "part2_plot(train_losses_L, train_accuracies, valid_losses_L, valid_accuracies)\n",
        "\n",
        "# Get predictions\n",
        "y_test_pred_c = torch.squeeze(torch.sigmoid(main_model(x_test_c_tensor))).round().detach().numpy()\n",
        "y_test_pred_aa = torch.squeeze(torch.sigmoid(main_model(x_test_aa_tensor))).round().detach().numpy()\n",
        "\n",
        "# Results for African American Race\n",
        "aa_cm = confusion_matrix(y_test_aa_tensor.detach().numpy(), y_test_pred_aa)\n",
        "aa_tn, aa_fp, aa_fn, aa_tp = aa_cm.ravel()\n",
        "aa_fpr = 100.0*aa_fp/(aa_fp+aa_tn)\n",
        "print(\"====== Test Results for Race: African American ======\")\n",
        "print(\"TN: %d, FP: %d, FN: %d, TP: %d\" %(aa_tn, aa_fp, aa_fn, aa_tp))\n",
        "print(\"False Positive Rate (FPR): %.4f%%\" %(aa_fpr))\n",
        "print(\"\\n\")\n",
        "\n",
        "# Results for Caucasian Race\n",
        "c_cm = confusion_matrix(y_test_c_tensor.detach().numpy(), y_test_pred_c)\n",
        "c_tn, c_fp, c_fn, c_tp = c_cm.ravel()\n",
        "c_fpr = 100.0*c_fp/(c_fp+c_tn)\n",
        "print(\"====== Test Results for Race: Caucasian ======\")\n",
        "print(\"TN: %d, FP: %d, FN: %d, TP: %d\" %(c_tn, c_fp, c_fn, c_tp))\n",
        "print(\"False Positive Rate (FPR): %.4f%%\" %(c_fpr))\n",
        "print(\"\\n\")\n",
        "\n",
        "# Test Results\n",
        "print(\"====== Test Results ======\")\n",
        "print(\"Testing Accuracy: %.4f%%\" %(100.0*(aa_tn + aa_tp + c_tn + c_tp)/(aa_tn + aa_fp + aa_fn + aa_tp + c_tn + c_fp + c_fn + c_tp)))\n",
        "print(\"Difference in FPR between races: %.4f%%\" %(abs(aa_fpr - c_fpr)))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "ECE324_Project1.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
